<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="NRES 746" />


<title>Lab Exercise 3</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cerulean.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">NRES 746</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Schedule
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="schedule.html">Course Schedule</a>
    </li>
    <li>
      <a href="labschedule.html">Lab Schedule</a>
    </li>
    <li>
      <a href="Syllabus2.pdf">Syllabus</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Lectures
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="INTRO.html">Introduction to NRES 746</a>
    </li>
    <li>
      <a href="LECTURE1.html">Why focus on algorithms?</a>
    </li>
    <li>
      <a href="LECTURE2.html">Working with probabilities</a>
    </li>
    <li>
      <a href="LECTURE3.html">The Virtual Ecologist</a>
    </li>
    <li>
      <a href="LECTURE4.html">Likelihood</a>
    </li>
    <li>
      <a href="LECTURE5.html">Optimization</a>
    </li>
    <li>
      <a href="LECTURE6.html">Bayesian #1: concepts</a>
    </li>
    <li>
      <a href="LECTURE7.html">Bayesian #2: mcmc</a>
    </li>
    <li>
      <a href="LECTURE8.html">Model Selection</a>
    </li>
    <li>
      <a href="LECTURE9.html">Performance Evaluation</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Lab exercises
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="LAB1.html">Lab 1: Algorithms in R</a>
    </li>
    <li>
      <a href="FINALPROJ.html">Final project overview</a>
    </li>
    <li>
      <a href="LAB2.html">Lab 2: Virtual ecologist</a>
    </li>
    <li>
      <a href="LAB3.html">Lab 3: Likelihood</a>
    </li>
    <li>
      <a href="LAB4.html">Lab 4: Bayesian Inference</a>
    </li>
    <li>
      <a href="FigureDemo.html">Demo: Figures in R</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Student-led topics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="TimeSeries.html">Time-series analysis</a>
    </li>
    <li>
      <a href="SEM.html">Structural Equation Models</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Data sets
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="TreeData.csv">Tree Data</a>
    </li>
    <li>
      <a href="ReedfrogPred.csv">Reed Frog Predation Data</a>
    </li>
    <li>
      <a href="ReedfrogFuncresp.csv">Reed Frog Func Resp</a>
    </li>
  </ul>
</li>
<li>
  <a href="Links.html">Links</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Lab Exercise 3</h1>
<h4 class="author"><em>NRES 746</em></h4>
<h4 class="date"><em>Fall 2018</em></h4>

</div>


<div id="maximum-likelihood-and-optimization" class="section level1">
<h1>Maximum likelihood and optimization</h1>
<p>These next few weeks are focused on fitting models, specifically estimating model parameters and confidence intervals, using likelihood techniques. Estimating model parameters means finding the values of a set of parameters that best “fit” the data. <em>Likelihood</em> is a metric that represents the probability of drawing your particular data given a specified model (e.g., a particular set of parameter values for a particular data-generating model). This lab is designed to take two lab sessions to complete.</p>
<p>As with all lab reports, your answers will either take the form of R functions or short written responses (submitted together in a Word document). The R functions should be stored in an R script file (‘.R’ extension). To allow me to evaluate your work more efficiently, please name your R script using the following convention: “[your first name]_[your last name]_lab3.R“. So my submission would be”kevin_shoemaker_lab3.R“. The name of your Word docuement doesn’t matter, as long as you submit via WebCampus.</p>
<p>Please submit the R script and the Word document via WebCampus by midnight on the due date (one week after the final lab session allocated for this topic – here, <em>Oct. 23, 2018</em>). You can work in groups but please submit the materials individually.</p>
<p>First, take a little time to review the <a href="LECTURE4.html">likelihood lecture</a>!</p>
<div id="example-reed-frog-predation-data" class="section level2">
<h2>Example: reed frog predation data</h2>
<p>First, load the reed frog predation data from the Bolker book- it can be found <a href="ReedfrogPred.csv">here</a>. Save this file to your working directory.</p>
<p>This dataset represents predation data for <em>Hyperolius spinigularis</em> (Vonesh and Bolker 2005). You can read more about this data set in the Bolker book.</p>
<pre class="r"><code>###### Read in the reed frog data set

rfp &lt;- read.csv(&quot;ReedfrogPred.csv&quot;)
head(rfp)</code></pre>
<pre><code>##   X density pred  size surv propsurv
## 1 1      10   no   big    9      0.9
## 2 2      10   no   big   10      1.0
## 3 3      10   no   big    7      0.7
## 4 4      10   no   big   10      1.0
## 5 5      10   no small    9      0.9
## 6 6      10   no small    9      0.9</code></pre>
<p>Parameter estimation is simplest when the data represent a collection of independent observations, with each observation having the same set of parameters. Because predation on tadpoles is size and density-dependent, we will subset these data to a single size class (“small”) and density (10) for all treatments including a predator. Subset your data now:</p>
<pre class="r"><code>##### Take a subset of the data

rfp_sub &lt;- subset(rfp, (rfp$pred==&#39;pred&#39;)&amp;(rfp$size==&quot;small&quot;)&amp;(rfp$density==10))
rfp_sub</code></pre>
<pre><code>##     X density pred  size surv propsurv
## 13 13      10 pred small    7      0.7
## 14 14      10 pred small    5      0.5
## 15 15      10 pred small    9      0.9
## 16 16      10 pred small    9      0.9</code></pre>
<p>For each individual, the per-trial probability of being eaten by a predator is a binomial process (i.e., they can survive or die during the interval). Recall that the likelihood that k out of N individuals are eaten as a function of the per capita predation probability p is:</p>
<p><span class="math inline">\(Prob(k|p,N) = \binom{N}{k}p^{k}(1-p)^{N-k}\)</span></p>
<p>Since the observations are independent, the joint likelihood of the whole data set is the product of the likelihood of each individual observation. So, if we have n observations, each with the same total number of tadpoles N, and the number of tadpoles killed in the ith observation is ki, then the likelihood is:</p>
<p><span class="math inline">\(L = \prod_{i=1}^{n}\binom{N}{k_{i}}p^{k_{i}}(1-p)^{N-k_{i}}\)</span></p>
<p>We conventionally work in terms of the log-likelihood (LL), which is:</p>
<p><span class="math inline">\(LL = \sum_{i=1}^{n}\left [log\binom{N}{k}+k_{i}log(p)+(N-k_{i})log(1-p) \right ]\)</span></p>
<p>In R this would be</p>
<pre class="r"><code>killed &lt;- rfp_sub$density-rfp_sub$surv
N=rfp_sub$density
p=0.5
sum(dbinom(killed, size=N, prob=p, log=TRUE))    # expression of data likelihood</code></pre>
<p>There is only one parameter in this calculation, <em>p</em>, because we know how many individuals we started with (<em>N</em> = 10 for each trial) and how many survived in each trial (k = 7, 5, 9, and 9). So we want to solve for the most likely value of <em>p</em> given our observations of <em>N</em> and <em>surv</em>. In essence we do this by picking a possible value of <em>p</em> (which can only range from 0 to 1), calculating the log-likelihood (LL) using the equation above, picking another value of p, completing the equation, etc. until we exhaust all possible values of p and identify the one having the highest likelihood value. Of course R has useful built in functions to help us!</p>
<p>The “dbinom()” function calculates the binomial likelihood for a specified data set, specifically a vector of the number of successes (or events) k, probability p, and number of trials N. Specify your vector of successes (here a success means being eaten by a predator!):</p>
<pre class="r"><code>num_killed &lt;- rfp_sub$density-rfp_sub$surv     # specify vector of &quot;successes&quot; (being eaten!)
num_killed</code></pre>
<pre><code>## [1] 3 5 1 1</code></pre>
<p>Given our observed <em>k</em> (number killed), and <em>N</em> = 10 for each trial, what is the likelihood that <em>p</em> = 0.5 for each of our trials?</p>
<pre class="r"><code>dbinom(num_killed,size=10,prob=0.5)  # evaluate data likelihood with p=0.5</code></pre>
<pre><code>## [1] 0.117187500 0.246093750 0.009765625 0.009765625</code></pre>
<p>[1] 0.117187500 0.246093750 0.009765625 0.009765625</p>
<p>We can see that given our data, fixed sample size, and model (with <em>p</em> = 0.5), our observed outcomes are very unlikely.</p>
<p>What is the likelihood of observing all 4 of our outcomes, i.e, the joint probability of our data?</p>
<pre class="r"><code>prod(dbinom(num_killed,size=10,prob=0.5))    # joint data likelihood</code></pre>
<pre><code>## [1] 2.750312e-06</code></pre>
<p>The joint likelihood values will be less than 1, and gets smaller and smaller each time we add more data (can you see why?). This is why we prefer to work with log-likelihoods (which yield larger numbers having better mathematical properties). And taking the log of value &lt;1 yields a negative number, which is why we speak in terms of log-likelihoods.</p>
<p>For now, we can build on this above process to estimate the likelihood function over the entire possible parameter space from 0 to 1.<br />
First we make a sequence of 100 probabilities from 0.01 to 1.</p>
<pre class="r"><code>p &lt;- seq(0.01, 1, by=0.01)     # prepare for visualizing the likelihood across parameter space</code></pre>
<p>Then we make an empty storage vector for the likelihoods we’ll calculate</p>
<pre class="r"><code>Lik &lt;- numeric(length=100)</code></pre>
<p>Now for the <strong>for</strong> loop! For every value of p (a sequence of 100 values) we will calculate the binomial probability and store it in the “Lik” vector.</p>
<pre class="r"><code>#########
# plot out the likelihood

for(i in 1:100){
  Lik[i] &lt;- prod(dbinom(num_killed,size=10,prob=p[i]))
}
plot(Lik~p,lty=&quot;solid&quot;,type=&quot;l&quot;, xlab=&quot;Predation Probability&quot;, ylab=&quot;Likelihood&quot;)</code></pre>
<p><img src="LAB3_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>But we want to maximize the log-likelihood:</p>
<pre class="r"><code>########
# plot out the log-likelihood

p &lt;- seq(0.01, 1, by=0.01)
LogLik &lt;- numeric(length=100)
for(i in 1:100){
  LogLik[i] &lt;- sum(dbinom(num_killed, size=10, 
  prob=p[i],log=TRUE))
}
plot(LogLik~p,lty=&quot;solid&quot;,type=&quot;l&quot;, xlab=&quot;Predation Probability&quot;, ylab=&quot;Log Likelihood&quot;)</code></pre>
<p><img src="LAB3_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>We can ask R to tell us at which value of p the LL is maximized:</p>
<pre class="r"><code>p[which(LogLik==max(LogLik))]     # MLE for probability of predation</code></pre>
<pre><code>## [1] 0.25</code></pre>
<p>And we can add an “abline()” to indicate the maximum Log-Likelihood estimate:</p>
<pre class="r"><code>plot(LogLik~p,lty=&quot;solid&quot;,type=&quot;l&quot;, xlab=&quot;Predation Probability&quot;, ylab=&quot;Log Likelihood&quot;)
abline(v=0.25,lwd=3)</code></pre>
<p><img src="LAB3_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>Alternatively, we can use the optim() or mle2() functions to find the maximum likelihood estimate. Although we seek the most likely, or maximum likelihood estimate, in practice we generally minimize the negative log-likelihood. To do so, first write a function to calculate the binomial negative log-likelihood function and estimate parameter p.</p>
<pre class="r"><code>###########
# Write a likelihood function

#    p: probability of predation per trial (param to estimate)
#    k: number killed per trial   (data)
#    N: number of tadpoles per trial (data)

binomNLL1 &lt;- function(p, k, N) {
  -sum(dbinom(k, size=N, prob=p, log=TRUE))
}</code></pre>
<p>As we did in class, you can use the ‘optim()’ function to minimize your negative log-likelihood function (‘binomNLL1()’) given a vector of starting parameters and your data. The starting parameters need not be accurate, but do need to be reasonable for the function to work, that’s why we spent time in class eyeballing curves and calculating the method of moments. Given that there is only one estimable parameter, <em>p</em>, in the binomial function, you need only provide a starting estimate for it. Calculate the negative log-likelihood:</p>
<pre class="r"><code>#####
# use &quot;optim()&quot; to find the MLE

opt1 &lt;- optim(fn=binomNLL1, par = c(p=0.5), N = 10, k = num_killed, method = &quot;BFGS&quot;)   # use &quot;optim()&quot; to estimate the parameter value that maximizes the likelihood function </code></pre>
<pre><code>## Warning in dbinom(k, size = N, prob = p, log = TRUE): NaNs produced

## Warning in dbinom(k, size = N, prob = p, log = TRUE): NaNs produced

## Warning in dbinom(k, size = N, prob = p, log = TRUE): NaNs produced

## Warning in dbinom(k, size = N, prob = p, log = TRUE): NaNs produced

## Warning in dbinom(k, size = N, prob = p, log = TRUE): NaNs produced</code></pre>
<p>You may get several warning messages, can you think why? opt1 returns a list that stores information about your optimization process.</p>
<pre class="r"><code>opt1    # check out the results of &quot;optim()&quot;</code></pre>
<pre><code>## $par
##         p 
## 0.2500002 
## 
## $value
## [1] 7.571315
## 
## $counts
## function gradient 
##       17        7 
## 
## $convergence
## [1] 0
## 
## $message
## NULL</code></pre>
<p>The important bits are whether or not the process achieved convergence and the parameter estimate that was converged upon.</p>
<pre class="r"><code>opt1$convergence</code></pre>
<pre><code>## [1] 0</code></pre>
<p>Here a value of 0 means convergence has been achieved, a value of 1 means the process failed to converge. There is more info about convergence and alternative optimization options in Chapter 7 of the Bolker book.</p>
<p>Your best fit estimate of p is:</p>
<pre class="r"><code>opt1$par  # MLE</code></pre>
<pre><code>##         p 
## 0.2500002</code></pre>
<p>This numerically computed answer is almost, but not exactly, equal to the theoretical answer of 0.25. The value of the function you optimized, binomNLL1, is:</p>
<pre class="r"><code>opt1$value     # max. likelihood (actually minimum negative-log-likelihood)</code></pre>
<pre><code>## [1] 7.571315</code></pre>
<p>which is the negative log-likelihood for the model. And, as we already know, the absolute likelihood of this particular outcome (5, 3, 1 and 1 out of 10 tadpoles eaten in four replicates) is quite low:</p>
<pre class="r"><code>exp(-opt1$value)   # convert to likelihood</code></pre>
<pre><code>## [1] 0.0005150149</code></pre>
<p>Plot your observed outcomes against your predictions under the maximum likelihood model:</p>
<pre class="r"><code>hist(num_killed,xlim=c(0,10),freq=F)
curve(dbinom(x,prob=opt1$par,size=10),add=T,from=0,to=10,n=11)</code></pre>
<p><img src="LAB3_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>Note that “freq=F” scales the y-axis of a histogram to “density”, which allows us to overlay probability density functions.</p>
<div id="challenge-problem-1" class="section level4">
<h4>Challenge problem 1</h4>
<p>NOTE: we went through this simple example as part of the MLE lecture, so you may already have this one done!</p>
<blockquote>
<p>Develop a function that returns the data likelihood (<em>likelihood function</em>) for the following scenario: you visit three known-occupied wetland sites ten times and for each site you record the number of visits for which a particular frog species is detected (at least one call within a 5 minute period). Assuming that all sites are occupied continously, compute the likelihood of these data: [3,2 and 6 detections for sites 1, 2, and 3 respectively] for a given detection probability <span class="math inline">\(p\)</span>. Assume that all sites have the same unknown detection probability (<em>p</em>, which is our free parameter). Using this likelihood function, answer the following questions:</p>
</blockquote>
<ul>
<li><p><strong>Exercise 1a</strong>. Write a function called “NLL_frogOccupancy()” for computing the data likelihood for the above scenario.</p>
<ul>
<li><strong>input</strong>:
<ul>
<li>params = a scalar (floating point) specifying a proposal for the parameter “p” (probability of detection for a single visit)<br />
</li>
<li>data = a vector of integers with number of elements equal to the number of sites, representing the number of times the species was detected out of N visits.</li>
<li>N = an integer representing the total number of visits conducted at each site (default= 10 visits)</li>
</ul></li>
<li><strong>suggested algorithm</strong>:
<ul>
<li>up to you!</li>
</ul></li>
<li><strong>return</strong>:
<ul>
<li>the sum of the negative log likehoods of all 3 observations (use binomial distribution)</li>
</ul></li>
</ul></li>
</ul>
<p>And test your function!</p>
<pre class="r"><code>NLL_frogOccupancy(params=0.5,data=c(3,2,6),N=10)   # test your function</code></pre>
<pre><code>## [1] 6.853154</code></pre>
<ul>
<li><strong>Exercise 1b</strong>. In your Word document, respond briefly to the following questions:</li>
</ul>
<ol style="list-style-type: decimal">
<li>What is the maximum likelihood estimate for the <em>p</em> (detection probability) parameter?<br />
</li>
<li>Using the “rule of 2”, what is the approximate 95% confidence interval for the <em>p</em> parameter. Include a figure illustrating how you got your answer.</li>
</ol>
<p><img src="LAB3_files/figure-html/answer1b-1.png" width="672" /></p>
</div>
</div>
<div id="adding-a-deterministic-relationship" class="section level2">
<h2>Adding a Deterministic Relationship</h2>
<p>So we’ve looked at how to obtain the likelihood of getting our dataset given a stochastic model (the binomial distribution), but now we want to consider more interesting ecological questions like when the mean or variance of the model parameters vary among groups or depend upon covariates. Recall that we subset our data above because we expected survival to be (in part) density-dependent. Here we’ll consider how to model the probability of tadpole survival as a function of the initial density of tadpoles in the population. To do so, we need to incorporate a deterministic function into our stochastic model.</p>
<p>Save the reed frog functional response dataset to your working directory- it can be found <a href="ReedfrogFuncResp.csv">here</a>.</p>
<p>First, examine the first few lines:</p>
<pre class="r"><code>#####
# 2a

rffr &lt;- read.csv(&quot;ReedfrogFuncResp.csv&quot;,row.names = 1)
  # alternative: data(ReedfrogFuncresp)     # from Bolker&#39;s &quot;emdbook&quot; package
  # ?Reedfrog      # learn more about this dataset
head(rffr)</code></pre>
<pre><code>##   Initial Killed
## 1       5      1
## 2       5      2
## 3      10      5
## 4      10      6
## 5      15     10
## 6      15      9</code></pre>
<p>Let’s look at the distribution of the data (probability of being killed).</p>
<pre class="r"><code>hist(rffr$Killed/rffr$Initial)</code></pre>
<p><img src="LAB3_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<p>Based on what we know mechanistically about the data, we’ll use a binomial distribution to describe the observed number killed.</p>
<p>Plot the number killed by the initial density (using plot()) to see what sort of deterministic function would describe the pattern. It looks like it could be linear, but because we know that this is a predation response, and that predators become handling-limited (saturated) at high prey densities. On page 182 Bolker indicates that if predation rate= <span class="math inline">\(aN/(1+ahN)\)</span> (Holling Type II functional response), this means that the per-capita predation rate of tadpoles decreases hyperbolically with tadpole density <span class="math inline">\((= a/(1 + ahN))\)</span>. We’ll use this deterministic function for our data.</p>
<p>First, let’s see what that curve would look like over our data points with an initial guess at the parameters (we always need an initial guess to seed our optimization algorithms). Recall that the a parameter of this hyperbolic function indicates the initial slope, which we’ll guess to be around 0.5, and the h parameter indicates 1/asymptote, which we fiddled around with to match the data (so try 1/80).</p>
<pre class="r"><code>#########
# define a Holling type II functional response, with an initial guess about parameter values

Holl2&lt;-function(x, a, h){(a*x)/(1+(a*h*x))}
plot(rffr$Killed~rffr$Initial)
curve(Holl2(x, a=0.5, h=1/80), add=TRUE,col=&quot;red&quot;)</code></pre>
<p><img src="LAB3_files/figure-html/answer2a2-1.png" width="672" /></p>
<p>This looks pretty good, but we want to actually fit the line to the data instead of making guesses, and we’ll use likelihood to do that. Just like before, we’ll write a <em>negative log likelihood function</em>, but this time we’ll incorporate the deterministic model.</p>
<pre class="r"><code>###########
# Write a likelihood function

#    params: vector of params to estimate (a and h from the Holling type II functional response)
#    k: number killed per trial   (data)
#    N: number of tadpoles per trial (data)

binomNLL2&lt;-function(params,N,k){
    a=params[1]
    h=params[2]
    predprob=a/(1+a*h*N)    
    -sum(dbinom(k,prob=predprob,size=N,log=TRUE))
}</code></pre>
<p>This likelihood function says that the structure of the data is described by a binomial distribution (either killed or not), and that the probability of predation (the number killed divided by the initial number) is explained by the Holling type II equation. (The equation is specified differently here than when we used it to make a curve, can you think of why?)</p>
<p>Now we’ll find the parameter values that best describe these data using ‘optim()’. We’ll use the same initial values for a and h that we used to plot the curve. N is the initial number of tadpoles, and k is the number of tadpoles killed.</p>
<pre class="r"><code>opt2 &lt;- suppressWarnings( optim(fn=binomNLL2,  par=c(a=0.5,h=(1/80)), N=rffr$Initial, k=rffr$Killed)   )  #use default simplex algorithm
opt2</code></pre>
<pre><code>## $par
##          a          h 
## 0.52593924 0.01660613 
## 
## $value
## [1] 46.72136
## 
## $counts
## function gradient 
##       53       NA 
## 
## $convergence
## [1] 0
## 
## $message
## NULL</code></pre>
<p>The results are not that different from our starting values, so we made a good guess.</p>
<div id="challenge-problem-2" class="section level4">
<h4>Challenge problem 2</h4>
<ul>
<li><p><strong>Exercise 2a</strong>. Write a function called “Rffuncresp()” for computing the data likelihood and plotting the goodness-of-fit for this model.</p>
<ul>
<li><strong>input</strong>:
<ul>
<li>params = vector of initial values for the params to estimate (length 2: a and h from the Holling type II functional response)<br />
</li>
<li>data = a matrix of 2 columns and one row per observation. The first column should represent the initial tadpole densities, and the second column should represent the number killed (eaten by dragonfly larvae).</li>
</ul></li>
<li><strong>suggested algorithm</strong>:
<ul>
<li>Compute the MLE for the a and h parameters of the Holling Type II relationship.<br />
</li>
<li>Plot the observed number killed (y axis) vs the initial densities<br />
</li>
<li>Overlay a line to visualize your initial guess (initial values)<br />
</li>
<li>Overlay another line to visualize the predictions based on the MLE parameters.</li>
<li>Finally, visualize “prediction intervals” around your MLE line to make a plot like Figure 6.5a in the Bolker book. You can use “qbinom()” to define the 95% quantiles of the binomial distribution for every point along your curve (see below).</li>
</ul></li>
<li><strong>return</strong>:
<ul>
<li>a vector of length 2 containing the MLE for the a and h parameters</li>
</ul></li>
</ul></li>
</ul>
<pre class="r"><code>inits &lt;- c(a=0.6,h=(1/60))    # test the function
Rffuncresp(params=inits,data=rffr)</code></pre>
<p><img src="LAB3_files/figure-html/test2a-1.png" width="672" /></p>
<pre><code>##          a          h 
## 0.52592194 0.01660555</code></pre>
<p>NOTE: the “prediction interval” you are asked to generate here is sometimes called a <em>“plug-in” prediction interval</em>, and is a quick and dirty way to assess goodness-of-fit. Essentially, you just take the best-fit model (with parameter values at their MLE values) and use the 0.025 and 0.975 quantiles of the “noise” process to define the range of data that would generally be produced under this model. NOTE: In “qbinom()”, for the “prob” argument, you can use the ratio of the x and y values to get a probability value from 0-1. For example:</p>
<pre class="r"><code>########
# how to generate plug-in prediction intervals

xvec &lt;- seq(40,80,5)
yvec &lt;- 0.5/(1+0.5*0.015*xvec) * xvec
upper&lt;-qbinom(0.975,prob=yvec/xvec, size=xvec) 
lower&lt;-qbinom(0.025,prob=yvec/xvec, size=xvec)

upper
lower</code></pre>
<ul>
<li><strong>Exercise 2b</strong>. In your Word document, respond briefly to the following questions:</li>
</ul>
<ol style="list-style-type: decimal">
<li><p>Try some different starting values for the <em>a</em> and <em>h</em> parameters. Can you find any starting values that cause the optimization algorithm (“optim()” function) to fail?</p></li>
<li><p>Bolker calls the prediction interval you generated above a <em>plug-in prediction interval</em>. In what way(s) is this interval different than a <em>true</em> prediction interval?</p></li>
</ol>
</div>
<div id="review-of-the-mle-process" class="section level3">
<h3>Review of the MLE process</h3>
<p><strong>Step 1</strong>. Identify the response and explanatory variables (e.g., Predation probability and Initial Population Size). Just stating what the response and explanatory variables are will help you start modeling.</p>
<p><strong>Step 2</strong>. Determine the stochastic distribution (e.g., Binomial). In this case, the stochastic distribution was easy to identify because we chose it mechanistically. Other times it may not be so clear what the best distribution is, and looking at the histogram and plotting different distributions over the top will be helpful.</p>
<p><strong>Step 3</strong>. Specify the deterministic function (e.g., Holling type II). Again, we chose this function mechanistically, but we could have chosen different functions just by looking at the plot of the points.</p>
<p><strong>Step 4</strong>. Specify the likelihood of the data given our deterministic expectations and the stochastic distribution: binomNLL2. Our negative <em>log likelihood function</em> combined the stochastic and deterministic elements together by having the stochastic parameter (in this case the binomial probability, <em>p</em>) be dependent upon the deterministic parameters.</p>
<p><strong>Step 5</strong>. Make a guess for the initial parameters (e.g., <em>a</em>=0.5, <em>h</em>=1/80). You need to have an initial guess at the parameters to make ‘optim()’ work, and we plotted the Holling curve to make our guess. Sometimes you will also need to make a guess at the parameters for the stochastic distribution. In these cases, the <em>method of moments</em> is often the best option (see Bolker book for details).</p>
<p><strong>Step 6</strong>. Estimate the best fit parameters using maximum likelihood. We used optim() to search through all the possible value combinations of parameters <em>a</em> and <em>h</em> to estimates for those parameters that correspond to the minimized negative log-likelihood.</p>
<p><strong>Step 7</strong>. Add confidence intervals around your estimates. We calculated some <em>plug-in estimates</em> to put “pseudo-prediction intervals” around our estimates based on the stochastic distribution.</p>
</div>
</div>
<div id="exploring-likelihood-surfaces-and-confidence-regions" class="section level2">
<h2>Exploring Likelihood Surfaces and Confidence Regions</h2>
<p>Let’s continue the myxomatosis virus titer example from the <a href="LECTURE5.html">optimization lecture</a>. The difference is that this time we’ll model a deterministic process (decay of viral loads over time) in addition to the stochastic process. Our goal is to fit a model to data on viral titers through time for the viruses that are grade 1. Biological common sense, and data from other titer levels, tells us to expect titer levels to start at zero, increase over time to a peak, and then to decline. Given those expectations, we’ll fit a Ricker model to these data, following Bolker’s example and extending it just a bit.</p>
<p>Our goals are to:</p>
<ul>
<li>Find the maximum likelihood estimates of the parameters of the Ricker model fit to the myxomytosis data.</li>
<li>Visualize the fit of this model to the data by:
<ul>
<li>Plotting the data</li>
<li>Adding the predicted Ricker curve</li>
<li>Adding plug-in confidence intervals</li>
<li>Plot the 2-dimensional likelihood surface for the parameters of the Ricker and add the bivariate 95% confidence interval</li>
</ul></li>
</ul>
<p>You can add the data from the ‘emdbook’ package:</p>
<pre class="r"><code>#######
# 3a


########
# Myxomatosis data

library(emdbook)
data(MyxoTiter_sum)      # load the data
head(MyxoTiter_sum)   </code></pre>
<pre><code>##   grade day titer
## 1     1   2 5.207
## 2     1   2 5.734
## 3     1   2 6.613
## 4     1   3 5.997
## 5     1   3 6.612
## 6     1   3 6.810</code></pre>
<p>Select just the grade 1 titers:</p>
<pre class="r"><code>myxdat &lt;- subset(MyxoTiter_sum, grade==1)    # select just the most virulent strain

plot(myxdat$titer~myxdat$day,xlim=c(0,10))    # visualize the relationship</code></pre>
<p><img src="LAB3_files/figure-html/answer3a2-1.png" width="672" /></p>
<div id="challenge-problem-3" class="section level4">
<h4>Challenge problem 3:</h4>
<p><strong>Fit a Ricker model to the myxomatosis data</strong> (see below for step-by step instructions)</p>
<ul>
<li><strong>Exercise 3a</strong>. Write a function called “NLL_myxRicker()” for computing the data likelihood and plotting the goodness-of-fit for this model.
<ul>
<li><strong>input</strong>:
<ul>
<li>params = vector of initial values for the params to estimate (length 3: <em>a</em> and <em>b</em> params from the Ricker model [see below], and the “shape” parameter of the Gamma distribution)<br />
</li>
<li>data = a matrix of 2 columns and one row per observation. The first column should represent the days since infection, and the second column should represent the virus titer.</li>
</ul></li>
<li><strong>suggested algorithm</strong>:
<ul>
<li>Compute the deterministic function: use a Ricker equation to model the expected (mean) virus titer as a function of days since infection</li>
<li>Compute the “scale” parameter of the Gamma distribution as a function of (1) the mean virus titer and (2) the “shape” parameter of the Gamma distribution [NOTE: the variance and the mean of the Gamma distribution are dependent- so we can’t simply model the expected value and the noise separately! See below for more detals]</li>
<li>Compute the sum of the negative log-likelihoods of all observations (use the “dgamma()” function)</li>
</ul></li>
<li><strong>return</strong>:
<ul>
<li>the sum of the negative log-likelihoods of all observations</li>
</ul></li>
</ul></li>
</ul>
<pre class="r"><code>NLL_myxRicker(params=c(a=4,b=0.2,shape=40),data=myxdat[,-1])   # test the function</code></pre>
<pre><code>## [1] 35.39427</code></pre>
<p>This task (develop likelihood function) can be broken down into a few steps, just like we did above!</p>
<p>Our question is: how does a virus titer change in rabbits as a function of time since infection? This is almost exactly the same problem as we just did (above), but we’re using different distributions and functions. To solve the problem, you’ll need to go through the same steps outlined above.</p>
<p><strong>Step 1</strong>. <em>Identify the response and explanatory variables</em>. The response is the virus titer and the explanatory variable is the days since infection.</p>
<p><strong>Step 2</strong>. <em>Determine the stochastic distribution.</em><br />
Start by plotting the histogram of the response variable. Bolker suggests a gamma distribution – does it look like a gamma would work? Write down the parameters for the gamma distribution (page 133). (For the gamma distribution, use with the shape and scale parameters (not the rate)).</p>
<p><strong>Step 3</strong>. <em>Specify the deterministic function</em>.<br />
Plot the data points (hint: look at figure 6.5b). Bolker suggests the Ricker curve – does it look like the Ricker curve would work? (Note that grade 1 virus is so virulent that most rabbits die before the titer has a chance to drop off entirely) Write down the equation and parameters for the Ricker curve (page 94).</p>
<p><strong>Step 4</strong>. <em>Specify the likelihood of the data given our deterministic expectations and the stochastic distribution.</em> Take a moment to think how the parameters of the stochastic distribution are determined by the parameters of the deterministic function. For the gamma distribution, both the shape and scale parameters are related to the mean of the distribution, i.e., mean = shape × scale (page 133). So how will you specify that the deterministic function (the Ricker model) should represent the mean? What parameters do you need your (negative) log-likelihood function to estimate? Write out your negative log-likelihood function to solve for the likelihood.</p>
<p>ASIDE: the mean and variance of the gamma distribution are inter-related: the shape parameter can be specified as: <span class="math inline">\(\frac{mean^2}{var}\)</span> and the scale parameter can be specified as <span class="math inline">\(\frac{var}{mean}\)</span>!</p>
<ul>
<li><p><strong>Exercise 3b</strong>. Write a function called “MyxRicker()” for computing the data likelihood and plotting the goodness-of-fit for this model.</p>
<ul>
<li><strong>input</strong>:
<ul>
<li>params = vector of initial values for the params to estimate (length 3: <em>a</em> and <em>b</em> params from the Ricker model [see below], and the “shape” parameter of the Gamma distribution)<br />
</li>
<li>data = a matrix of 2 columns and one row per observation. The first column should represent the days since infection, and the second column should represent the virus titer.</li>
</ul></li>
<li><strong>suggested algorithm</strong>:
<ul>
<li>Compute the MLE for the <em>a</em>, <em>b</em>, and <em>shape</em> parameters for the Ricker/Gamma model (use “optim()” with the likelhood function you just wrote and the initial values in “params”).<br />
</li>
<li>Plot the observed virus titer (y axis) vs the days since infection (x axis).<br />
</li>
<li>Overlay a line to visualize your predictions from the Ricker model (expected values) based on the MLE parameters (just the Ricker parameters).</li>
<li>Finally, visualize “plug-in prediction intervals” around your MLE line to make a plot like Figure 6.5a in the Bolker book. Hint: use “qgamma()” to define the 95% quantiles of the Gamma distribution for every point along your curve (see below).</li>
</ul></li>
<li><strong>return</strong>:
<ul>
<li>a vector of length 3 containing the MLE for the a, b, and shape parameters</li>
</ul></li>
</ul></li>
</ul>
<pre class="r"><code>MyxRicker(params=c(a=2,b=0.2,shape=30),data=myxdat[,-1])   # test the function</code></pre>
<p><img src="LAB3_files/figure-html/test3b-1.png" width="672" /></p>
<pre><code>##          a          b      shape 
##  3.5611591  0.1713262 90.5287907</code></pre>
<p>To complete this exercise will involve going through the final steps (5-7) in the process outlined above:</p>
<p><strong>Step 5</strong>. <em>Make a guess for the initial parameters</em>. We need initial parameters to put into “optim()”. Remember that the Ricker curve parameters can be estimated based on the initial slope and maximum (see pg. 95). Try plotting the curve over the points to get an approximate fit. There really isn’t any easier way to get there than trial and error for the deterministic function.</p>
<p><strong>Step 6</strong>. <em>Estimate the best fit parameters using maximum likelihood</em>.<br />
Now use ‘optim()’ to get your maximum likelihood parameter estimates.</p>
<p><strong>Step 7</strong>. <em>Add confidence/prediction intervals around your estimates</em>.<br />
After your run of ‘optim()’ (did you achieve convergence?), plot your fitted Ricker curve to your data. Revisit the earlier prediction interval code to add <em>plug-in</em> prediction intervals around your predicted curve based on gamma distributed errors (should resemble Figure 6.5b on page 184 of text).</p>
<p>Use the “qgamma()” function</p>
<pre class="r"><code>########
# Plug-in prediction intervals!

upper&lt;-qgamma(0.975,shape=?, scale=?)   # remember that the mean of the gamma distribution is shape*scale
lower&lt;-qgamma(0.025,shape=?, scale=?)</code></pre>
</div>
<div id="challenge-problem-4-2-dimensional-likelihood-surface" class="section level4">
<h4>Challenge problem 4: 2-dimensional likelihood surface</h4>
<p>Making “plug-in” confidence intervals looks nice on the plot (and is a useful, quick-and-dirty way to assess goodness-of-fit), but if we also want to visualize parameter uncertainty (and not just uncertainty arising from the stochastic component) we need to consider other plausble parameter values from our <em>n</em>-dimensional likelihood surface (with as many dimensions as there are free parameters).</p>
<ul>
<li><p><strong>Exercise 4a</strong>. Make a function called “MyxRicker_ci()” that takes any two parameters from your myxomatosis model as inputs (holding any remaining parameters constant) and visualizes how the likelihood changes across this 2D parameter space. What we’ll end up with will look something like Figure 6.7 in the Bolker book.</p>
<ul>
<li><strong>input</strong>:
<ul>
<li>LikFunc = a likelihood function for the Myxomatosis data (use the function you developed for Exercise 3a [NLL_myxRicker()])</li>
<li>params = vector of initial values for the params to estimate (length 3: <em>a</em> and <em>b</em> params from the Ricker model [see below], and the “shape” parameter of the Gamma distribution)</li>
<li>params_selected = character vector of length 2 (character strings) indicating which two parameters to visualize (holding the other one constant) (the vector should contain two of the following text strings: “a”, “b”, and “shape”)<br />
</li>
<li>data = a matrix of 2 columns and one row per observation. The first column should represent the days since infection, and the second column should represent the virus titer.</li>
<li>param1_lims = a vector of length 2 specifying the lower and upper bounds of the first parameter specified in “params_selected”</li>
<li>param2_lims = a vector of length 2 specifying the lower and upper bounds of the second parameter specified in “params_selected”</li>
</ul></li>
<li><strong>suggested algorithm</strong>:
<ul>
<li>Compute the MLE for the <em>a</em>, <em>b</em>, and <em>shape</em> parameters for the Ricker/Gamma model (use “optim()” with the likelhood function and the initial values in “params”)<br />
</li>
<li>Set the “constant/fixed” variable (the one not in “params_selected”) to its maximum likelihood estimate (which you just computed).<br />
</li>
<li>For each of the two parameters in “parameters_selected”, develop a vector of length 50 that ranges from the lower to the upper bound.</li>
<li>Loop over the two dimensions specified in “params_selected” (e.g., using a nested ‘for’ loop, iterating through both vectors computed in the previous step), characterizing all of parameter space from the lower to upper bounds of both parameters. For each “chunk/pixel” of parameter space, compute and store the likelhood (holding the third parameter at its MLE).<br />
</li>
<li>Use the “image()” function to visualize 2D parameter space, using “topo.colors” to define the colors.<br />
</li>
<li>Use the “contour()” function to draw contour lines at 2, 4, 6, 8, and 10 log-likelihood units from the MLE point.</li>
<li>For each parameter in “params_selected”, compute the approximate 95% “profile likelihood”, using the “rule of 2”. For each parameter, loop across possible parameter values and store the maximum log-likelihood value across all possible values of the other parameter. Record the range of parameter values that fall within approximately 2 log-likelihood units of the maximum log-likelihood.</li>
</ul></li>
<li><strong>return</strong>:
<ul>
<li>a data frame with two columns (for each parameter in “params_selected”) and two rows (representing the lower bound and the upper bound of the approximate 95% profile likelihood interval for each parameter (respectively).</li>
</ul></li>
</ul></li>
</ul>
<pre class="r"><code>#  test: Ricker params &quot;a&quot; and &quot;b&quot;
testab &lt;- MyxRicker_ci(LikFunc = NLL_myxRicker, params=c(a=2,b=0.2,shape=30), params_selected = c(&quot;a&quot;,&quot;b&quot;), data=myxdat[,-1], param1_lims= c(0.1,9),param2_lims=c(0.01,0.5))</code></pre>
<p><img src="LAB3_files/figure-html/test4a-1.png" width="672" /></p>
<pre class="r"><code># test: Ricker param &quot;a&quot; and gamma &quot;shape&quot; 
testas &lt;- MyxRicker_ci(LikFunc = NLL_myxRicker, params=c(a=2,b=0.2,shape=30), params_selected = c(&quot;a&quot;,&quot;shape&quot;), data=myxdat[,-1], param1_lims= c(1,8),param2_lims=c(10,150))</code></pre>
<p><img src="LAB3_files/figure-html/test4a-2.png" width="672" /></p>
<pre class="r"><code>testab</code></pre>
<pre><code>##       var1      var2
## 1 3.246465 0.1535354
## 2 3.875758 0.1881818</code></pre>
<pre class="r"><code>testas</code></pre>
<pre><code>##       var1     var2
## 1 3.474747  51.0101
## 2 3.686869 147.1717</code></pre>
</div>
<div id="optional-challenge-problem-5-profile-likelihood-using-optim" class="section level4">
<h4>Optional Challenge Problem 5: profile likelihood using “optim()”</h4>
<p>Construct <em>profile likelihood</em> confidence intervals for any one selected parameter. You will need to modify your likelihood functions and “optim()” commands to estimate only the parameters <em>other than</em> the one you are trying to get a CI for (because you’ll be fixing the selected parameter).</p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
