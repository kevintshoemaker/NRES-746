for(obs in 1:n.observations){
expected[obs] <- a*day[obs]*exp(-b*day[obs])  # Ricker
titer[obs] ~ dgamma(shape,shape/expected[obs])
titer.sim[obs] ~ dgamma(shape,shape/expected[obs])    # simulate new data (accounting for parameter uncertainty!
}
#############
# PRIORS
############
shape ~ dgamma(0.001,0.001)
a ~ dunif(0,10)
b ~ dunif(0,10)
#############
# SIMULATED DATA FOR VISUALIZATION
#############
for(day2 in 1:10){
expected.new[day2] <- a*day2*exp(-b*day2)  # Ricker
titer.new[day2] ~ dgamma(shape,shape/expected.new[day2])
}
#############
# DERIVED QUANTITIES
#############
for(obs in 1:n.observations){
SE_obs[obs] <- pow(titer[obs]-expected[obs],2)
SE_sim[obs] <- pow(titer.sim[obs]-expected[obs],2)
}
RMSE_obs <- sqrt(mean(SE_obs[]))
RMSE_sim <- sqrt(mean(SE_sim[]))
}
", file="BUGSmod_ricker1.txt")
myx.data.for.bugs <- list(
titer = Myx$titer,
day = Myx$day,
n.observations = length(Myx$titer)
)
init.vals.for.bugs <- function(){
list(
shape=runif(1,20,100),
a=runif(1,0.5,1.5),
b=runif(1,0.1,0.3)
)
}
params.to.store <- c("shape","a","b","RMSE_obs","RMSE_sim","titer.new")    # specify the parameters we want to get the posteriors for
jags.fit <- jags(data=myx.data.for.bugs,inits=init.vals.for.bugs,parameters.to.save=params.to.store,n.iter=50000,model.file="BUGSmod_ricker1.txt",n.chains = 3,n.burnin = 5000,n.thin = 20 )
jags.fit.mcmc <- as.mcmc(jags.fit)
posterior <- as.data.frame(jags.fit$BUGSoutput$sims.list)
plot(Myx$titer~Myx$day,xlim=c(0,10),ylim=c(0,15),type="n")
expected <- Ricker(mean(posterior$a),mean(posterior$b),1:10)
points(1:10,expected,type="l",col="red")
boxplot(x=as.list(posterior[,7:16]),at=1:10,add=T,boxwex=0.25,xaxt="n",range=0,border="red")
points(Myx$day,Myx$titer,cex=1.5,pch=20)
plot(posterior$RMSE_sim~posterior$RMSE_obs, main="posterior predictive check")
abline(0,1,col="red",lwd=2)
p.value=length(which(as.vector(jags.fit.mcmc[,"RMSE_sim"][[1]])>as.vector(jags.fit.mcmc[,"RMSE_obs"][[1]])))/length(as.vector(jags.fit.mcmc[,"RMSE_sim"][[1]]))
p.value
##########
# Summary statistics of a models "usefulness" (e.g., R-squared)
SS_res <- sum((Myx$titer-Ricker(MaxLik$par["a"],MaxLik$par["b"],Myx$day))^2)
SS_tot <- sum((Myx$titer-mean(Myx$titer))^2)
Rsquared <- 1-SS_res/SS_tot
cat("R-squared = ", Rsquared, "\n")
#########
# Fit the null likelihood model!
NegLogLik_null <- function(params){
-sum(dgamma(Myx$titer,shape=params[2],scale=params[1]/params[2],log = T))
}
init.params <- c(mean=7,shape=50)
MaxLik_null <- optim(par=init.params, fn=NegLogLik_null)
McFadden <- 1-(MaxLik$value/MaxLik_null$value)
cat("McFadden's R-squared = ", McFadden)
RMSE = sqrt(mean((Myx$titer-Ricker(MaxLik$par["a"],MaxLik$par["b"],Myx$day))^2))
cat("RMSE = ", RMSE, "\n")
####
# Collect new data that were not used in model fitting
newdata <- data.frame(
grade = 1,
day = c(2,3,4,5,6,7,8),
titer = c(4.4,7.2,6.8,5.9,9.1,8.3,8.8)
)
newdata
###########
# Validation #1
plot(Myx$titer~Myx$day,xlim=c(0,10),ylim=c(0,15),type="n",xlab="days",ylab="titer")
expected <- Ricker(MaxLik$par['a'],MaxLik$par['b'],1:10)
points(1:10,expected,type="l",col="green")
expected <- Ricker(MaxLik$par['a'],MaxLik$par['b'],1:10)
simdata <- array(0,dim=c(1000,10))
for(i in 1:1000){
simdata[i,] <- rgamma(10,shape=MaxLik$par['shape'],scale=expected/MaxLik$par['shape'])
}
upper <- apply(simdata,2,function(t) quantile(t,0.975))
lower <- apply(simdata,2,function(t) quantile(t,0.025))
points(1:10,upper,type="l",col="green",lty=2)
points(1:10,lower,type="l",col="green",lty=2)
boxplot(x=as.list(as.data.frame(simdata)),at=1:10,add=T,boxwex=0.25,xaxt="n",range=0,border="green")
points(newdata$day,newdata$titer,cex=1.5,pch=20,col="red")
points(Myx$day,Myx$titer,cex=1.5,pch=20,col="black")
legend("topleft",pch=c(20,20),col=c("black","red"),legend=c("original data","validation data"))
SS_res <- sum((newdata$titer-Ricker(MaxLik$par["a"],MaxLik$par["b"],newdata$day))^2)
SS_tot <- sum((newdata$titer-mean(newdata$titer))^2)
Rsquared_validation <- 1-SS_res/SS_tot
cat("R-squared = ", Rsquared, "\n")
expected <- Ricker(MaxLik$par["a"],MaxLik$par["b"],newdata$day)
McFadden_validation <- 1-(sum(dgamma(newdata$titer,shape=MaxLik$par["shape"],scale=expected/MaxLik$par["shape"], log = T))/sum(dgamma(newdata$titer,shape=MaxLik_null$par["shape"],scale=MaxLik_null$par["mean"]/MaxLik_null$par["shape"],log=T)))
cat("pseudo R-squared = ", McFadden_validation, "\n")
RMSE = sqrt(mean((newdata$titer-Ricker(MaxLik$par["a"],MaxLik$par["b"],newdata$day))^2))
cat("RMSE = ", RMSE, "\n")
#########
# Validation #2
newdata <- data.frame(        # imagine these are new observations...
grade = 1,
day = c(10,11,12,13,14,15,16),
titer = c(6.8,8.0,4.5,3.1,2.7,1.2,0.04)
)
newdata
plot(Myx$titer~Myx$day,xlim=c(0,20),ylim=c(0,15),type="n",xlab="days",ylab="titer")
expected <- Ricker(MaxLik$par['a'],MaxLik$par['b'],1:20)
points(1:20,expected,type="l",col="green")
expected <- Ricker(MaxLik$par['a'],MaxLik$par['b'],1:20)
simdata <- array(0,dim=c(1000,20))
for(i in 1:1000){
simdata[i,] <- rgamma(20,shape=MaxLik$par['shape'],scale=expected/MaxLik$par['shape'])
}
upper <- apply(simdata,2,function(t) quantile(t,0.975))
lower <- apply(simdata,2,function(t) quantile(t,0.025))
points(1:20,upper,type="l",col="green",lty=2)
points(1:20,lower,type="l",col="green",lty=2)
boxplot(x=as.list(as.data.frame(simdata)),at=1:20,add=T,boxwex=0.25,xaxt="n",range=0,border="green")
points(newdata$day,newdata$titer,cex=1.5,pch=20,col="red")
points(Myx$day,Myx$titer,cex=1.5,pch=20,col="black")
legend("topleft",pch=c(20,20),col=c("black","red"),legend=c("original data","new data"))
SS_res <- sum((newdata$titer-Ricker(MaxLik$par["a"],MaxLik$par["b"],newdata$day))^2)
SS_tot <- sum((newdata$titer-mean(newdata$titer))^2)
Rsquared_validation <- 1-SS_res/SS_tot
cat("R-squared = ", Rsquared_validation, "\n")
expected <- Ricker(MaxLik$par["a"],MaxLik$par["b"],newdata$day)
McFadden_validation <- 1-(sum(dgamma(newdata$titer,shape=MaxLik$par["shape"],scale=expected/MaxLik$par["shape"], log = T))/sum(dgamma(newdata$titer,shape=MaxLik_null$par["shape"],scale=MaxLik_null$par["mean"]/MaxLik_null$par["shape"],log=T)))
cat("pseudo R-squared = ", McFadden_validation, "\n")
RMSE = sqrt(mean((newdata$titer-Ricker(MaxLik$par["a"],MaxLik$par["b"],newdata$day))^2))
cat("RMSE = ", RMSE, "\n")
#####################
# CROSS-VALIDATION
#####################
#####
# PARTITION THE DATA
####
n.folds <- nrow(Myx)   # jackknife
Myx$fold <- sample(c(1:n.folds),size=nrow(Myx),replace=FALSE)
init.params <- c(a=1,b=0.2,shape=50)
Myx$pred_CV <- 0
for(i in 1:n.folds){
Myx2 <- subset(Myx,fold!=i)   # observations to use for fitting
newfit <- optim(par=init.params, fn=NegLogLik_func, data=Myx2)   # fit the model, leaving out this partition
ndx <- Myx$fold == i
Myx$pred_CV[ndx] <- Ricker(newfit$par['a'],newfit$par['b'],Myx$day[ndx])
}
Myx$pred_full <- Ricker(MaxLik$par['a'],MaxLik$par['b'],Myx$day)
Myx
RMSE_full <- sqrt(mean((Myx$titer-Myx$pred_full)^2))
RMSE_CV <- sqrt(mean((Myx$titer-Myx$pred_CV)^2))
RMSE_full
RMSE_CV
VarExplained_full = 1 - mean((Myx$titer-Myx$pred_full)^2)/mean((Myx$titer-mean(Myx$titer))^2)
VarExplained_CV = 1 - mean((Myx$titer-Myx$pred_CV)^2)/mean((Myx$titer-mean(Myx$titer))^2)
VarExplained_full
VarExplained_CV
model1 <- glm(Survived ~ Sex + Age + SibSp + Parch + Fare, data=titanic, family="binomial")    #logistic regression
##########
# Cross-validation: titanic disaster example!
titanic <- read.csv("titanic.csv",header=T)
head(titanic)
model1 <- glm(Survived ~ Sex + Age + SibSp + Parch + Fare, data=titanic, family="binomial")    #logistic regression
summary(model1)
titanic$Survived
?optim
params <- c(
int=1,
male = -3,
sibsp = 0,
parch = 0,
fare = 0.02
)
LikFunc <- function(params){
linear <- params['int'] +
params['male']*as.numeric(titanic$Sex=="male") +
params['sibsp']*titanic$SibSp +
params['parch']*titanic$Parch +
params['fare']*titanic$Fare
logitlinear <-  1/(1+exp(-(linear)))
-sum(dbinom(titanic$Survived,size=1,prob = logitlinear,log=T))
}
LikFunc(params)
MLE <- optim(fn=LikFunc,par = params,method="BFGS")
MLE$par
titanic$Sex
titanic$Age
titanic2 <- na.omit(titanic)
titanic2 <- na.omit(titanic)
model1 <- glm(Survived ~ Sex + Age + SibSp + Parch + Fare, data=titanic2, family="binomial")    #logistic regression
summary(model1)
params <- c(
int=1,
male = -3,
sibsp = 0,
parch = 0,
fare = 0.02
)
LikFunc <- function(params){
linear <- params['int'] +
params['male']*as.numeric(titanic2$Sex=="male") +
params['sibsp']*titanic2$SibSp +
params['parch']*titanic2$Parch +
params['fare']*titanic2$Fare
logitlinear <-  1/(1+exp(-(linear)))
-sum(dbinom(titanic2$Survived,size=1,prob = logitlinear,log=T))
}
LikFunc(params)
MLE <- optim(fn=LikFunc,par = params)
MLE$par
titanic2$SibSp
titanic2$Parch
type(titanic2$Parch)
class(titanic2$Parch)
titanic2$Fare
titanic2 <- na.omit(titanic)
model1 <- glm(Survived ~ Sex + scale(Age) + scale(SibSp) + scale(Parch) + scale(Fare), data=titanic2, family="binomial")    #logistic regression
summary(model1)
params <- c(
int=1,
male = -1,
age = 0,
sibsp = 0,
parch = 0,
fare = 0
)
LikFunc <- function(params){
linear <- params['int'] +
params['male']*as.numeric(titanic2$Sex=="male") +
params['age']*scale(titanic2$Age) +
params['sibsp']*scale(titanic2$SibSp) +
params['parch']*scale(titanic2$Parch) +
params['fare']*scale(titanic2$Fare)
logitlinear <-  1/(1+exp(-(linear)))
-sum(dbinom(titanic2$Survived,size=1,prob = logitlinear,log=T))
}
LikFunc(params)
MLE <- optim(fn=LikFunc,par = params)
MLE$par
###
plot(titanic$Survived~titanic$Fare,pch=16,xlab="FARE ($)",ylab="Survived!")
predict_df <- data.frame(
Sex = "male",
Age = mean(titanic$Age,na.rm=T),
SibSp = mean(titanic$SibSp),
Parch = mean(titanic$Parch),
Fare = seq(Fare_range[1],Fare_range[2])
)
SibSp_range <- range(titanic$SibSp)
Parch_range <- range(titanic$Parch)
Fare_range <- range(titanic$Fare)
Age_range <- range(titanic$Age,na.rm = T)
###
plot(titanic$Survived~titanic$Fare,pch=16,xlab="FARE ($)",ylab="Survived!")
predict_df <- data.frame(
Sex = "male",
Age = mean(titanic$Age,na.rm=T),
SibSp = mean(titanic$SibSp),
Parch = mean(titanic$Parch),
Fare = seq(Fare_range[1],Fare_range[2])
)
probSurv <- predict(model1,predict_df,type="response")
lines(seq(Fare_range[1],Fare_range[2]),probSurv)
###
predict_df <- data.frame(
Sex = c("male","female"),
Age = mean(titanic$Age,na.rm=T),
SibSp = mean(titanic$SibSp),
Parch = mean(titanic$Parch),
Fare = mean(titanic$Fare,na.rm=T)
)
tapply(titanic$Survived,titanic$Sex,mean)[2:1]
probSurv <- predict(model1,predict_df,type="response")
names(probSurv) <- c("male","female")
probSurv
###
plot(titanic$Survived~titanic$SibSp,pch=16,xlab="# of Siblings/spouses",ylab="Survived!")
predict_df <- data.frame(
Sex = "male",
Age = mean(titanic$Age,na.rm=T),
SibSp = seq(SibSp_range[1],SibSp_range[2],0.01),
Parch = mean(titanic$Parch),
Fare = mean(titanic$Fare,na.rm=T)
)
probSurv <- predict(model1,predict_df,type="response")
lines(seq(SibSp_range[1],SibSp_range[2],0.01),probSurv)
library(ROCR)
library(rms)
model1 <- glm(Survived ~ Sex + SibSp + Parch + Fare, data=titanic, family="binomial")
###################################
#################### CROSS VALIDATION CODE FOR BINARY RESPONSE
n.folds = 10       # set the number of "folds"
foldVector = rep(c(1:n.folds),times=floor(length(titanic$Survived)/9))[1:length(titanic$Survived)]
CV_df <- data.frame(
CVprediction = numeric(nrow(titanic)),      # make a data frame for storage
realprediction = 0,
realdata = 0
)
for(i in 1:n.folds){
fit_ndx <- which(foldVector!=i)
validate_ndx <- which(foldVector==i)
model <- glm(formula = Survived ~ Sex + SibSp + Parch + Fare, family = "binomial", data = titanic[fit_ndx,])
CV_df$CVprediction[validate_ndx] <-  plogis(predict(model,newdata=titanic[validate_ndx,]))
CV_df$realprediction[validate_ndx]  <-  plogis(predict(model1,newdata=titanic[validate_ndx,]))
CV_df$realdata[validate_ndx] <- titanic$Survived[validate_ndx]
}
CV_RMSE = sqrt(mean((CV_df$realdata - CV_df$CVprediction)^2))       # root mean squared error for holdout samples in 10-fold cross-validation
real_RMSE = sqrt(mean((CV_df$realdata - CV_df$realprediction)^2))  # root mean squared error for residuals from final model
# print RMSE statistics
cat("The RMSE for the model under cross-validation is: ", CV_RMSE, "\n")
cat("The RMSE for the model using all data for training is: ", real_RMSE, "\n")
par(mfrow=c(2,1))
pred <- prediction(CV_df$CVprediction,CV_df$realdata)     # for holdout samples in cross-validation
perf <- performance(pred,"tpr","fpr")
auc <- performance(pred,"auc")
plot(perf, main="Cross-validation")
text(.9,.1,paste("AUC = ",round(auc@y.values[[1]],2),sep=""))
pred <- prediction(CV_df$realprediction,CV_df$realdata)     # for final model
perf <- performance(pred,"tpr","fpr")
auc <- performance(pred,"auc")
plot(perf, main="All data")
text(.9,.1,paste("AUC = ",round(auc@y.values[[1]],2),sep=""))
CV_df$CVprediction[which(CV_df$CVprediction==1)] <- 0.9999       # ensure that all predictions are not exactly 0 or 1
CV_df$CVprediction[which(CV_df$CVprediction==0)] <- 0.0001
CV_df$realprediction[which(CV_df$realprediction==1)] <- 0.9999
CV_df$realprediction[which(CV_df$realprediction==0)] <- 0.0001
fit_deviance_CV <- mean(-2*(dbinom(CV_df$realdata,1,CV_df$CVprediction,log=T)-dbinom(CV_df$realdata,1,CV_df$realdata,log=T)))
fit_deviance_real <- mean(-2*(dbinom(CV_df$realdata,1,CV_df$realprediction,log=T)-dbinom(CV_df$realdata,1,CV_df$realdata,log=T)))
null_deviance <- mean(-2*(dbinom(CV_df$realdata,1,mean(CV_df$realdata),log=T)-dbinom(CV_df$realdata,1,CV_df$realdata,log=T)))
deviance_explained_CV <- (null_deviance-fit_deviance_CV)/null_deviance   # based on holdout samples
deviance_explained_real <- (null_deviance-fit_deviance_real)/null_deviance   # based on full model...
# print RMSE statistics
cat("The McFadden R2 for the model under cross-validation is: ", deviance_explained_CV, "\n")
cat("The McFadden R2 for the model using all data for training is: ", deviance_explained_real, "\n")
unlink('LECTURE9_cache', recursive = TRUE)
rmd2rscript <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- "echo"
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- !grepl(input, pattern = stringToFind2, perl = TRUE)   # is it hidden (echo=FALSE)
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript_labanswers <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- c("answer","test")
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- grepl(input, pattern = stringToFind2[1], perl = TRUE) | grepl(input, pattern = stringToFind2[2])
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript("LECTURE9.Rmd")
install.packages(c("AmesHousing", "h2o", "rattle", "rpart.plot", "rsample"))
rmd2rscript <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- "echo"
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- !grepl(input, pattern = stringToFind2, perl = TRUE)   # is it hidden (echo=FALSE)
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript_labanswers <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- c("answer","test")
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- grepl(input, pattern = stringToFind2[1], perl = TRUE) | grepl(input, pattern = stringToFind2[2])
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript_labanswers("LAB3.Rmd")
rmd2rscript_labanswers("LAB4.Rmd")
rmd2rscript_labanswers("LAB3.Rmd")
rmd2rscript_labanswers("LAB3.Rmd")
rmd2rscript_labanswers("LAB4.Rmd")
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
ztest <- z.test.algorithm(sample = my.sample, pop.mean=population.mean, pop.sd=population.sd )   # try to run the new function
z.test.algorithm <- function(sample, pop.mean, pop.sd){
#############
# Compute the sample statistic
#############
observed_mean <- mean(sample)
sample.size <- length(observed_mean)   # compute sample size
#################
# Generate SAMPLING DISTRIBUTION
#################
reps <- 1000                 # set the number of replicate samples
null_dist <- numeric(reps)       # initialize a storage structure for sampling distribution
for(i in 1:reps){            # for each replicate...
nullsamp <- rnorm(10,pop.mean,pop.sd)      # draw a sample assuming no treatment effect
null_dist[i] <- mean(nullsamp)           # compute and store the sample produced under the null hypothesis
}
more.extreme <- length(which(null_dist<=observed_mean))       # how many of these are more extreme than the sample statistic?
p_value <- more.extreme/reps
to_return <- list()   # initialize object to return
to_return$null_dist <- null_dist
to_return$p_value <- p_value
to_return$observed_mean <- observed_mean
return(to_return)
}
ztest <- z.test.algorithm(sample = my.sample, pop.mean=population.mean, pop.sd=population.sd )   # try to run the new function
boot_sample <- function(df,statfunc,n_samples,responsevar="Volume"){
indices <- c(1:nrow(df))
output <- matrix(NA,nrow=n_samples,ncol=ncol(df)-1)        # storage object- to store a single bootstrapped sample from the original data
for(i in 1:n_samples){              # for each bootstrap replicate:
boot_rows <- sample(indices,size=nrow(df),replace=T)         # randomly sample observations with replacement
newdf <- df[boot_rows,]                       # dataframe of bootstrapped observations
output[i,] <- statfunc(newdf,responsevar)                 # generate statistics from the bootstrapped sample  (e.g., compute Rsquared after regressing y on all possible x variables)
}
return(output)
}
boot <- boot_sample(df=trees,statfunc=Rsquared,n_samples=1000)   # generate test statistics (Rsquared vals) for 1000 bootstrap samples
Rsquared <- function(df,responsevar="Volume"){    # univariate models only- interaction and multiple regression not implemented here
response <- df[,responsevar]       # extract the response variable
names <- names(df)
rsq <- numeric(length(names))        # named storage vector
names(rsq) <- names(df)
rsq <- rsq[names(rsq)!=responsevar]           # assume that all columns that are not the response variable are possible predictor variables
for(i in names(rsq)){         # loop through predictors
predictor <- df[,i]                  # extract this predictor
model <- lm(response~predictor)       # regress response on predictor
rsq[i] <- summary(model)$r.square       # extract R-squared statistic
}
return(rsq)
}
stat <- Rsquared(trees,"Volume")
stat
boot_sample <- function(df,statfunc,n_samples,responsevar="Volume"){
indices <- c(1:nrow(df))
output <- matrix(NA,nrow=n_samples,ncol=ncol(df)-1)        # storage object- to store a single bootstrapped sample from the original data
for(i in 1:n_samples){              # for each bootstrap replicate:
boot_rows <- sample(indices,size=nrow(df),replace=T)         # randomly sample observations with replacement
newdf <- df[boot_rows,]                       # dataframe of bootstrapped observations
output[i,] <- statfunc(newdf,responsevar)                 # generate statistics from the bootstrapped sample  (e.g., compute Rsquared after regressing y on all possible x variables)
}
return(output)
}
boot <- boot_sample(df=trees,statfunc=Rsquared,n_samples=10,n_stats=2)       # generate test stats from lots of bootstrapped samples
boot <- boot_sample(df=trees,statfunc=Rsquared,n_samples=10)       # generate test stats from lots of bootstrapped samples
colnames(boot) <- names(stat)         # name the columns to recall which predictor variables they represent
boot
