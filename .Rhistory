par(mfrow=c(3,2))
plot(bvn,col=1:10000)
plot(bvn,type="l")
plot(ts(bvn[,1]))
plot(ts(bvn[,2]))
hist(bvn[,1],40)
hist(bvn[,2],40)
par(mfrow=c(1,1))
###############
# Metropolis-Hastings implementation of bivariate normal sampler...
library(mvtnorm)    # load a package that allows us to compute probability densities for mv normal distribution
metropolisHastings <- function (n, rho=0.98){    # an MCMC sampler implementation of a bivariate random number generator
mat <- matrix(ncol = 2, nrow = n)   # matrix for storing the random samples
x <- 0   # initial values for all parameters
y <- 0
prev <- dmvnorm(c(x,y),mean=c(0,0),sigma = matrix(c(1,rho,rho,1),ncol=2))   # probability density of the distribution at the starting values
mat[1, ] <- c(x, y)        # initialize the markov chain
counter <- 1
while(counter<=n) {
newx <- rnorm(1,x,0.5)     # make a jump. Note the symmetrical proposal distribution
newy <- rnorm(1,y,0.5)
newprob <- dmvnorm(c(newx,newy),sigma = matrix(c(1,rho,rho,1),ncol=2))    # assess whether the new jump is good!
ratio <- newprob/prev   # compute the ratio of probabilities at the old (jump from) and proposed (jump to) locations.
prob.accept <- min(1,ratio)     # decide the probability of accepting the new jump!
rand <- runif(1)
if(rand<=prob.accept){
x=newx;y=newy    # set x and y to the new location
mat[counter,] <- c(x,y)    # store this in the storage array
counter=counter+1
prev <- newprob    # get ready for the next iteration
}
}
return(mat)
}
###########
# Test the new M-H sampler
bvn<-metropolisHastings(10000,0.98)
par(mfrow=c(3,2))
plot(bvn,col=1:10000)
plot(bvn,type="l")
plot(ts(bvn[,1]))
plot(ts(bvn[,2]))
hist(bvn[,1],40)
hist(bvn[,2],40)
par(mfrow=c(1,1))
############
# MCMC implementation of the Myxomatosis example from the Bolker book
############
library(emdbook)
MyxDat <- MyxoTiter_sum
Myx <- subset(MyxDat,grade==1)
head(Myx)
###########
# Visualize the Myxomatosis data for the 100th time!
hist(Myx$titer,freq=FALSE)
#########
# ... and overlay a proposed data-generating model (gamma distribution)
hist(Myx$titer,freq=FALSE)
curve(dgamma(x,shape=40,scale=0.15),add=T,col="red")
##############
# define 2-D parameter space!
##############
shapevec <- seq(3,100,by=0.1)
scalevec <- seq(0.01,0.5,by=0.001)
##############
# define the likelihood surface across this grid within parameter space
##############
GammaLogLikelihoodFunction <- function(params){
sum(dgamma(Myx$titer,shape=params['shape'],scale=params['scale'],log=T))
}
surface2D <- matrix(nrow=length(shapevec),ncol=length(scalevec))   # initialize storage variable
newparams <- c(shape=50,scale=0.2)
for(i in 1:length(shapevec)){
newparams['shape'] <- shapevec[i]
for(j in 1:length(scalevec)){
newparams['scale'] <- scalevec[j]
surface2D[i,j] <- GammaLogLikelihoodFunction(newparams)
}
}
############
# Visualize the likelihood surface
############
image(x=shapevec,y=scalevec,z=surface2D,zlim=c(-1000,-30),col=topo.colors(12))
contour(x=shapevec,y=scalevec,z=surface2D,levels=c(-30,-40,-80,-500),add=T)
#############
# Function for returning the prior probability density for any point in parameter space
GammaPriorFunction <- function(params){
prior <- c(shape=NA,scale=NA)
prior['shape'] <- dgamma(params['shape'],shape=0.01,scale=100)
prior['scale'] <- dgamma(params['scale'],shape=0.001,scale=100)
# prior['shape'] <- dunif(params['shape'],3,100)        # alternative: could use uniform prior!
# prior['scale'] <- dunif(params['scale'],0.01,0.5)
return(prod(prior))
}
GammaLogPriorFunction <- function(params){
prior <- c(shape=NA,scale=NA)
prior['shape'] <- dgamma(params['shape'],shape=0.01,scale=100,log=T)
prior['scale'] <- dgamma(params['scale'],shape=0.001,scale=100,log=T)
# prior['shape'] <- dunif(params['shape'],3,100)        # alternative: could use uniform prior!
# prior['scale'] <- dunif(params['scale'],0.01,0.5)
return(sum(prior))
}
curve(dgamma(x,shape=0.01,scale=100),3,100)
params <- c(shape=40,scale=0.15)
params
GammaPriorFunction(params)
prior2D <- matrix(nrow=length(shapevec),ncol=length(scalevec))   # initialize storage variable
newparams <- c(shape=50,scale=0.2)
for(i in 1:length(shapevec)){
newparams['shape'] <- shapevec[i]
for(j in 1:length(scalevec)){
newparams['scale'] <- scalevec[j]
prior2D[i,j] <- GammaPriorFunction(newparams)
}
}
############
# Visualize the prior likelihood surface
############
image(x=shapevec,y=scalevec,z=prior2D,zlim=c(0.0000001,0.001),col=topo.colors(12))
#contour(x=shapevec,y=scalevec,z=prior2D,levels=c(-30,-40,-80,-500),add=T)
#############
# Function for returning the prior probability density for any point in parameter space
GammaPriorFunction <- function(params){
prior <- c(shape=NA,scale=NA)
prior['shape'] <- dgamma(params['shape'],shape=0.001,scale=1000)
prior['scale'] <- dgamma(params['scale'],shape=0.001,scale=1000)
# prior['shape'] <- dunif(params['shape'],3,100)        # alternative: could use uniform prior!
# prior['scale'] <- dunif(params['scale'],0.01,0.5)
return(prod(prior))
}
GammaLogPriorFunction <- function(params){
prior <- c(shape=NA,scale=NA)
prior['shape'] <- dgamma(params['shape'],shape=0.001,scale=1000,log=T)
prior['scale'] <- dgamma(params['scale'],shape=0.001,scale=1000,log=T)
# prior['shape'] <- dunif(params['shape'],3,100)        # alternative: could use uniform prior!
# prior['scale'] <- dunif(params['scale'],0.01,0.5)
return(sum(prior))
}
curve(dgamma(x,shape=0.001,scale=1000),3,100)
params <- c(shape=40,scale=0.15)
params
GammaPriorFunction(params)
prior2D <- matrix(nrow=length(shapevec),ncol=length(scalevec))   # initialize storage variable
newparams <- c(shape=50,scale=0.2)
for(i in 1:length(shapevec)){
newparams['shape'] <- shapevec[i]
for(j in 1:length(scalevec)){
newparams['scale'] <- scalevec[j]
prior2D[i,j] <- GammaPriorFunction(newparams)
}
}
############
# Visualize the prior likelihood surface
############
image(x=shapevec,y=scalevec,z=prior2D,zlim=c(0.0000001,0.001),col=topo.colors(12))
#contour(x=shapevec,y=scalevec,z=prior2D,levels=c(-30,-40,-80,-500),add=T)
image(x=shapevec,y=scalevec,z=prior2D,zlim=c(0.000000001,0.001),col=topo.colors(12))
############
# Function for computing the ratio of posterior densities between any two points in parameter space
PosteriorRatio <- function(oldguess,newguess){
oldLik <- max(1e-90,GammaLikelihoodFunction(oldguess))   # compute likelihood and prior density at old guess
oldPrior <- max(1e-90,GammaPriorFunction(oldguess))
newLik <- GammaLikelihoodFunction(newguess)             # compute likelihood and prior density at new guess
newPrior <- GammaPriorFunction(newguess)
return((newLik*newPrior)/(oldLik*oldPrior))          # compute ratio of weighted likelihoods
}
PosteriorRatio2 <- function(oldguess,newguess){
oldLogLik <- GammaLogLikelihoodFunction(oldguess)   # compute likelihood and prior density at old guess
oldLogPrior <- GammaLogPriorFunction(oldguess)
newLogLik <- GammaLogLikelihoodFunction(newguess)             # compute likelihood and prior density at new guess
newLogPrior <- GammaLogPriorFunction(newguess)
return(exp((newLogLik+newLogPrior)-(oldLogLik+oldLogPrior)))          # compute ratio of weighted likelihoods
}
oldguess <- params
newguess <- c(shape=39,scale=0.15)
PosteriorRatio(oldguess,newguess)
############
# Write a non-log-transformed likelihood function
GammaLikelihoodFunction <- function(params){
prod(dgamma(Myx$titer,shape=params['shape'],scale=params['scale'],log=F))
}
GammaLogLikelihoodFunction <- function(params){
sum(dgamma(Myx$titer,shape=params['shape'],scale=params['scale'],log=T))
}
params <- c(shape=40,scale=0.15)
params
GammaLikelihoodFunction(params)
GammaLogLikelihoodFunction(params)
############
# Function for computing the ratio of posterior densities between any two points in parameter space
PosteriorRatio <- function(oldguess,newguess){
oldLik <- max(1e-90,GammaLikelihoodFunction(oldguess))   # compute likelihood and prior density at old guess
oldPrior <- max(1e-90,GammaPriorFunction(oldguess))
newLik <- GammaLikelihoodFunction(newguess)             # compute likelihood and prior density at new guess
newPrior <- GammaPriorFunction(newguess)
return((newLik*newPrior)/(oldLik*oldPrior))          # compute ratio of weighted likelihoods
}
PosteriorRatio2 <- function(oldguess,newguess){
oldLogLik <- GammaLogLikelihoodFunction(oldguess)   # compute likelihood and prior density at old guess
oldLogPrior <- GammaLogPriorFunction(oldguess)
newLogLik <- GammaLogLikelihoodFunction(newguess)             # compute likelihood and prior density at new guess
newLogPrior <- GammaLogPriorFunction(newguess)
return(exp((newLogLik+newLogPrior)-(oldLogLik+oldLogPrior)))          # compute ratio of weighted likelihoods
}
oldguess <- params
newguess <- c(shape=39,scale=0.15)
PosteriorRatio(oldguess,newguess)
PosteriorRatio2(oldguess,newguess)
############
# Define proposal distribution for jumps in parameter space (use normal distribution)!
# function for making new guesses
newGuess <- function(oldguess){
sdshapejump <- 4
sdscalejump <- 0.07
jump <- c(shape=rnorm(1,mean=0,sd=sdshapejump),scale=rnorm(1,0,sdscalejump))
newguess <- abs(oldguess + jump)    # note: by taking the abs val to avoid negative numbers, our proposal jump probs are not strictly symmetrical, but this should not present a big issue in practice
return(newguess)
}
# set a new "guess" near to the original guess
newGuess(oldguess=params)
newGuess(oldguess=params)
newGuess(oldguess=params)
##########
# Set a starting point in parameter spacer
startingvals <- c(shape=75,scale=0.28)    # starting point for the algorithm
###########
# Try our new functions
newguess <- newGuess(startingvals)    # take a jump in parameter space
newguess
PosteriorRatio2(startingvals,newguess)   # difference in posterior ratio
###############
# Visualize the Metropolis-Hastings routine:
chain.length <- 11
oldguess <- startingvals
guesses <- matrix(0,nrow=chain.length,ncol=2)
colnames(guesses) <- names(startingvals)
guesses[1,] <- startingvals
counter <- 2
while(counter <= chain.length){
newguess <- newGuess(oldguess)
post.rat <- PosteriorRatio2(oldguess,newguess)
prob.accept <- min(1,post.rat)
rand <- runif(1)
if(rand<=prob.accept){
oldguess <- newguess
guesses[counter,] <- newguess
counter=counter+1
}
}
# visualize!
image(x=shapevec,y=scalevec,z=surface2D,zlim=c(-1000,-30),col=topo.colors(12))
contour(x=shapevec,y=scalevec,z=surface2D,levels=c(-30,-40,-80,-500),add=T)
lines(guesses,col="red")
##########
# Get more MCMC samples
chain.length <- 100
oldguess <- startingvals
guesses <- matrix(0,nrow=chain.length,ncol=2)
colnames(guesses) <- names(startingvals)
guesses[1,] <- startingvals
counter <- 2
while(counter <= chain.length){
newguess <- newGuess(oldguess)
post.rat <- PosteriorRatio2(oldguess,newguess)
prob.accept <- min(1,post.rat)
rand <- runif(1)
if(rand<=prob.accept){
oldguess <- newguess
guesses[counter,] <- newguess
counter=counter+1
}
}
# visualize!
image(x=shapevec,y=scalevec,z=surface2D,zlim=c(-1000,-30),col=topo.colors(12))
contour(x=shapevec,y=scalevec,z=surface2D,levels=c(-30,-40,-80,-500),add=T)
lines(guesses,col="red")
############
# And more...
chain.length <- 1000
oldguess <- startingvals
guesses <- matrix(0,nrow=chain.length,ncol=2)
colnames(guesses) <- names(startingvals)
guesses[1,] <- startingvals
counter <- 2
while(counter <= chain.length){
newguess <- newGuess(oldguess)
post.rat <- PosteriorRatio2(oldguess,newguess)
prob.accept <- min(1,post.rat)
rand <- runif(1)
if(rand<=prob.accept){
oldguess <- newguess
guesses[counter,] <- newguess
counter=counter+1
}
}
# visualize!
image(x=shapevec,y=scalevec,z=surface2D,zlim=c(-1000,-30),col=topo.colors(12))
contour(x=shapevec,y=scalevec,z=surface2D,levels=c(-30,-40,-80,-500),add=T)
lines(guesses,col="red")
############
# Remove "burn-in" (allow MCMC routine some time to get to the posterior)
burn.in <- 100
MCMCsamples <- guesses[-c(1:burn.in),]
chain.length=chain.length-burn.in
plot(1:chain.length,MCMCsamples[,'shape'],type="l",main="shape parameter",xlab="iteration",ylab="shape")
plot(1:chain.length,MCMCsamples[,'scale'],type="l",main="scale parameter",xlab="iteration",ylab="scale")
##########
# Try again- run for much longer
chain.length <- 20000
oldguess <- startingvals
guesses <- matrix(0,nrow=chain.length,ncol=2)
colnames(guesses) <- names(startingvals)
guesses[1,] <- startingvals
counter <- 2
while(counter <= chain.length){
newguess <- newGuess(oldguess)
post.rat <- PosteriorRatio2(oldguess,newguess)
prob.accept <- min(1,post.rat)
rand <- runif(1)
if(rand<=prob.accept){
oldguess <- newguess
guesses[counter,] <- newguess
counter=counter+1
}
}
# visualize!
image(x=shapevec,y=scalevec,z=surface2D,zlim=c(-1000,-30),col=topo.colors(12))
contour(x=shapevec,y=scalevec,z=surface2D,levels=c(-30,-40,-80,-500),add=T)
lines(guesses,col="red")
#############
# Use longer "burn-in"
burn.in <- 5000
MCMCsamples <- guesses[-c(1:burn.in),]
chain.length=chain.length-burn.in
plot(1:chain.length,MCMCsamples[,'shape'],type="l",main="shape parameter",xlab="iteration",ylab="shape")
plot(1:chain.length,MCMCsamples[,'scale'],type="l",main="scale parameter",xlab="iteration",ylab="scale")
##########
# "thin" the MCMC samples
thinnedMCMC <- MCMCsamples[seq(1,chain.length,by=5),]
plot(1:nrow(thinnedMCMC),thinnedMCMC[,'shape'],type="l",main="shape parameter",xlab="iteration",ylab="shape")
plot(1:nrow(thinnedMCMC),thinnedMCMC[,'scale'],type="l",main="scale parameter",xlab="iteration",ylab="scale")
# Visualize the posterior!
plot(density(thinnedMCMC[,'scale']),main="scale parameter",xlab="scale")
plot(density(thinnedMCMC[,'shape']),main="shape parameter",xlab="shape")
#########
# More visual posterior checks...
par(mfrow=c(3,2))
plot(thinnedMCMC,col=1:10000)
plot(thinnedMCMC,type="l")
plot(ts(thinnedMCMC[,1]))
plot(ts(thinnedMCMC[,2]))
hist(thinnedMCMC[,1],40)
hist(thinnedMCMC[,2],40)
par(mfrow=c(1,1))
unlink("LECTURE8_cache", recursive = TRUE)
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
############################################################
####                                                    ####
####  NRES 746, Lecture 8                               ####
####                                                    ####
####  Kevin Shoemaker                                   ####
####  University of Nevada, Reno                        ####
####                                                    ####
############################################################
############################################################
####  Model selection and multi-model inference         ####
############################################################
#######
# Load the balsam fir dataset (finally, no more rabbits and virus titers!)
library(emdbook)
data(FirDBHFec)
fir <- na.omit(FirDBHFec[,c("TOTCONES","DBH","WAVE_NON")])
fir$TOTCONES <- round(fir$TOTCONES)
head(fir)
plot(fir$TOTCONES ~ fir$DBH)   # fecundity as a function of tree size (diameter at breast height)
#########
# tree fecundity by size, categorized into two site-level categories: "wave" and "non-wave"
ndx <- fir$WAVE_NON=="w"   # logical vector indicating which observations were from "wave" sites
plot(fir$TOTCONES[ndx] ~ fir$DBH[ndx],xlab="DBH",ylab="Tot Cones")
points(fir$DBH[!ndx],fir$TOTCONES[!ndx],pch=4,col="red")
legend("topleft",pch=c(1,4),col=c("black","red"),legend=c("Wave","Non-wave"),bty="n")
########
# build likelihood function for the full model: CONES ~ negBINOM( a(wave)*DBH^b(wave), dispersion(wave))
NegBinomLik_full <- function(params){
wave.code <- as.numeric(fir$WAVE_NON)      # convert to ones and twos    # note: we are hard-coding the data into our likelhood function here!
a <- c(params[1],params[2])[wave.code]     # a parameters (two for wave and one for non-wave)
b <- c(params[3],params[4])[wave.code]      # b parameter (two for wave and one for non-wave)
k <- c(params[5],params[6])[wave.code]       # over-dispersion parameters (two for wave and one for non-wave)
expcones <- a*fir$DBH^b   # expected number of cones (deterministic component)
-sum(dnbinom(fir$TOTCONES,mu=expcones,size=k,log=TRUE))     # add stochastic component: full data likelihood
}
params <- c(a.n=1,a.w=1,b.n=1,b.w=1,k.n=1,k.w=1)
NegBinomLik_full(params)
#### Find the MLE
MLE_full <- optim(fn=NegBinomLik_full,par=c(a.n=1,a.w=1,b.n=1,b.w=1,k.n=1,k.w=1),method="L-BFGS-B")
MLE_full$par
MLE_full$value
########
# build likelihood function for a reduced model: CONES ~ negBINOM( a(wave)*DBH^b, dispersion(wave))
NegBinomLik_constb <- function(params){
wave.code <- as.numeric(fir$WAVE_NON)      # convert to ones and twos
a <- c(params[1],params[2])[wave.code]      # a parameters
b <- params[3]                              # b parameter (not a function of wave/nonwave)
k <- c(params[4],params[5])[wave.code]      # dispersion parameters
expcones <- a*fir$DBH^b
-sum(dnbinom(fir$TOTCONES,mu=expcones,size=k,log=TRUE))
}
params <- c(a.n=1,a.w=1,b=1,k.n=1,k.w=1)
NegBinomLik_constb(params)
### Find the MLE
MLE_constb <- optim(fn=NegBinomLik_constb,par=c(a.n=1,a.w=1,b=1,k.n=1,k.w=1),method="L-BFGS-B")
MLE_constb$par
MLE_constb$value
###########
# Bayes factor example
###########
##### take a basic binomial distribution with parameter p fixed at 0.5:
probs1 <- dbinom(0:10,10,0.5)
names(probs1) = 0:10
barplot(probs1,ylab="probability")
## Q: What is the *marginal likelihood* under this simple model for an observation of 2 mortalities out of 10?
## A:
dbinom(2,10,0.5)
###########
# Compute the marginal likelihood of observing 2 mortalities
# ?integrate
binom2 <- function(x) dbinom(x=2,size=10,prob=x)
marginal_likelihood <- integrate(f=binom2,0,1)$value    # use "integrate" function in R
marginal_likelihood  # equal to 0.0909 = 1/11
###########
# Compute the marginal likelihood of observing 3 mortalities
binom3 <- function(x) dbinom(x=3,size=10,prob=x)
marginal_likelihood <- integrate(f=binom3,0,1)$value    # use "integrate" function
marginal_likelihood   # equal to 0.0909 = 1/11
#########
# simulate data from the model across all possible values of the parameter "p"
lots=1000000
a_priori_data <- rbinom(lots,10,prob=rbeta(lots,1,1))   # no particular observation is favored
for_hist <- table(a_priori_data)/lots
barplot(for_hist,xlab="Potential Observation",ylab="Marginal likelihood")
###########
# Overlay the marginal likelihood of the simpler model, with p fixed at 0.5
probs2 <- rep(1/11,times=11)
names(probs2) = 0:10
barplot(probs2,ylab="probability",ylim=c(0,1))
probs1 <- dbinom(0:10,10,0.5)
names(probs1) = 0:10
barplot(probs1,ylab="probability",add=T,col="red",density=20)
############
# Finally, compute the bayes factor given that we observed 2 mortalities. Which model is better?
probs2 <- rep(1/11,times=11)
names(probs2) = 0:10
barplot(probs2,ylab="probability",ylim=c(0,1))
probs1 <- dbinom(0:10,10,0.5)
names(probs1) = 0:10
barplot(probs1,ylab="probability",add=T,col="red",density=20)
abline(v=3,col="green",lwd=4 )
sample(20,1:10)
sample(1:10,20)
sample(1:10,20,F)
sample(1:10,20,T)
unlink("LECTURE8_cache", recursive = TRUE)
rmd2rscript <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- "echo"
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- !grepl(input, pattern = stringToFind2, perl = TRUE)   # is it hidden (echo=FALSE)
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
# rmd2rscript_labanswers <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts: see NRESlabs folder!!
#   outfile <- gsub(".Rmd",".R",infile)
#   close( file( outfile, open="w" ) )   # clear output file
#   con1 <- file(infile,open="r")
#   con2 <- file(outfile,"w")
#   stringToFind <- "```{r*"
#   stringToFind2 <- c("answer","test","solution")
#   isrblock <- FALSE
#   #count=0
#   blocknum=0
#
#   while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
#     isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
#     showit <- grepl(input, pattern = stringToFind2[1], perl = TRUE) | grepl(input, pattern = stringToFind2[2])
#     if(isrblock){
#       blocknum=blocknum+1
#       while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
#         if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#         #count=count+1
#       }
#       isrblock=FALSE
#     }
#   }
#   closeAllConnections()
# }
rmd2rscript("LECTURE8.Rmd")
