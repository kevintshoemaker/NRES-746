CV_df$realprediction[validate_ndx]  <-  predict(thismod,data=titanic2[validate_ndx,],type="response")$predictions[,2]
CV_df$realdata[validate_ndx] <- titanic2$Survived[validate_ndx]
}
CV_df$realdata
fact=TRUE
if(fact){
CV_df$realdata=CV_df$realdata-1
}
CV_RMSE = sqrt(mean((CV_df$realdata - CV_df$CVprediction)^2))       # root mean squared error for holdout samples in 10-fold cross-validation
real_RMSE = sqrt(mean((CV_df$realdata - CV_df$realprediction)^2))  # root mean squared error for residuals from final model
cat("The RMSE for the model under cross-validation is: ", CV_RMSE, "\n")
cat("The RMSE for the model using all data for training is: ", real_RMSE, "\n")
library(ROCR)
library(rms)
par(mfrow=c(2,1))
pred <- prediction(CV_df$CVprediction,CV_df$realdata)     # for holdout samples in cross-validation
perf <- performance(pred,"tpr","fpr")
auc <- performance(pred,"auc")
plot(perf, main="Cross-validation")
text(.9,.1,paste("AUC = ",round(auc@y.values[[1]],2),sep=""))
library(ROCR)
library(rms)
par(mfrow=c(2,1))
pred <- prediction(CV_df$CVprediction,CV_df$realdata)     # for holdout samples in cross-validation
perf <- performance(pred,"tpr","fpr")
auc <- performance(pred,"auc")
plot(perf, main="Cross-validation")
text(.9,.1,paste("AUC = ",round(auc@y.values[[1]],2),sep=""))
pred <- prediction(CV_df$realprediction,CV_df$realdata)     # for final model
perf <- performance(pred,"tpr","fpr")
auc <- performance(pred,"auc")
plot(perf, main="All data")
text(.9,.1,paste("AUC = ",round(auc@y.values[[1]],2),sep=""))
CV_df$CVprediction[which(CV_df$CVprediction==1)] <- 0.9999       # ensure that all predictions are not exactly 0 or 1
CV_df$CVprediction[which(CV_df$CVprediction==0)] <- 0.0001
CV_df$realprediction[which(CV_df$realprediction==1)] <- 0.9999
CV_df$realprediction[which(CV_df$realprediction==0)] <- 0.0001
fit_deviance_CV <- mean(-2*(dbinom(CV_df$realdata,1,CV_df$CVprediction,log=T)-dbinom(CV_df$realdata,1,CV_df$realdata,log=T)))
fit_deviance_real <- mean(-2*(dbinom(CV_df$realdata,1,CV_df$realprediction,log=T)-dbinom(CV_df$realdata,1,CV_df$realdata,log=T)))
null_deviance <- mean(-2*(dbinom(CV_df$realdata,1,mean(CV_df$realdata),log=T)-dbinom(CV_df$realdata,1,CV_df$realdata,log=T)))
deviance_explained_CV <- (null_deviance-fit_deviance_CV)/null_deviance   # based on holdout samples
deviance_explained_real <- (null_deviance-fit_deviance_real)/null_deviance   # based on full model...
# print RMSE statistics
cat("The McFadden R2 for the model under cross-validation is: ", deviance_explained_CV, "\n")
cat("The McFadden R2 for the model using all data for training is: ", deviance_explained_real, "\n")
unlink("LECTURE10_cache", recursive = TRUE)
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
library(emdbook)    # this is the package provided to support the textbook!
?emdbook::MyxoTiter_sum
####################
# Explore Bolker's myxomatosis example
library(emdbook)    # this is the package provided to support the textbook!
MyxDat <- MyxoTiter_sum         # load Bolker's example data
Myx <- subset(MyxDat,grade==1)    # subset: least virulent
head(Myx)
###########
# Overlay a gamma distribution on the histogram
hist(Myx$titer,freq=FALSE)     # note the "freq=FALSE", which displays densities of observations, and therefore makes histograms comparable with probability density functions
curve(dgamma(x,shape=40,scale=0.15),add=T,col="red")
################
# Build likelihood function
GammaLikelihoodFunction <- function(params){           # only one argument (params)- the data are hard-coded here (this is often the case with simple likelihood functions)
sum(dgamma(Myx$titer,shape=params['shape'],scale=params['scale'],log=T))     # use params and data to compute likelihood
}
params <- c(40,0.15)
names(params) <- c("shape","scale")
params
GammaLikelihoodFunction(params)    # test the function!
################
# Build likelihood function
GammaLikelihoodFunction <- function(params){           # only one argument (params)- the data are hard-coded here (this is often the case with simple likelihood functions)
sum(dgamma(Myx$titer,shape=params['shape'],scale=params['scale'],log=T))     # use params and data to compute likelihood
}
params <- c(40,0.15)
names(params) <- c("shape","scale")
params
GammaLikelihoodFunction(params)    # test the function!
############
# USE R's 'OPTIM()' FUNCTION
############
############
# Optimize using R's built-in "optim()" function: find the maximum likelihood estimate
ctrl <- list(fnscale=-1)   # maximize rather than minimize!!
MLE <- optim(fn=GammaLikelihoodFunction,par=params,control=ctrl,method="BFGS")   # stop the warnings!
MLE$par
############
# USE R's 'OPTIM()' FUNCTION
############
############
# Optimize using R's built-in "optim()" function: find the maximum likelihood estimate
ctrl <- list(fnscale=-1)   # maximize rather than minimize!!
MLE <- optim(fn=GammaLikelihoodFunction,par=params,control=ctrl,method="BFGS")   # stop the warnings!
MLE$par
##############
# visualize the fit
hist(Myx$titer,freq=FALSE)
curve(dgamma(x,shape=MLE$par["shape"],scale=MLE$par["scale"]),add=T,col="red")
1^0
library(emdbook)
data(emdbook::MyxoTiter_sum)
data(MyxoTiter_sum)
emdbook::MyxoTiter_sum
emdbook::MyxoTiter_sum
myxdat = emdbook::MyxoTiter_sum
library(ggplot)
library(ggplot2)
ggplot(myxdat)
ggplot(myxdat)+
geom_point(aes(x=titer,y=day))
ggplot(myxdat)+
geom_point(aes(x=titer,y=day))+
facet_wrap(grade)
ggplot(myxdat,aes(x=titer,y=day))+
geom_point()+
facet_wrap(facets = grade,nrow = 2)
ggplot(myxdat,aes(x=titer,y=day))+
geom_point()+
facet_wrap(~grade,nrow = 2)
ggplot(myxdat,aes(x=day,y=titer))+
geom_point()+
facet_wrap(~grade,nrow = 2)
?emdbook::MyxoTiter_sum
curve(dgamma(x,shape=1,scale=1),0,10)
curve(dgamma(x,shape=.1,scale=10),0,10)
curve(dgamma(x,shape=10,scale=0.1),0,10)
curve(dgamma(x,shape=10,scale=0.2),0,10)
curve(dgamma(x,shape=10,scale=0.5),0,10)
curve(dgamma(x,shape=5,scale=1),0,10)
curve(dgamma(x,shape=2.5,scale=2),0,10)
curve(dgamma(x,shape=1,scale=5),0,10)
curve(dgamma(x,shape=2.5,scale=2),0,10)
curve(dgamma(x,shape=1,scale=5),0,10)
curve(dgamma(x,shape=.25,scale=20),0,10)
curve(dgamma(x,shape=.25,rate=1/20),0,10)
curve(dgamma(x,shape=.25,scale=20),0,10)
curve(dgamma(x,shape=.25,rate=1/20),0,10)
rmd2rscript <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- "echo"
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- !grepl(input, pattern = stringToFind2, perl = TRUE)   # is it hidden (echo=FALSE)
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
# rmd2rscript_labanswers <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts: see NRESlabs folder!!
#   outfile <- gsub(".Rmd",".R",infile)
#   close( file( outfile, open="w" ) )   # clear output file
#   con1 <- file(infile,open="r")
#   con2 <- file(outfile,"w")
#   stringToFind <- "```{r*"
#   stringToFind2 <- c("answer","test","solution")
#   isrblock <- FALSE
#   #count=0
#   blocknum=0
#
#   while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
#     isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
#     showit <- grepl(input, pattern = stringToFind2[1], perl = TRUE) | grepl(input, pattern = stringToFind2[2])
#     if(isrblock){
#       blocknum=blocknum+1
#       while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
#         if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#         #count=count+1
#       }
#       isrblock=FALSE
#     }
#   }
#   closeAllConnections()
# }
rmd2rscript("LAB3demo.Rmd")
rmd2rscript("LECTURE4.Rmd")
rmd2rscript("LECTURE5.Rmd")
#############
# SIMPLEX OPTIMIZATION METHOD!
#############
########
# set up an "initial" simplex
firstguess <- c(shape=70,scale=0.22)   # "user" first guess
simplex <- list()
# set up the initial simplex based on the first guess...
simplex[['vertex1']] <- firstguess + c(3,0.04)
simplex[['vertex2']] <- firstguess + c(-3,-0.04)
simplex[['vertex3']] <- firstguess + c(3,-0.04)
simplex
## first let's make a function to plot the simplex on a 2-D likelihood surface...
addSimplex <- function(simplex,col="green"){
temp <- as.data.frame(simplex)    # easier to work with data frame here
points(x=temp[1,c(1,2,3,1)], y=temp[2,c(1,2,3,1)],type="b",lwd=2,col=col)
}
image(x=shapevec,y=scalevec,z=surface2D,zlim=c(-1000,-30),col=topo.colors(12))
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
############################################################
####                                                    ####
####  NRES 746, Lecture 5                               ####
####                                                    ####
####  Kevin Shoemaker                                   ####
####  University of Nevada, Reno                        ####
####                                                    ####
############################################################
############################################################
####  Optimization                                      ####
####     Searching parameter space to identify the MLE  ####
####     While thwarting the curse of dimensionality    ####
############################################################
####################
# Explore Bolker's myxomatosis example
library(emdbook)    # this is the package provided to support the textbook!
MyxDat <- MyxoTiter_sum         # load Bolker's example data
Myx <- subset(MyxDat,grade==1)    # subset: most virulent
head(Myx)
hist(Myx$titer,freq=FALSE)    # distribution of virus loads
###########
# Overlay a gamma distribution on the histogram
hist(Myx$titer,freq=FALSE)     # note the "freq=FALSE", which displays densities of observations, and therefore makes histograms comparable with probability density functions
curve(dgamma(x,shape=40,scale=0.15),add=T,col="red")
################
# Build likelihood function
GammaLikelihoodFunction <- function(params){           # only one argument (params)- the data are hard-coded here (this is often the case with simple likelihood functions)
sum(dgamma(Myx$titer,shape=params['shape'],scale=params['scale'],log=T))     # use params and data to compute likelihood
}
params <- c(40,0.15)
names(params) <- c("shape","scale")
params
GammaLikelihoodFunction(params)    # test the function!
############
# USE R's 'OPTIM()' FUNCTION
############
############
# Optimize using R's built-in "optim()" function: find the maximum likelihood estimate
ctrl <- list(fnscale=-1)   # maximize rather than minimize!!
MLE <- optim(fn=GammaLikelihoodFunction,par=params,control=ctrl,method="BFGS")   # stop the warnings!
MLE$par
##############
# visualize the fit
hist(Myx$titer,freq=FALSE)
curve(dgamma(x,shape=MLE$par["shape"],scale=MLE$par["scale"]),add=T,col="red")
######################
# BRUTE FORCE ALTERNATIVE
######################
##############
# define 2-D parameter space!
##############
shapevec <- seq(10,100,by=0.1)        # divide parameter space into tiny increments
scalevec <- seq(0.01,0.3,by=0.001)
##############
# define the likelihood surface across this grid within parameter space
##############
surface2D <- matrix(nrow=length(shapevec),ncol=length(scalevec))   # initialize storage variable
newparams <- params
for(i in 1:length(shapevec)){
newparams['shape'] <- shapevec[i]
for(j in 1:length(scalevec)){
newparams['scale'] <- scalevec[j]
surface2D[i,j] <- GammaLikelihoodFunction(newparams)   # compute likelihood for every point in 2-d parameter space
}
}
############
# Visualize the likelihood surface
############
image(x=shapevec,y=scalevec,z=surface2D,zlim=c(-1000,-30),col=topo.colors(12))
contour(x=shapevec,y=scalevec,z=surface2D,levels=c(-30,-40,-80,-500),add=T)
############
# Find the MLE
############
ndx <- which(surface2D==max(surface2D),arr.ind=T)  # index of the max likelihood grid cell
shapevec[ndx[,1]]
scalevec[ndx[,2]]
MLE$par  # compare with the answer from "optim()"
###################
# Derivative-based optimization methods
###################
######
# function for estimating the slope of the likelihood surface at any point in parameter space....
## NOTE: even here I'm using a coarse, brute force method for estimating the first and second derivative of the likelihood function
params <- MLE$par
SlopeFunc <- function(shape_guess,tiny=0.001){
params['shape'] <- shape_guess
high <- GammaLikelihoodFunction(params+c(tiny,0))
low <- GammaLikelihoodFunction(params-c(tiny,0))
slope <- (high-low)/(tiny*2)
return(slope)
}
SlopeFunc(shape_guess=30)    #try it!
#########
# Visualize the slope of the likelihood function at different points in parameter space
shapevec <- seq(10,100,by=0.1)
##############
# define the likelihood surface
##############
surface1D <- numeric(length(shapevec))   # initialize storage variable
newparams <- params
for(i in 1:length(shapevec)){
newparams['shape'] <- shapevec[i]
surface1D[i] <- GammaLikelihoodFunction(newparams)
}
plot(surface1D~shapevec,type="l")
point <- GammaLikelihoodFunction(c(shape=30,MLE$par['scale']))
slope <- SlopeFunc(shape_guess=30)
lines(c(20,40),c(point-slope*10,point+slope*10),col="red")
########
# function for estimating the curvature of the likelihood function at any point in parameter space
params <- MLE$par
CurvatureFunc <- function(shape_guess,tiny=0.001){
params['shape'] <- shape_guess
high <- SlopeFunc(shape_guess+tiny)
low <- SlopeFunc(shape_guess-tiny)
curvature <- (high-low)/(tiny*2)   # how much the slope is changing in this region of the function
return(curvature)
}
CurvatureFunc(shape_guess=30)   # try it!
######
# First- visualize the gradient of the likelihood function
firstderiv <- numeric(length(shapevec))   # initialize storage variable
for(i in 1:length(shapevec)){
firstderiv[i] <- SlopeFunc(shapevec[i])
}
plot(firstderiv~shapevec,type="l")
abline(h=0,col="red")
#########
# Now we can perform a simple, derivative-based optimization!
### Pick "80" as the starting value
firstderiv <- SlopeFunc(80)           # evaluate the first and second derivatives
secondderiv <- CurvatureFunc(80)
firstderiv
secondderiv
#########
# Use this info to estimate the root
oldguess <- 80
newguess <- oldguess - firstderiv/secondderiv   # estimate the root (where first deriv is zero)
newguess
##########
# Repeat this process
oldguess <- 41.31
newguess <- oldguess - SlopeFunc(oldguess)/CurvatureFunc(oldguess)
newguess
#######
# again...
oldguess<-newguess
newguess <- oldguess - SlopeFunc(oldguess)/CurvatureFunc(oldguess)
newguess
#######
# again...
oldguess<-newguess
newguess <- oldguess - SlopeFunc(oldguess)/CurvatureFunc(oldguess)
newguess
#######
# again...
oldguess<-newguess
newguess <- oldguess - SlopeFunc(oldguess)/CurvatureFunc(oldguess)
newguess
##########
# Implement the Newton Method as a function!
NewtonMethod <- function(firstguess,tolerance=0.0000001){
deriv <- SlopeFunc(firstguess)
oldguess <- firstguess
counter <- 0
while(abs(deriv)>tolerance){
deriv <- SlopeFunc(oldguess)
newguess <- oldguess - deriv/CurvatureFunc(oldguess)
oldguess<-newguess
counter=counter+1
}
mle <- list()
mle$estimate <- newguess
mle$likelihood <- GammaLikelihoodFunction(c(shape=newguess,MLE$par['scale']))
mle$iterations <- counter
return(mle)
}
newMLE <- NewtonMethod(firstguess=80)
newMLE
#############
# SIMPLEX OPTIMIZATION METHOD!
#############
########
# set up an "initial" simplex
firstguess <- c(shape=70,scale=0.22)   # "user" first guess
simplex <- list()
# set up the initial simplex based on the first guess...
simplex[['vertex1']] <- firstguess + c(3,0.04)
simplex[['vertex2']] <- firstguess + c(-3,-0.04)
simplex[['vertex3']] <- firstguess + c(3,-0.04)
simplex
## first let's make a function to plot the simplex on a 2-D likelihood surface...
addSimplex <- function(simplex,col="green"){
temp <- as.data.frame(simplex)    # easier to work with data frame here
points(x=temp[1,c(1,2,3,1)], y=temp[2,c(1,2,3,1)],type="b",lwd=2,col=col)
}
image(x=shapevec,y=scalevec,z=surface2D,zlim=c(-1000,-30),col=topo.colors(12))
contour(x=shapevec,y=scalevec,z=surface2D,levels=c(-30,-40,-80,-500),add=T)
addSimplex(simplex)
########
# Evaluate log-likelihood at each vertex of the simplex
SimplexLik <- function(simplex){
newvec <- unlist(lapply(simplex,GammaLikelihoodFunction))   # note use of apply instead of for loop...
return(newvec)
}
SimplexLik(simplex)
#####
# Helper Functions
#####
## this function reflects the worst vertex across the remaining vector
ReflectIt <- function(oldsimplex,WorstVertex){
## re-arrange simplex- worst must be first
worstndx <- which(names(oldsimplex)==WorstVertex)
otherndx <- c(1:3)[-worstndx]
newndx <- c(worstndx,otherndx)
## translate so that vertex 1 is the origin (0,0)
oldsimplex <- oldsimplex[newndx]
translate <- oldsimplex[[1]]
newsimplex <- list(oldsimplex[[1]]-translate,oldsimplex[[2]]-translate,oldsimplex[[3]]-translate)
reflected <- c(newsimplex[[2]]["shape"]+newsimplex[[3]]["shape"],newsimplex[[2]]["scale"]+newsimplex[[3]]["scale"])
names(reflected) <- c("shape","scale")
## translate back to the likelihood surface
newsimplex[[1]] <- reflected
newsimplex <- list(newsimplex[[1]]+translate,newsimplex[[2]]+translate,newsimplex[[3]]+translate)
## return the new simplex
names(newsimplex) <- names(oldsimplex)
## generate some alternative jumps (or "oozes"!)...
oldpoint <- oldsimplex[[1]]
newpoint <- newsimplex[[1]]
newpoint2 <- newpoint-oldpoint
double <- newpoint2 * 3
half <- newpoint2 * 0.24
alternates <- list()
alternates$reflected <- newsimplex
alternates$double <- newsimplex
alternates$half <- newsimplex
alternates$double[[1]] <- double + oldpoint
alternates$half[[1]] <- half + oldpoint
return(alternates)
}
ShrinkIt <- function(oldsimplex,BestVertex){
newsimplex <- oldsimplex
## indices...
bestndx <- which(names(oldsimplex)==BestVertex)
otherndx <- c(1:3)[-bestndx]
translate <- oldsimplex[[bestndx]]
i=2
for(i in otherndx){
newvector <- oldsimplex[[i]]-translate
shrinkvector <- newvector * 0.5
newsimplex[[i]] <- shrinkvector + translate
}
return(newsimplex)
}
MoveTheSimplex <- function(oldsimplex){     # (incomplete) nelder-mead algorithm
newsimplex <- oldsimplex  #
# Start by identifying the *worst* vertex (the one with the lowest likelihood)
VertexLik <- SimplexLik(newsimplex)
WorstLik <- min(VertexLik)
BestLik <- max(VertexLik)
WorstVertex <- names(VertexLik[which.min(VertexLik)])    # identify vertex with lowest likelihood
candidates <- ReflectIt(oldsimplex=newsimplex,WorstVertex)      # reflect across the remaining edge
CandidateLik <- sapply(candidates,SimplexLik)                          # re-evaluate likelihood at the vertices...
CandidateLik <- apply(CandidateLik,c(1,2), function(t) ifelse(is.nan(t),-99999,t))
bestCandidate <- names(which.max(CandidateLik[WorstVertex,]))
bestCandidateLik <- CandidateLik[WorstVertex,bestCandidate]
if(CandidateLik[WorstVertex,"reflected"]>=WorstLik){
if(CandidateLik[WorstVertex,"reflected"]>BestLik){
if(CandidateLik[WorstVertex,"double"]>CandidateLik[WorstVertex,"reflected"]){
newsimplex <- candidates[["double"]]    # expansion
}else{
newsimplex <- candidates[["reflected"]]
}
}else if(CandidateLik[WorstVertex,"half"]>CandidateLik[WorstVertex,"reflected"]){   # contraction
newsimplex <- candidates[["half"]]
}else{
newsimplex <- candidates[["reflected"]]
}
}else{
BestVertex <- names(VertexLik[which.max(VertexLik)])
newsimplex <- ShrinkIt(oldsimplex,BestVertex)
}
return(newsimplex)
}
# image(x=shapevec,y=scalevec,z=surface2D,zlim=c(-1000,-30),col=topo.colors(12))
# contour(x=shapevec,y=scalevec,z=surface2D,levels=c(-30,-40,-80,-500),add=T)
# addSimplex(oldsimplex,col="red")
# addSimplex(candidates$reflected,col="green")
# addSimplex(candidates$half,col="green")
###########
# Visualize the simplex
oldsimplex <- simplex
newsimplex <- MoveTheSimplex(oldsimplex)
image(x=shapevec,y=scalevec,z=surface2D,zlim=c(-1000,-30),col=topo.colors(12))
contour(x=shapevec,y=scalevec,z=surface2D,levels=c(-30,-40,-80,-500),add=T)
addSimplex(oldsimplex,col="red")
addSimplex(newsimplex)
############
# Make another move
oldsimplex <- newsimplex
newsimplex <- MoveTheSimplex(oldsimplex)
image(x=shapevec,y=scalevec,z=surface2D,zlim=c(-1000,-30),col=topo.colors(12))
contour(x=shapevec,y=scalevec,z=surface2D,levels=c(-30,-40,-80,-500),add=T)
addSimplex(oldsimplex,col="red")
addSimplex(newsimplex)
