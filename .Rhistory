rmd2rscript_labanswers <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- c("answer","test")
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- grepl(input, pattern = stringToFind2[1], perl = TRUE) | grepl(input, pattern = stringToFind2[2])
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript("LECTURE2.Rmd")
unlink("LECTURE3_cache", recursive = TRUE)
rmd2rscript <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- "echo"
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- !grepl(input, pattern = stringToFind2, perl = TRUE)   # is it hidden (echo=FALSE)
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript_labanswers <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- c("answer","test")
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- grepl(input, pattern = stringToFind2[1], perl = TRUE) | grepl(input, pattern = stringToFind2[2])
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript("LECTURE3.Rmd")
rmd2rscript("LECTURE3.Rmd")
rmd2rscript("LECTURE4.Rmd")
rmarkdown::render('index.Rmd', 'word_document')
rmarkdown::render('schedule.Rmd', 'word_document')
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
rmarkdown::render('index.Rmd',rmarkdown::pdf_document())
rmarkdown::render('schedule.Rmd',rmarkdown::pdf_document())
rmarkdown::render('INTRO.Rmd',rmarkdown::pdf_document())
rmd2rscript <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- "echo"
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- !grepl(input, pattern = stringToFind2, perl = TRUE)   # is it hidden (echo=FALSE)
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript_labanswers <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- c("answer","test")
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- grepl(input, pattern = stringToFind2[1], perl = TRUE) | grepl(input, pattern = stringToFind2[2])
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript("LECTURE3.Rmd")
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
###############
# Demo: using data simulation to make inferences
data(mtcars)    # use the 'mtcars' data set as an example
# ?mtcars
plot(mpg~disp, data = mtcars, las = 1, pch = 16, xlab = "Displacement (cu. in.)", ylab = "Miles/Gallon")   # visualize the relationship
#########
# try an exponential model
Deterministic_component <- function(xvals,a,b){
yexp <- a*exp(b*xvals)        # deterministic exponential decline (assuming b is negative)
return(yexp)
}
DataGenerator_exp <- function(xvals,params){
yexp <- Deterministic_component(xvals,params$a,params$b)  # get signal
yvals <- rnorm(length(yexp),yexp,sqrt(params$c))     # add noise (normally distributed)
return(yvals)
}
###########
# generate data under an assumed process model
xvals=mtcars$disp    # xvals same as data (there is no random component here- we can't really "sample" x values)
params <- list()
params$a=30             # set model parameters arbitrarily (eyeballing to the data) (see Bolker book)
params$b=-0.005   # = 1/200
params$c=5
yvals <- DataGenerator_exp(xvals,params)
plot(yvals~xvals)      # plot the simulated data
##########
# assess goodness-of-fit of a known data-generating model
PlotRangeOfPlausibleData <- function(xvals,params,reps){
samplesize <- length(xvals)
results <- array(0,dim=c(samplesize,reps))   # storage array for results
for(i in 1:reps){
yvals <- DataGenerator_exp(xvals,params)
results[,i] <- yvals
}
# now make a boxplot of the results
boxplot(lapply(1:nrow(results), function(i) results[i,]),at=xvals, xaxt="n",main="Plausible data under this model",ylab="mpg",xlab="Displacement",boxwex=6)
cleanseq <- (seq(0,max(round(xvals/100)),length=(max(round(xvals/100)))+1))*100
axis(1,at=cleanseq,labels = cleanseq)    # label the x axis properly
}
reps <- 1000    # number of replicate datasets to generate
PlotRangeOfPlausibleData(xvals,params,reps)    # run the function to visualize the range of data that could be produced under this model
############
# finally, overlay the real data to evaluate goodness of fit!
real_yvals <- mtcars$mpg
PlotRangeOfPlausibleData(xvals,params,reps)
points(xvals,real_yvals,pch=20,cex=3,col="green")
##########
# now change the parameters and see if the data fit to the model
params$a=40       # was 30
params$b=-0.001   # was 0.005
PlotRangeOfPlausibleData(xvals,params,reps)
points(xvals,real_yvals,pch=20,cex=3,col="green")    # overlay the real data
#######
# try again- select a new set of parameters
params$a=33       # was 40
params$b=-0.004   # was 0.001
params$c=0.5
PlotRangeOfPlausibleData(xvals,params,reps)
points(xvals,real_yvals,pch=20,cex=3,col="green")    # overlay the real data
DT <- data.table(V1=c(1L,2L),
V2=LETTERS[1:3],
V3=round(rnorm(4),4),
V4=1:12)
library(data.table)
DT <- data.table(V1=c(1L,2L),
V2=LETTERS[1:3],
V3=round(rnorm(4),4),
V4=1:12)
DT
DT[,sum(V1)]
DT[,.(sum(V1),sd(V3))]
DT[,.(Aggregate=sum(V1),
Sd.V3=sd(V3))]
DT[,.(V1,Sd.V3=sd(V3))]
DT[,.(print(V2),
plot(V3),
NULL)]
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
############################################################
####                                                    ####
####  NRES 746, Lecture 3                               ####
####                                                    ####
####  Kevin Shoemaker                                   ####
####  University of Nevada, Reno                        ####
####                                                    ####
############################################################
############################################################
####  The virtual ecologist                             ####
####     Building data simulation models                ####
############################################################
#############
# Short exercise:
# Generate 50 samples from Normal(mean=10,sd=5)
# Generate 1000 samples from Poisson(mean=50)
# Generate 10 samples from Beta(shape1=0.1,shape2=0.1)
# Try some other distributions and parameters.  NOTE: you can visualize probability densities easily using the "curve" function:
curve(dnorm(x,0,2),-10,10)
# What happens when you try to use a discrete distribution?
############
# SIMULATE DATA GENERATION: decompose into deterministic and stochastic components
##########
# Deterministic component: define function for transforming a predictor variable into an expected response (linear regression)
# Arguments:
# x: vector of covariate values
# a: the intercept of a linear relationship mapping the covariate to an expected response
# b: the slope of a linear relationship mapping the covariate to an expected response
deterministic_component <- function(x,a,b){
linear <- a + b*x   # specify a deterministic, linear functional form
return(linear)
}
xvals = seq(0,100,10)  # define the values of a hypothetical predictor variable (e.g., tree girth)
expected_vals <- deterministic_component(xvals,175,-1.5)   # use the deterministic component to determine the expected response (e.g., tree volume)
expected_vals
plot(xvals,expected_vals)   # plot out the relationship
# plot(xvals,expected_vals,type="l")    # alternatively, plot as a line
##########
# Stochastic component: define a function for transforming an expected (deterministic) response and adding a layer of "noise" on top!
# Arguments:
# x: vector of expected responses
# variance: variance of the "noise" component of your data simulation model
stochastic_component <- function(x,variance){
sd <- sqrt(variance)       # convert variance to standard deviation
stochvals <- rnorm(length(x),x,sd)       # add a layer of "noise" on top of the expected response values
return(stochvals)
}
# alternative: add the "residuals" onto the expected values.
# stochastic_component <- function(x,variance){
#   sd <- sqrt(variance)       # convert variance to standard deviation
#   stochvals <- rnorm(length(x),0,sd)       # generate the 'residuals'
#   return(x+stochvals)             # add a layer of "noise" on top of the expected response values
# }
### Simulate stochastic data!!
sim_vals <- stochastic_component(expected_vals,variance=500)   # try it- run the function to add noise to your expected values.
plot(xvals,sim_vals)     # plot it- it should look much more "noisy" now!
# ALTERNATIVELY:
sim_vals <- stochastic_component(deterministic_component(xvals,175,-1.5),500)    # stochastic "shell" surrounds a deterministic "core"
############
# Goodness-of-fit test!
# Does the data fall into the range of plausble data produced by this fully specified model?
############
# Imagine you have the following "real" data (e.g., tree volumes).
realdata <- data.frame(Volume=c(125,50,90,110,80,75,100,400,350,290,350),Girth=xvals)
plot(realdata$Girth,realdata$Volume)
#############
# Let's simulate many datasets from our hypothesized data generating model (intercept=10,slope=4,variance=1000):
reps <- 1000    # specify number of replicate datasets to generate
samplesize <- nrow(realdata)    # define the number of data points we should generate for each simulation "experiment"
simresults <- array(0,dim=c(samplesize,reps))   # initialize a storage array for results
for(i in 1:reps){       # for each independent simulation "experiment":
exp_vals <- deterministic_component(realdata$Girth,a=10,b=4)          # simulate the expected tree volumes for each measured girth value
sim_vals <- stochastic_component(exp_vals,1000)  # add stochastic noise
simresults[,i] <- sim_vals   # store the simulated data for later
}
# now make a boxplot of the results
boxplot(t(simresults),xaxt="n")    # (repeat) make a boxplot of the simulation results
axis(1,at=c(1:samplesize),labels=realdata$Girth)                          # add x axis labels
#########
# Now overlay the "real" data
# how well does the model fit the data?
boxplot(lapply(1:nrow(simresults), function(i) simresults[i,]),xaxt="n")    # (repeat) make a boxplot of the simulation results
axis(1,at=c(1:samplesize),labels=realdata$Girth)                          # add x axis labels
points(c(1:samplesize),realdata$Volume,pch=20,cex=3,col="red",xaxt="n")     # this time, overlay the "real" data
#############
# Let's simulate many datasets from our hypothesized data generating model (intercept=100,slope=0,variance=75000):
reps <- 1000    # specify number of replicate datasets to generate
samplesize <- nrow(realdata)    # define the number of data points we should generate for each simulation "experiment"
simresults <- array(0,dim=c(samplesize,reps))   # initialize a storage array for results
for(i in 1:reps){       # for each independent simulation "experiment":
exp_vals <- deterministic_component(realdata$Girth,a=100,b=0)          # simulate the expected tree volumes for each measured girth value
sim_vals <- stochastic_component(exp_vals,75000)  # add stochastic noise
simresults[,i] <- sim_vals   # store the simulated data for later
}
# now make a boxplot of the results
boxplot(lapply(1:nrow(simresults), function(i) simresults[i,]),xaxt="n")    # (repeat) make a boxplot of the simulation results
axis(1,at=c(1:samplesize),labels=realdata$Girth)                          # add x axis labels
points(c(1:samplesize),realdata$Volume,pch=20,cex=3,col="red",xaxt="n")     # this time, overlay the "real" data
unlink("LECTURE3_cache", recursive = TRUE)
#############
# Let's simulate many datasets from our hypothesized data generating model (intercept=100,slope=0,variance=75000):
reps <- 1000    # specify number of replicate datasets to generate
samplesize <- nrow(realdata)    # define the number of data points we should generate for each simulation "experiment"
simresults <- array(0,dim=c(samplesize,reps))   # initialize a storage array for results
for(i in 1:reps){       # for each independent simulation "experiment":
exp_vals <- deterministic_component(realdata$Girth,a=100,b=0)          # simulate the expected tree volumes for each measured girth value
sim_vals <- stochastic_component(exp_vals,200000)  # add stochastic noise
simresults[,i] <- sim_vals   # store the simulated data for later
}
# now make a boxplot of the results
boxplot(lapply(1:nrow(simresults), function(i) simresults[i,]),xaxt="n")    # (repeat) make a boxplot of the simulation results
axis(1,at=c(1:samplesize),labels=realdata$Girth)                          # add x axis labels
points(c(1:samplesize),realdata$Volume,pch=20,cex=3,col="red",xaxt="n")     # this time, overlay the "real" data
0.25^(1/25)
0.75^(1/25)
rmd2rscript <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- "echo"
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- !grepl(input, pattern = stringToFind2, perl = TRUE)   # is it hidden (echo=FALSE)
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript_labanswers <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- c("answer","test")
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- grepl(input, pattern = stringToFind2[1], perl = TRUE) | grepl(input, pattern = stringToFind2[2])
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript("LECTURE3.Rmd")
rmd2rscript("LECTURE4.Rmd")
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
############################################################
####                                                    ####
####  NRES 746, Lecture 4                               ####
####                                                    ####
####  Kevin Shoemaker                                   ####
####  University of Nevada, Reno                        ####
####                                                    ####
############################################################
############################################################
####  Likelihood                                        ####
####     Assessing the probability of the data          ####
####     under a known data-generating model            ####
############################################################
###############
# Demo: using data simulation to make inferences
data(mtcars)    # use the 'mtcars' data set as an example
# ?mtcars
plot(mpg~disp, data = mtcars, las = 1, pch = 16, xlab = "Displacement (cu. in.)", ylab = "Miles/Gallon")   # visualize the relationship
#########
# try an exponential model
Deterministic_component <- function(xvals,a,b){
yexp <- a*exp(b*xvals)        # deterministic exponential decline (assuming b is negative)
return(yexp)
}
DataGenerator_exp <- function(xvals,params){
yexp <- Deterministic_component(xvals,params$a,params$b)  # get signal
yvals <- rnorm(length(yexp),yexp,sqrt(params$c))     # add noise (normally distributed)
return(yvals)
}
###########
# generate data under an assumed process model
xvals=mtcars$disp    # xvals same as data (there is no random component here- we can't really "sample" x values)
params <- list()
params$a=30             # set model parameters arbitrarily (eyeballing to the data) (see Bolker book)
params$b=-0.005   # = 1/200
params$c=5
yvals <- DataGenerator_exp(xvals,params)
plot(yvals~xvals)      # plot the simulated data
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
############################################################
####                                                    ####
####  NRES 746, Lecture 4                               ####
####                                                    ####
####  Kevin Shoemaker                                   ####
####  University of Nevada, Reno                        ####
####                                                    ####
############################################################
############################################################
####  Likelihood                                        ####
####     Assessing the probability of the data          ####
####     under a known data-generating model            ####
############################################################
###############
# Demo: using data simulation to make inferences
data(mtcars)    # use the 'mtcars' data set as an example
# ?mtcars
plot(mpg~disp, data = mtcars, las = 1, pch = 16, xlab = "Displacement (cu. in.)", ylab = "Miles/Gallon")   # visualize the relationship
#########
# try an exponential model
Deterministic_component <- function(xvals,a,b){
yexp <- a*exp(b*xvals)        # deterministic exponential decline (assuming b is negative)
return(yexp)
}
DataGenerator_exp <- function(xvals,params){
yexp <- Deterministic_component(xvals,params$a,params$b)  # get signal
yvals <- rnorm(length(yexp),yexp,sqrt(params$c))     # add noise (normally distributed)
return(yvals)
}
###########
# generate data under an assumed process model
xvals=mtcars$disp    # xvals same as data (there is no random component here- we can't really "sample" x values)
params <- list()
params$a=30             # set model parameters arbitrarily (eyeballing to the data) (see Bolker book)
params$b=-0.005   # = 1/200
params$c=5
yvals <- DataGenerator_exp(xvals,params)
plot(yvals~xvals)      # plot the simulated data
xvals
params
reps
reps=100
samplesize <- length(xvals)
results <- array(0,dim=c(samplesize,reps))   # storage array for results
for(i in 1:reps){
yvals <- DataGenerator_exp(xvals,params)
results[,i] <- yvals
}
results
lapply(1:nrow(results), function(i) results[i,])
# now make a boxplot of the results
boxplot(lapply(1:nrow(results), function(i) results[i,]),at=xvals, xaxt="n",main="Plausible data under this model",ylab="mpg",xlab="Displacement",boxwex=6)
?boxplot
cleanseq <- (seq(0,max(round(xvals/100)),length=(max(round(xvals/100)))+1))*100
cleanseq
axis(1,at=cleanseq,labels = cleanseq)    # label the x axis properly
##########
# assess goodness-of-fit of a known data-generating model
PlotRangeOfPlausibleData <- function(xvals,params,reps=100){
samplesize <- length(xvals)
results <- array(0,dim=c(samplesize,reps))   # storage array for results
for(i in 1:reps){
yvals <- DataGenerator_exp(xvals,params)
results[,i] <- yvals
}
# now make a boxplot of the results
boxplot(lapply(1:nrow(results), function(i) results[i,]),at=xvals, xaxt="n",main="Plausible data under this model",ylab="mpg",xlab="Displacement",boxwex=6)
cleanseq <- (seq(0,max(round(xvals/100)),length=(max(round(xvals/100)))+1))*100
axis(1,at=cleanseq,labels = cleanseq)    # label the x axis properly
}
reps <- 1000    # number of replicate datasets to generate
PlotRangeOfPlausibleData(xvals,params,reps)    # run the function to visualize the range of data that could be produced under this model
############
# finally, overlay the real data to evaluate goodness of fit!
real_yvals <- mtcars$mpg
PlotRangeOfPlausibleData(xvals,params,reps)
points(xvals,real_yvals,pch=20,cex=3,col="green")
##########
# now change the parameters and see if the data fit to the model
params$a=40       # was 30
params$b=-0.001   # was 0.005
PlotRangeOfPlausibleData(xvals,params,reps)
points(xvals,real_yvals,pch=20,cex=3,col="green")    # overlay the real data
#######
# try again- select a new set of parameters
params$a=33       # was 40
params$b=-0.004   # was 0.001
params$c=0.5
PlotRangeOfPlausibleData(xvals,params,reps)
points(xvals,real_yvals,pch=20,cex=3,col="green")    # overlay the real data
install.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
