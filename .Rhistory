na.action = "na.fail", REML=FALSE)
summary(fullmod)
library(effects)
plot(effects::effect("elev.s",fullmod))
plot(effects::effect("afg.s",fullmod))
plot(effects::effect("jul.s",fullmod))
# plot(effects::effect("jul.s",fullmod))
plot(effects::effect("pfg.s",fullmod))
library(DHARMa)
sims <- simulateResiduals(fullmod)
testResiduals(sims)
ranef(fullmod)
elevs <- seq(min(df$elev.s),max(elev.s),length=100)
elevs <- seq(min(df$elev.s),max(df$elev.s),length=100)
elevs
newdf <- data.frame(
elev.s = elevs,
afg.s = mean(df$afg.s),
pfg.s = mean(df$pfg.s),
ID = factor(levels(df$ID)[1],levels=levels(df$ID))
)
predict(fullmod,newdf,type="response")
preds <- predict(fullmod,newdf,type="response")
plot(elevs,preds,type="l")
newdf <- data.frame(
elev.s = elevs,
afg.s = mean(df$afg.s),
pfg.s = mean(df$pfg.s),
ID = factor(levels(df$ID)[2],levels=levels(df$ID))
)
preds <- predict(fullmod,newdf,type="response")
# plot(elevs,preds,type="l")
lines(elevs,preds)
newdf <- data.frame(
elev.s = elevs,
afg.s = mean(df$afg.s),
pfg.s = mean(df$pfg.s),
ID = factor(levels(df$ID)[3],levels=levels(df$ID))
)
preds <- predict(fullmod,newdf,type="response")
# plot(elevs,preds,type="l")
lines(elevs,preds)
newdf <- data.frame(
elev.s = elevs,
afg.s = mean(df$afg.s),
pfg.s = mean(df$pfg.s),
ID = factor(levels(df$ID)[4],levels=levels(df$ID))
)
preds <- predict(fullmod,newdf,type="response")
# plot(elevs,preds,type="l")
lines(elevs,preds)
library(rpart)          # library to plot a decision tree.
library(randomForest)   # RandomForest library
library(rfUtilities)    # library to use utility functions on Random forest model to analyse model perfomance and evaluation.
data(iris)
head(iris)
tree <- rpart(Species~.,method = 'class',control = rpart.control(cp=0,minsplit = 1),data = iris)
par(xpd= NA) # setting the plot parameter not to expand(To avoid text being cut out at the corners)
plot(tree)
# adding the text to the tree
# use.n =T to plot the number of obs assosicated with each class at each node.
text(tree,use.n = T)
tree <- rpart(Species~.,method = 'class',control = rpart.control(cp=0.05,minsplit = 1),data = iris)
set.seed(1234) #setting the intial value for Random number generator
rf <- randomForest(Species ~ .,data = iris,mtry = 4,ntrees = 100,proximity=TRUE,importance= TRUE )
print(rf)
print(rf)
plot(rf) # plotting OOB error rate of all three species based on no.of tree generated by Random Forest
?randomForest
knitr::opts_chunk$set(echo = TRUE, message = F)
library(geoR) # this may be obsolete soon
library(dplyr)
library(sf)
library(leaflet)
library(viridis)
library(terra)
library(geodata)
library(geoR) # this may be obsolete soon
library(INLA)
data(gambia)
library(geoR) # this may be obsolete soon
library(dplyr)
library(sf)
library(leaflet)
library(viridis)
library(terra)
library(geodata)
library(INLA)
library(randomForest)
library(rfUtilities)
library(randomForest)
library(rfUtilities)
my_data = read.csv("C:/Users/mahip/Downloads/ET_data.csv")
library(randomForest)
library(rfUtilities)
my_data = read.csv("ET_data.csv")
my_data = na.omit(my_data)
# Initialize empty training and test sets
train_set <- data.frame()
test_set <- data.frame()
# Specify the number of rows to include in each set alternately
rows_per_set <- 3
# Create alternating sets
for (i in seq(1, nrow(my_data), by = rows_per_set * 2)) {
test_indices <- i:(i + rows_per_set - 1)
train_indices <- (i + rows_per_set):(i + rows_per_set * 2 - 1)
test_set <- rbind(test_set, my_data[test_indices, , drop = FALSE])
train_set <- rbind(train_set, my_data[train_indices, , drop = FALSE])
}
train_set <- na.omit(train_set)
set.seed(123)
rf <- randomForest(data = train_set ,x = train_set[,c(1,3:8)],y = train_set$ET,ntree = 600,mtry = 2,importance = TRUE,proximity = TRUE)
print(rf)
plot(rf)
set.seed(123)
tuneRF(y = train_set$ET,x = train_set[,c(1,3:8)],,mtryStart = 2,stepFactor = 3,trace = TRUE,plot = TRUE, ntreeTry = 600 )
cv <- rf.crossValidation(x= rf, xdata = my_data[,c(1,3:8)],ydata = my_data$ET,p = 0.2, n = 99, seed = 123)
cv <- rf.crossValidation(x= rf, xdata = my_data[,c(1,3:8)],ydata = my_data$ET,p = 0.2, n = 99, seed = 123)
mean(cv$fit.var.exp)
mean(cv$fit.mse)
mean(cv$y.rmse)
mean(cv$y.mbe)
mean(cv$y.mae)
mean(cv$D)
mean(cv$p.val)
varImpPlot(rf)
library(randomForest)
library(rfUtilities)
my_data = read.csv('path_to_csv')
rmd2rscript <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- "echo"
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- !grepl(input, pattern = stringToFind2, perl = TRUE)   # is it hidden (echo=FALSE)
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
# rmd2rscript_labanswers <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts: see NRESlabs folder!!
#   outfile <- gsub(".Rmd",".R",infile)
#   close( file( outfile, open="w" ) )   # clear output file
#   con1 <- file(infile,open="r")
#   con2 <- file(outfile,"w")
#   stringToFind <- "```{r*"
#   stringToFind2 <- c("answer","test","solution")
#   isrblock <- FALSE
#   #count=0
#   blocknum=0
#
#   while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
#     isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
#     showit <- grepl(input, pattern = stringToFind2[1], perl = TRUE) | grepl(input, pattern = stringToFind2[2])
#     if(isrblock){
#       blocknum=blocknum+1
#       while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
#         if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#         #count=count+1
#       }
#       isrblock=FALSE
#     }
#   }
#   closeAllConnections()
# }
install.packages("INLA",repos=c(getOption("repos"),INLA="https://inla.r-inla-download.org/R/stable"), dep=TRUE)
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
library(INLA)
rmd2rscript <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- "echo"
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- !grepl(input, pattern = stringToFind2, perl = TRUE)   # is it hidden (echo=FALSE)
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
# rmd2rscript_labanswers <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts: see NRESlabs folder!!
#   outfile <- gsub(".Rmd",".R",infile)
#   close( file( outfile, open="w" ) )   # clear output file
#   con1 <- file(infile,open="r")
#   con2 <- file(outfile,"w")
#   stringToFind <- "```{r*"
#   stringToFind2 <- c("answer","test","solution")
#   isrblock <- FALSE
#   #count=0
#   blocknum=0
#
#   while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
#     isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
#     showit <- grepl(input, pattern = stringToFind2[1], perl = TRUE) | grepl(input, pattern = stringToFind2[2])
#     if(isrblock){
#       blocknum=blocknum+1
#       while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
#         if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#         #count=count+1
#       }
#       isrblock=FALSE
#     }
#   }
#   closeAllConnections()
# }
rmd2rscript("SpatialRegression.Rmd")
rmd2rscript <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- "echo"
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- !grepl(input, pattern = stringToFind2, perl = TRUE)   # is it hidden (echo=FALSE)
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
# rmd2rscript_labanswers <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts: see NRESlabs folder!!
#   outfile <- gsub(".Rmd",".R",infile)
#   close( file( outfile, open="w" ) )   # clear output file
#   con1 <- file(infile,open="r")
#   con2 <- file(outfile,"w")
#   stringToFind <- "```{r*"
#   stringToFind2 <- c("answer","test","solution")
#   isrblock <- FALSE
#   #count=0
#   blocknum=0
#
#   while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
#     isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
#     showit <- grepl(input, pattern = stringToFind2[1], perl = TRUE) | grepl(input, pattern = stringToFind2[2])
#     if(isrblock){
#       blocknum=blocknum+1
#       while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
#         if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#         #count=count+1
#       }
#       isrblock=FALSE
#     }
#   }
#   closeAllConnections()
# }
rmd2rscript("SpatialRegression.Rmd")
# Load libraries ----
library(codep)
library(vegan)
library(datasets)
library(tidyverse)
data(Doubs)
?Doubs #Information about the Doubs Fish data set.
Doubs
data(Doubs)
View(Doubs.env)
View(Doubs.fish)
species <- as.data.frame(Doubs.fish[-8,])
vars <- as.data.frame(cbind(Doubs.env[-8,],Doubs.geo[-8,]))
CHA.alt <- species$CHA + 1 #get rid of zeros to prep for log link
COGO_mod <- glm(CHA.alt ~ pH + flo + oxy, data = vars, family = Gamma(link = "log"))
summary(COGO_mod) #oxygen is significantly positive!
(Y.hmm <- data.frame(hydrophillic_1 = c(1, 0, 0), hydrophillic_2 = c(1, 1, 0),
mesic_1 = c(0, 1, 0), mesic_2 = c(0,4,0),
xeric_1 = c(0, 1, 3),xeric_2 = c(0, 0, 2),
row.names = c("sample_1_wet", "sample_2_intermediate",
"sample_3_dry")))
# Calculate Euclidean distance using the dist() function
(Y.hmm.DistEu <- as.matrix(dist(x = Y.hmm, method = "euclidean")))
# Calculate Euclidean Distance by Hand
calc_eu_dist <- function(spe_abun_df) {
# Create output matrix
output <- as.data.frame(matrix(NA, nrow = nrow(spe_abun_df), ncol = nrow(spe_abun_df)))
# Index through the rows of the data frame
for (i in 1:nrow(spe_abun_df)) {
x1 <- spe_abun_df[i, ]
for (t in 1:nrow(spe_abun_df)) {
x2 <- spe_abun_df[t,]
# Calculate euclidean distance and place distance into output data frame
output[i,t] <- sqrt(sum((x1 - x2)^2))
}
}
# Return output
return(output)
}
# Run Euclidean distance by hand function
(Y.hmm_eu_dist <- calc_eu_dist(Y.hmm))
(Y.hmm.BCdist <- vegan::vegdist(Y.hmm, method = "bray", binary = FALSE))
(Y.hmm.BCdist.matrix <- as.matrix(Y.hmm.BCdist))
# Calculate Bray-Curtis coefficient by hand
calc_bc_dist <- function(spe_abun_df) {
# Create output matrix
output <- as.data.frame(matrix(NA, nrow = nrow(spe_abun_df), ncol = nrow(spe_abun_df)),
row.names = rownames(spe_abun_df))
colnames(output) <- rownames(spe_abun_df)
# Index through the rows of the data frame
for (i in 1:nrow(spe_abun_df)) {
x1 <- spe_abun_df[i, ]
for (t in 1:nrow(spe_abun_df)) {
x2 <- spe_abun_df[t,]
# Create empty data frame to find the minimum values of each species between two sites
comp_df <- as.data.frame(matrix(nrow = 2, ncol = ncol(spe_abun_df)))
# Place the site values into the data frame
comp_df[1,] = x1
comp_df[2,] = x2
# Find the minimum abundance values of each species and sum them.
min_abundances <- apply(comp_df, 2, min)
W <- sum(min_abundances)
# Sum the abundances of site 1
A = sum(x1)
# Sum the abundances of site 2
B = sum(x2)
# Calculate the Bray-Curtis coefficient
bc_dist <- (1 - ((2 * W) / (A + B)))
# Place the BC coefficient into the output data frame
output[i,t] <- bc_dist
}
}
# Return output
return(output)
}
# Run Bray-Curtis coefficient by hand function
calc_bc_dist(Y.hmm)
data(Doubs)
species <- Doubs.fish[-8,]
spe.hel <- as.data.frame(vegan::decostand(species, method = "hellinger"))
head(spe.hel)
# Compute covarience matrix by hand
comp_cov <- function(data) {
output_df <- as.data.frame(matrix(NA, nrow = ncol(spe.hel), ncol = ncol(spe.hel)), row.names = colnames(data))
colnames(output_df) <- colnames(data)
for (i in 1:ncol(data)) {
mean.dif.x1 <- data[,i] - mean(data[,i])
for (p in 1:ncol(data)) {
mean.dif.x2 <- data[,p] - mean(data[,p])
output <- mean.dif.x1 * mean.dif.x2
output_df[i, p] <- sum(output)/(nrow(data)-1)
}
}
return(output_df)
}
cov_matrix <- comp_cov(spe.hel)
# Compare with built-in function
cov_base_func <- cov(spe.hel)
eigen_decomp <- eigen(cov_matrix)
# Extract Eigenvalues
(eig_values <- eigen_decomp$values)
# Extract Eigenvalues
(eig_values <- eigen_decomp$values)
# Extract Eigenvectors
(eig_vectors <- -eigen_decomp$vectors)
rownames(eig_vectors) = colnames(spe.hel)
# Extract the first two eigenvectors
eig_vec_1 <- eig_vectors[,1]
eig_vec_2 <- eig_vectors[,2]
# Calculate the estimated variance for each eigenvalue
(e_var <- eig_values / (nrow(spe.hel) - 1))
# Data frame with variance percentages
var_per <- data.frame(
PC  = c("PC01", "PC02", "PC03", "PC04", "PC05", "PC06","PC07", "PC08", "PC09",
"PC10", "PC11", "PC12", "PC13", "PC14", "PC15", "PC16", "PC17", "PC18",
"PC19", "PC20", "PC21", "PC22", "PC23", "PC24", "PC25", "PC26", "PC27"),
PER = c(e_var) * 100 / sum(e_var)) # Calculate the percentage
# Scree plot to show amount of variance accounted by each principal component
barplot(PER ~ PC, data = var_per,
xlab = "Principal Components",
ylab = "Percent of Variation %")
# Kaiser-Guttman Criterion
eig_val_PC <- data.frame(
PC = c("PC01", "PC02", "PC03", "PC04", "PC05", "PC06","PC07", "PC08", "PC09",
"PC10", "PC11", "PC12", "PC13", "PC14", "PC15", "PC16", "PC17", "PC18",
"PC19", "PC20", "PC21", "PC22", "PC23", "PC24", "PC25", "PC26", "PC27"),
EV = eig_values)
# Plot principal components and overlay average eigenvalue line
barplot(EV ~ PC, data = eig_val_PC,
xlab = "Principal Components",
ylab = "Eigenvalues")
abline(h = mean(eig_values), col = "red")
# Broken stick Model
broken_stick <- function(eig_values) {
# Calculate Broken Stick Model
n = length(eig_values)
bsm = data.frame(j=seq(1:n), prop_var=0)
bsm$prop_var[1] = 1/n
for (i in 2:n) {
bsm$prop_var[i] = bsm$prop_var[i-1] + (1/(n + 1 - i))
}
bsm$prop_var = 100*bsm$prop_var/n
# Plot Broken Stick Modol Over
barplot(t(cbind(100*eig_values/sum(eig_values), bsm$p[n:1])),
beside=TRUE,
main="Broken Stick Model",
col=c("red","blue"),
las=2,
xlab = "Principal Components", ylab = "Percent of Variation (%)")
legend("topright", c("Eigenvalues", "Broken stick model"),
pch=15,
col=c("red","blue"),
bty="n")
}
broken_stick(eig_values)
eig_vec_kgc <- eig_values[eig_values > mean(eig_values)]
sum(var_per$PER[1:length(eig_vec_kgc)])
# Plot only the first principal component
plot(BAR ~ BLA, col = as.factor(rownames(spe.hel)), pch = 19,
xlim = c(-0.25,0.5), ylim = c(-0.5,0.5),
data = (spe.hel), xlab = "BLA (Standardized)", ylab = "BAR (Standardized)")
abline(v=0 , h=0, col = "dark gray")
# Overlap first eigenvector/principal component
abline(0, eig_vec_1[11]/eig_vec_1[6], col='purple')
# Plot lines from the first eigenvector to points
line1 <- c(0, eig_vec_1[11]/eig_vec_1[6])
perp.segment.coord <- function(x0, y0, line1){
a <- line1[1]  #intercept
b <- line1[2]  #slope
x1 <- (x0 + b * y0 - a * b)/(1 + b^2)
y1 <- a + b * x1
list(x0 = x0, y0 = y0,
x1 = x1, y1 = y1)
}
ss <- perp.segment.coord(spe.hel[,6], spe.hel[,11], line1)
segments(x0 = ss$x0, x1 = ss$x1, y0 = ss$y0, y1 = ss$y1, col = 'purple')
with(spe.hel, text(BAR ~ BLA, labels = as.factor(rownames(spe.hel)), pos = 1, cex=1))
title(main = "First Principal Component over the Standardized Data",
sub = "Purple Lines Horizontal to the First Principal Components is the Variance", cex.sub = 0.75)
# Plot both the first and second principal component
plot(BAR ~ BLA, col = as.factor(rownames(spe.hel)), pch = 19,
xlim = c(-0.25,0.5), ylim = c(-0.5,0.5),
data = (spe.hel), xlab = "BLA (Standardized)", ylab = "BAR (Standardized)")
abline(v=0 , h=0, col = "dark gray")
# Overlap pertinent eigenvectors
abline(0, eig_vec_1[11]/eig_vec_1[6], col='purple')
abline(0, eig_vec_2[11]/eig_vec_2[6], col='orange')
# Plot the lines from second eigenvector to points
line2 <- c(0, eig_vec_2[11]/eig_vec_2[6])
ss <- perp.segment.coord(spe.hel[,6], spe.hel[,11], line2)
segments(x0 = ss$x0, x1 = ss$x1, y0 = ss$y0, y1 = ss$y1,col = 'orange')
with(spe.hel, text(BAR ~ BLA, labels = as.factor(rownames(spe.hel)),pos = 1, cex=1))
title(main = "First (Purple) and Second (Orange) Principal Component over the Standardized Data",
cex.main = 0.8, sub = "Lines Horizontal to the Principal Components are the Variance", cex.sub = 0.75)
# Get variable loading scores
variable.loads <- data.frame(
PC01 = eig_vec_1, # First eigenvector
PC02 = eig_vec_2  # Second eigenvector
)
head(variable.loads)
# Get site loading scores
loading.scores <- as.data.frame(as.matrix(spe.hel) %*% eig_vectors)
colnames(loading.scores) = c("PC01", "PC02", "PC03", "PC04", "PC05", "PC06","PC07", "PC08",
"PC09", "PC10", "PC11", "PC12", "PC13", "PC14", "PC15", "PC16",
"PC17", "PC18", "PC19", "PC20", "PC21", "PC22", "PC23", "PC24",
"PC25", "PC26", "PC27")
head(loading.scores)
# Set plot parameters
par(mar = c(5, 5, 10, 5),
mgp = c(2, 1, 0))
# Plot site loading scores
plot(loading.scores[,2] ~ loading.scores[,1],
xlab = 'PC1', ylab = "PC2",
xlim = c(-1,1), ylim  = c(-1,1),col = as.factor(rownames(loading.scores)), pch = 19)
# Set plot parameters
par(mar = c(5, 5, 10, 5),
mgp = c(2, 1, 0))
# Plot site loading scores
plot(loading.scores[,2] ~ loading.scores[,1],
xlab = 'PC1', ylab = "PC2",
xlim = c(-1,1), ylim  = c(-1,1),col = as.factor(rownames(loading.scores)), pch = 19)
abline(v = 0, col = "orange")
abline(h = 0, col = "purple")
with(loading.scores, text(PC02 ~ PC01, labels = as.factor(rownames(loading.scores)),pos = 1, cex=1))
par(new=TRUE)
# Overlay the variable loading scores
plot(PC02 ~ PC01,
xlim = c(-1, 1), ylim = c(-1,1),
col = "red", pch = 8, axes = F, xlab = "", ylab = "",
data = variable.loads)
View(variable.loads)
