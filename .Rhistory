par(new=TRUE)
# Overlay the variable loading scores
plot(PC02 ~ PC01,
xlim = c(-1, 1), ylim = c(-1,1),
col = "red", pch = 8, axes = F, xlab = "", ylab = "",
data = variable.loads)
View(variable.loads)
RDA_prep <- function(x, y){
# Step 1: hellinger-transform the y data
y=as.data.frame(vegan::decostand(y, method = "hellinger"))
# Step 2: center and scale the x data
x=scale(x)
return(list(x=x,y=y))
}
# Use the function to prepare our data for RDA
data <- RDA_prep(x = vars,
y = species
)
data$x
#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#
#$       NRES 746 Lab Script      $#
#$       Intro to Ordination      $#
#$ Martin Genova & Kierstin Acuna $#
#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#
# Load libraries ----
library(codep)
library(vegan)
# Load Doubs fish Data ----
data(Doubs)
# Process data ---
species <- as.data.frame(Doubs.fish[-8,])  # remove observation with no data
vars <- as.data.frame(cbind(Doubs.env[-8,],Doubs.geo[-8,]))
nrow(species)  # 29 sites (30 but one removed)
ncol(species)  # 27 species
## Explore the data ----
# Count the number of species frequencies in each abundance class
length(unlist(species))   # 783 observations in the species data (species*sites)
ab <- table(unlist(species))
ab      # as many as 5 individuals of a single species was observed at a single site...
# Plot distribution of species frequencies
barplot(ab, xlab = "Abundance class", ylab = "Frequency", col = grey(5:0/5))   # not sure why this is needed
sort(colSums(species))  # most abundant species is LOC (73 observations). Least abundant is CHA and OMB (15 individuals)
sort(rowSums(species))  # at the site level, some sites have as low as 3 captures and others as much as 89
# Look at the spread of the predictor variables
# ?Doubs
summary(vars)    # lots of variability in the scales of the predictor variables...
# Exercise 1 ----
# Build a function to prepare the data for RDA
# NOTES ----
# x is env vars, y is species
# hellinger transform is useful when you only care about relative abundances.
RDA_prep <- function(x, y){
# Step 1: hellinger-transform the y data
y=as.data.frame(vegan::decostand(y, method = "hellinger"))
# Step 2: center and scale the x data
x=scale(x)
return(list(x=x,y=y))
}
# Use the function to prepare our data for RDA
data <- RDA_prep(x = vars,
y = species
)
?dbrda
species
vars
names(vars)
?Doubs
cor(vars)
caret::findCorrelation(vars,cutoff=0.75)
vars
cor(data$x)
caret::findCorrelation(data$x)
vars <- names(data$x)
vars <- names(data$x)
vars
data$x
colnames(data$x)
varstokeep <- c("slo","flo","pH","nit","Alt")
cor(data$x[,varstokeep])
varstokeep <- c("slo","flo","pH","nit","Lat")
cor(data$x[,varstokeep])
RDA_prep <- function(x, y){
# Step 1: hellinger-transform the y data
y=as.data.frame(vegan::decostand(y, method = "hellinger"))
# Step 2: center and scale the x data
x=as.data.frame(scale(x))
return(list(x=x,y=y))
}
# Use the function to prepare our data for RDA
data <- RDA_prep(x = vars,
y = species
)
#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#
#$       NRES 746 Lab Script      $#
#$       Intro to Ordination      $#
#$ Martin Genova & Kierstin Acuna $#
#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#
# Load libraries ----
library(codep)
library(vegan)
# Load Doubs fish Data ----
data(Doubs)
# Process data ---
species <- as.data.frame(Doubs.fish[-8,])  # remove observation with no data
vars <- as.data.frame(cbind(Doubs.env[-8,],Doubs.geo[-8,]))
nrow(species)  # 29 sites (30 but one removed)
ncol(species)  # 27 species
## Explore the data ----
# Count the number of species frequencies in each abundance class
length(unlist(species))   # 783 observations in the species data (species*sites)
ab <- table(unlist(species))
ab      # as many as 5 individuals of a single species was observed at a single site...
# Plot distribution of species frequencies
barplot(ab, xlab = "Abundance class", ylab = "Frequency", col = grey(5:0/5))   # not sure why this is needed
sort(colSums(species))  # most abundant species is LOC (73 observations). Least abundant is CHA and OMB (15 individuals)
sort(rowSums(species))  # at the site level, some sites have as low as 3 captures and others as much as 89
# Look at the spread of the predictor variables
# ?Doubs
summary(vars)    # lots of variability in the scales of the predictor variables...
# Exercise 1 ----
# Build a function to prepare the data for RDA
# NOTES ----
# x is env vars, y is species
# hellinger transform is useful when you only care about relative abundances.
RDA_prep <- function(x, y){
# Step 1: hellinger-transform the y data
y=as.data.frame(vegan::decostand(y, method = "hellinger"))
# Step 2: center and scale the x data
x=as.data.frame(scale(x))
return(list(x=x,y=y))
}
#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#
#$       NRES 746 Lab Script      $#
#$       Intro to Ordination      $#
#$ Martin Genova & Kierstin Acuna $#
#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#
# Load libraries ----
library(codep)
library(vegan)
# Load Doubs fish Data ----
data(Doubs)
# Process data ---
species <- as.data.frame(Doubs.fish[-8,])  # remove observation with no data
vars <- as.data.frame(cbind(Doubs.env[-8,],Doubs.geo[-8,]))
nrow(species)  # 29 sites (30 but one removed)
ncol(species)  # 27 species
## Explore the data ----
# Count the number of species frequencies in each abundance class
length(unlist(species))   # 783 observations in the species data (species*sites)
ab <- table(unlist(species))
ab      # as many as 5 individuals of a single species was observed at a single site...
# Plot distribution of species frequencies
barplot(ab, xlab = "Abundance class", ylab = "Frequency", col = grey(5:0/5))   # not sure why this is needed
sort(colSums(species))  # most abundant species is LOC (73 observations). Least abundant is CHA and OMB (15 individuals)
sort(rowSums(species))  # at the site level, some sites have as low as 3 captures and others as much as 89
# Look at the spread of the predictor variables
# ?Doubs
summary(vars)    # lots of variability in the scales of the predictor variables...
# Exercise 1 ----
# Build a function to prepare the data for RDA
# NOTES ----
# x is env vars, y is species
# hellinger transform is useful when you only care about relative abundances.
RDA_prep <- function(x, y){
# Step 1: hellinger-transform the y data
y=as.data.frame(vegan::decostand(y, method = "hellinger"))
# Step 2: center and scale the x data
x=as.data.frame(scale(x))
return(list(x=x,y=y))
}
# Use the function to prepare our data for RDA
data <- RDA_prep(x = vars,
y = species
)
data$x
data$y   # now the species
colnames(data$x)
varstokeep <- c("slo","flo","pH","nit","Lat")
cor(data$x[,varstokeep])
dbrda_global <- dbrda(species ~ slo+flo+pH+nit+Lat,
data = data$x,
distance = "bray")
rda_null <- vegan::rda(species ~ 1, data=data$x)
?ordiR2step
# Step 2: Use the ordiR2step function for variable selection. Define the object as the
#   null rda, and the scope as the global rda.
selection <- vegan::ordiR2step(dbrda_global)
full_form <- paste0("species~",paste(varstokeep,collapse="+"))
full_form <- as.formula(paste0("species~",paste(varstokeep,collapse="+")))
dbrda_global <- dbrda(full_form,
data = data$x,
distance = "bray")
full_form <- as.formula(paste0("species~",paste(varstokeep,collapse="+")))
dbrda_global <- dbrda(full_form,
data = data$x,
distance = "bray")
null_form <- as.formula("species~1")
dbrda_global <- dbrda(full_form,
data = data$x,
distance = "bray")
rda_null <- vegan::rda(null_form, data=data$x)
# Step 2: Use the ordiR2step function for variable selection. Define the object as the
#   null rda, and the scope as the global rda.
selection <- vegan::ordiR2step(dbrda_global,scope=list(full_form,null_form))
# Step 2: Use the ordiR2step function for variable selection. Define the object as the
#   null rda, and the scope as the global rda.
selection <- vegan::ordiR2step(dbrda_global,scope=list(upper=full_form,lower=null_form))
list(upper=full_form,lower=null_form)
dbrda_null <- vegan::dbrda(null_form, data=data$x,distance = "bray")
# Step 2: Use the ordiR2step function for variable selection. Define the object as the
#   null rda, and the scope as the global rda.
selection <- vegan::ordiR2step(dbrda_null,scope=dbrda_global)
# Step 3: View the results. The formula in the "Call" contains the variables that
#   ordiR2step selected.
selection
selection$terms
str(selection$terms)
# Step 3: View the results. The formula in the "Call" contains the variables that
#   ordiR2step selected.
selection$call
selection
finalvars <- c("flo","nit","slo")
final_form <- as.formula(paste0("species~",paste(finalvars,collapse="+")))
# Exercise 3 ----
# Step 1: Use the rda function to run an rda on the variables selected in exercise 2
rda_final <- vegan::dbrda(final_form, data = data$x,
distance = "bray"   )
# Step 2: Visualize the rda using the ordiplot function
vegan::ordiplot( rda_final    )
# Step 3: Calculate the adjusted R-squared and p-values for the rda
r2 <- vegan::RsquareAdj( rda_final    )
r2
p <- vegan::anova.cca( rda_final    )
p
p
summary(rda_final)
p
cor(data$x[,varstokeep])
?dbrda
varstokeep <- c("slo","flo","pH","nit","Lat","bdo")
cor(data$x[,varstokeep])
full_form <- as.formula(paste0("species~",paste(varstokeep,collapse="+")))
null_form <- as.formula("species~1")
dbrda_global <- dbrda(full_form,
data = data$x,
distance = "bray")
dbrda_null <- vegan::dbrda(null_form, data=data$x,distance = "bray")
# Step 2: Use the ordiR2step function for variable selection. Define the object as the
#   null rda, and the scope as the global rda.
selection <- vegan::ordiR2step(dbrda_null,scope=dbrda_global)
varstokeep <- c("slo","flo","pH","nit","Lat")
cor(data$x[,varstokeep])
full_form <- as.formula(paste0("species~",paste(varstokeep,collapse="+")))
null_form <- as.formula("species~1")
dbrda_global <- dbrda(full_form,
data = data$x,
distance = "bray")
dbrda_null <- vegan::dbrda(null_form, data=data$x,distance = "bray")
# Step 2: Use the ordiR2step function for variable selection. Define the object as the
#   null rda, and the scope as the global rda.
selection <- vegan::ordiR2step(dbrda_null,scope=dbrda_global)
selection$call
varstokeep <- c("slo","flo","pH","nit","Lat","bdo")
cor(data$x[,varstokeep])
full_form <- as.formula(paste0("species~",paste(varstokeep,collapse="+")))
null_form <- as.formula("species~1")
dbrda_global <- dbrda(full_form,
data = data$x,
distance = "bray")
dbrda_null <- vegan::dbrda(null_form, data=data$x,distance = "bray")
# Step 2: Use the ordiR2step function for variable selection. Define the object as the
#   null rda, and the scope as the global rda.
selection <- vegan::ordiR2step(dbrda_null,scope=dbrda_global)
selection$call
finalvars <- c("flo","bdo","slo")
final_form <- as.formula(paste0("species~",paste(finalvars,collapse="+")))
# Exercise 3 ----
# Step 1: Use the rda function to run an rda on the variables selected in exercise 2
rda_final <- vegan::dbrda(final_form, data = data$x,
distance = "bray"   )
# Step 2: Visualize the rda using the ordiplot function
vegan::ordiplot( rda_final    )
set.seed(123) #Set seed to get reproduceable results
?ts
#Load the Nile dataset
data(Nile)
class(Nile) #ts object already!
#It's easy to turn a ts object back into a regular dataframe
Nile <- data.frame(Y=as.matrix(Nile), date=time(Nile))
#Look at the data
head(Nile)
#Turn it into a timeseries
Nile.ts <- ts(data = Nile$Y, start = 1871, end = 1970, frequency = 1) #our data will be column 'Y', the discharge!And frequency is 1 since it is measured once a year!
ts.plot(Nile.ts) #ts.plot() plots time series objects
plot(Nile.ts)
#Plot our original dataframe that wasn't a timeseries object
ts.plot(Nile$Y) #remember we plot our response variable, Y
#Load the beavers dataset from R
data(beavers) #We'll work with beaver1 :)
View(beaver2)
#Look at the data
head(beaver1)
summary(beaver1)
#Subset out only the first day
beaver1 <- beaver1[which(beaver1$day == 346),] #Take all the data on day 346
#Turn it into a timeseries
beaver1.ts <- ts(data = beaver1$temp) #our data will be the temperature.
library(jagsUI)
library("MARSS")
# load the data from the "MARSS" package
data(lakeWAplankton, package = "MARSS")
View(lakeWAplanktonTrans)
library("MARSS")
# load the data from the "MARSS" package
data(lakeWAplankton, package = "MARSS")
phyto <- lakeWAplanktonTrans #Give it a name to keep the original data structure in tact
phyto <- phyto[phyto[,"Year"] > 1975,] #Subset to years greater than 1975 (missing data in early years)
# Note that our data is monthly!
head(phyto)
#Turn into time series object
phyto.ts <- ts(phyto, start = c(1976,1), freq = 12)
#Plot the ACF
acf(phyto.ts[,"Cryptomonas"], na.action = na.pass, las = 1)
#Plot the PCF
pacf(phyto.ts[,"Cryptomonas"], na.action = na.pass, las = 1)
data(beavers)
head(phyto.ts)
fit.lm <- lm(Cryptomonas~cos(2*pi*Month/12)+sin(2*pi*Month/12),data=phyto.ts)
summary(fit.lm)
nd <- data.frame(Month=1:12)
predict(fit.lm,nd)
plot(nd$Month, predict(fit.lm,nd))
#Plot the PCF
pacf(phyto.ts[,"Cryptomonas"], na.action = na.pass, las = 1)
plot(phyto.ts[,"Cryptomonas"])
phyto.ts.lag
phyto.ts.lag <- phyto.ts
phyto.ts.lag
phyto.ts.lag[,"lag1"] <- NA
head(phyto)
plot(phyto.ts[,"Cryptomonas"])
phyto.lag <- phyto
phyto
phyto.lag <- as.data.frame(phyto)
phyto.lag <- as.data.frame(phyto)
View(phyto)
View(phyto.lag)
phyto.lag$lag1 <- NA
phyto.lag$lag1[2:nrow(phyto.lag)] <- phyto.lag$Cryptomonas[1:(nrow(phyto.lag)-1)]
fit.lm <- lm(Cryptomonas~lag1 + cos(2*pi*Month/12)+sin(2*pi*Month/12),data=phyto.lag)
summary(fit.lm)
nd <- data.frame(Month=1:12)
plot(nd$Month, predict(fit.lm,nd))
nd <- data.frame(Month=1:12,lag1=0)
plot(nd$Month, predict(fit.lm,nd))
library(lubridate)
paste0(phyto.lag$Year,phyto.lag$Month,"1",sep="_")
paste(phyto.lag$Year,phyto.lag$Month,"1",collapse="_")
paste(phyto.lag$Year,phyto.lag$Month,"1")
paste(phyto.lag$Year,phyto.lag$Month,"1",sep="_")
phyto.lag$DATE <- ymd(paste(phyto.lag$Year,phyto.lag$Month,"1",sep="_"))
fit.lm <- lm(Cryptomonas~lag1 + cos(2*pi*Month/12)+sin(2*pi*Month/12),data=phyto.lag)
summary(fit.lm)
plot(Cryptomonas~DATE,data=phyto.lag)
plot(Cryptomonas~DATE,data=phyto.lag,type="l")
lines(phyto.lag$DATE,predict(fit.lm),col="green",lwd=2)
phyto.lag <- na.omit(phyto.lag)
phyto.lag$DATE <- ymd(paste(phyto.lag$Year,phyto.lag$Month,"1",sep="_"))
fit.lm <- lm(Cryptomonas~lag1 + cos(2*pi*Month/12)+sin(2*pi*Month/12),data=phyto.lag)
summary(fit.lm)
phyto.lag <- as.data.frame(phyto)
phyto.lag$lag1 <- NA
phyto.lag$lag1[2:nrow(phyto.lag)] <- phyto.lag$Cryptomonas[1:(nrow(phyto.lag)-1)]
library(lubridate)
phyto.lag <- na.omit(phyto.lag)
phyto.lag$DATE <- ymd(paste(phyto.lag$Year,phyto.lag$Month,"1",sep="_"))
phyto.lag
phyto.lag <- as.data.frame(phyto)
phyto.lag$lag1 <- NA
phyto.lag$lag1[2:nrow(phyto.lag)] <- phyto.lag$Cryptomonas[1:(nrow(phyto.lag)-1)]
head(phyto.lag)
tokeep <- c("Cryptomonas","lag1","DATE","Month")
phyto.lag <- phyto.lag[,tokeep]
phyto.lag <- as.data.frame(phyto)
phyto.lag$lag1 <- NA
phyto.lag$lag1[2:nrow(phyto.lag)] <- phyto.lag$Cryptomonas[1:(nrow(phyto.lag)-1)]
library(lubridate)
tokeep <- c("Cryptomonas","lag1","DATE","Month")
phyto.lag <- phyto.lag[,tokeep]
names(phyto.lag)
phyto.lag$lag1[2:nrow(phyto.lag)] <- phyto.lag$Cryptomonas[1:(nrow(phyto.lag)-1)]
library(lubridate)
phyto.lag$DATE <- ymd(paste(phyto.lag$Year,phyto.lag$Month,"1",sep="_"))
tokeep <- c("Cryptomonas","lag1","DATE","Month")
names(phyto.lag)
phyto.lag <- phyto.lag[,tokeep]
head(phyto.lag)
phyto.lag <- na.omit(phyto.lag)
fit.lm <- lm(Cryptomonas~lag1 + cos(2*pi*Month/12)+sin(2*pi*Month/12),data=phyto.lag)
summary(fit.lm)
nd <- data.frame(Month=1:12,lag1=0)
plot(nd$Month, predict(fit.lm,nd))
plot(Cryptomonas~DATE,data=phyto.lag,type="l")
lines(phyto.lag$DATE,predict(fit.lm),col="green",lwd=2)
fit.lm <- lm(Cryptomonas~lag1 + sin(2*pi*Month/12),data=phyto.lag)
summary(fit.lm)
nd <- data.frame(Month=1:12,lag1=0)
plot(nd$Month, predict(fit.lm,nd))
plot(Cryptomonas~DATE,data=phyto.lag,type="l")
lines(phyto.lag$DATE,predict(fit.lm),col="green",lwd=2)
plot(nd$Month, predict(fit.lm,nd),type="l")
data <-  read.csv('./Data/portal_timeseries.csv') #Read in the data, will need to edit to wherever you have it stored
library(jagsUI)
data <-  read.csv('portal_timeseries.csv') #Read in the data, will need to edit to wherever you have it stored
head(data)
library(jagsUI)
data <-  read.csv('portal_timeseries.csv') #Read in the data, will need to edit to wherever you have it stored
head(data)
plot.ts(data$NDVI) #Plot the time series
#Plot AC plots, anything interesting? :)
acf(data$NDVI)
pacf(data$NDVI)
#For secret (forecasting) reasons we're going to cut the last 10 observations out
oos <- data[-(1:(nrow(data)-10)),] #Take the last 100 rows of the data frame and save it as a new dataframe
data.training <- data[(1:(nrow(data)-10)),] #Take out the last 100 rows and the rest of the data is what we will use to make our model
View(data.training)
filename <-  "NDVI_Model.txt"
cat("
model{
#Likelihood
for(t in 2:time){ #Loop through the number of observations, we have to start at t=2 because at t=1 there is no t-1 data to pull from!
NDVI[t] ~ dnorm(expNDVI[t],precNDVI)
expNDVI[t] <- b0 + b1*NDVI[t-1] + b2*rain[t-1]
}
#Priors
b0 ~ dnorm(0,0.1) #intercept term - dnorm uses mu and precision (1/var). So prec of 0.1 is a var of 10
b1 ~ dnorm(0,0.1) #slope term for previous month's NDVI
b2 ~ dnorm(0,0.1) #slope term for previous month's RAIN
sd ~ dnorm(0,0.1)T(0,) #We're truncating the prior to be positive
#Derived terms
precNDVI <- pow(sd,-2) #compute precision from stdv. 1/var
}
",
file = filename)
datalist <- list(time = nrow(data.training), NDVI = data.training$NDVI, rain = data.training$rain)
inits <- function(){
vals <- list(
b0 = runif(1,-10,10),
b1 = runif(1,-10,10),
b2 = runif(1,-10,10),
sd = runif(1,1,10)
)
return(vals)
}
inits() #testing
datalist
#Specify what parameters we're interested in (what do we obtain a joint posterior dist for)
#   What are our free params
params <- c("b0", "b1", "b2","sd")
nc <- 3 #number of chains
niter <- 10000 #Number of iterations, includes burnin
nb <- 2500 #burnin
thin <- 5 #thining
#Inits should be function itself, not just one run of it
#N.adapt is the tuning parameter
mod <- jags(data = datalist, inits = inits, parameters.to.save = params,
model.file = filename,
n.chains = nc, n.adapt=1000, n.iter = niter, n.burnin=nb, n.thin=thin,
parallel=F)
###Visualize posteriors and assess convergence----
mod #Summary of the model
plot(mod) #Plot trace plots and posterior distributions of our parameters
sims <-  mod$sims.list #Pull out each iteration parameter estimates
Predictions <- matrix(NA, length(sims$b0), nrow(oos)) #Create a blank matrix to store our predictions
dim(Predictions) # nrow = # of iterations, ncol = years we're making predictions for (withheld data)
for(p in 1:length(sims$b0)){ #Loops through the number of iterations
NDVI <- data$NDVI[1] #give it a value to start at
for(t in 1:nrow(oos)){
NDVI <- sims$b0[p]+sims$b1[p]*NDVI+sims$b2[p]*oos$rain[t] #Copy the process from what you did in the model
Predictions[p,t] <- NDVI
}
}
#Take some summary statistics from our predictions to plot
Mean <- apply(Predictions,2, mean)
UCI <- apply(Predictions,2,quantile, prob = .975)
LCI <- apply(Predictions,2,quantile, prob = .025)
#Now let's plot our forecast
par(mfrow = c(1,1))
plot(Mean, type = 'l', ylim = c(0.1,0.4))
lines(UCI, lty = 2, col = 'steelblue')
lines(LCI, lty = 2, col = 'steelblue')
points(oos$NDVI, col = 'red') #Actual data
?sin
# load the data from the "MARSS" package
data(lakeWAplankton, package = "MARSS")
phyto <- lakeWAplanktonTrans #Give it a name to keep the original data structure in tact
phyto <- phyto[phyto[,"Year"] > 1975,] #Subset to years greater than 1975 (missing data in early years)
# Note that our data is monthly!
head(phyto)
#Turn into time series object
phyto.ts <- ts(phyto, start = c(1976,1), freq = 12)
#Plot the ACF
acf(phyto.ts[,"Cryptomonas"], na.action = na.pass, las = 1)
plot(mod) #Plot trace plots and posterior distributions of our parameters
#Inits should be function itself, not just one run of it
#N.adapt is the tuning parameter
mod <- jags(data = datalist, inits = inits, parameters.to.save = params,
model.file = filename,
n.chains = nc, n.adapt=1000, n.iter = niter, n.burnin=nb, n.thin=thin,
parallel=F)
###Visualize posteriors and assess convergence----
mod #Summary of the model
