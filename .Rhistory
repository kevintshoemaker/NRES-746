newguess
startingvals
newguess
# function for making new guesses
newGuess <- function(oldguess){
sdshapejump <- 1 #4
sdscalejump <- 0.01
jump <- c(shape=rnorm(1,mean=0,sd=sdshapejump),scale=rnorm(1,0,sdscalejump))
newguess <- abs(oldguess + jump)    # note: by taking the abs val to avoid negative numbers, our proposal jump probs are not strictly symmetrical, but this should not present a big issue in practice
return(newguess)
}
newGuess(oldguess=params)
newGuess(oldguess=params)
newGuess(oldguess=params)
startingvals <- c(shape=75,scale=0.28)    # starting point for the algorithm
startingvals
newguess <- newGuess(startingvals)    # take a jump in parameter space
newguess
PosteriorRatio2(startingvals,newguess)   # difference in posterior ratio
startingvals
newguess <- newGuess(startingvals)    # take a jump in parameter space
newguess
# function for making new guesses
newGuess <- function(oldguess){
sdshapejump <- .5 #4
sdscalejump <- 0.01
jump <- c(shape=rnorm(1,mean=0,sd=sdshapejump),scale=rnorm(1,0,sdscalejump))
newguess <- abs(oldguess + jump)    # note: by taking the abs val to avoid negative numbers, our proposal jump probs are not strictly symmetrical, but this should not present a big issue in practice
return(newguess)
}
newGuess(oldguess=params)
newGuess(oldguess=params)
newGuess(oldguess=params)
newGuess(oldguess=params)
newGuess(oldguess=params)
newGuess(oldguess=params)
startingvals <- c(shape=75,scale=0.28)    # starting point for the algorithm
startingvals
newguess <- newGuess(startingvals)    # take a jump in parameter space
newguess
PosteriorRatio2(startingvals,newguess)   # difference in posterior ratio
chain.length <- 11
oldguess <- startingvals
guesses <- matrix(0,nrow=chain.length,ncol=2)
colnames(guesses) <- names(startingvals)
guesses[1,] <- startingvals
chain.length <- 11
oldguess <- startingvals
guesses <- matrix(0,nrow=chain.length,ncol=2)
colnames(guesses) <- names(startingvals)
guesses[1,] <- startingvals
counter <- 2
while(counter <= chain.length){
newguess <- newGuess(oldguess)
post.rat <- PosteriorRatio2(oldguess,newguess)
prob.accept <- min(1,post.rat)
rand <- runif(1)
if(rand<=prob.accept){
oldguess <- newguess
guesses[counter,] <- newguess
}else{
guesses[counter,] <- oldguess
}
counter=counter+1
}
# Visualize the Metropolis-Hastings routine: ---------------
chain.length <- 11
oldguess <- startingvals
guesses <- matrix(0,nrow=chain.length,ncol=2)
colnames(guesses) <- names(startingvals)
guesses[1,] <- startingvals
counter <- 2
while(counter <= chain.length){
newguess <- newGuess(oldguess)
post.rat <- PosteriorRatio2(oldguess,newguess)
prob.accept <- min(1,post.rat)
rand <- runif(1)
if(rand<=prob.accept){
oldguess <- newguess
guesses[counter,] <- newguess
}else{
guesses[counter,] <- oldguess
}
counter=counter+1
}
# visualize!
image(x=shapevec,y=scalevec,z=surface2D,zlim=c(-1000,-30),col=topo.colors(12))
contour(x=shapevec,y=scalevec,z=surface2D,levels=c(-30,-40,-80,-500),add=T)
lines(guesses,col="red")
# Get more MCMC samples --------------
chain.length <- 100
oldguess <- startingvals
guesses <- matrix(0,nrow=chain.length,ncol=2)
colnames(guesses) <- names(startingvals)
guesses[1,] <- startingvals
counter <- 2
while(counter <= chain.length){
newguess <- newGuess(oldguess)
post.rat <- PosteriorRatio2(oldguess,newguess)
prob.accept <- min(1,post.rat)
rand <- runif(1)
if(rand<=prob.accept){
oldguess <- newguess
guesses[counter,] <- newguess
}else{
guesses[counter,] <- oldguess
}
counter=counter+1
}
# visualize!
image(x=shapevec,y=scalevec,z=surface2D,zlim=c(-1000,-30),col=topo.colors(12))
contour(x=shapevec,y=scalevec,z=surface2D,levels=c(-30,-40,-80,-500),add=T)
lines(guesses,col="red")
# And more... -------------------
chain.length <- 1000
oldguess <- startingvals
guesses <- matrix(0,nrow=chain.length,ncol=2)
colnames(guesses) <- names(startingvals)
guesses[1,] <- startingvals
counter <- 2
while(counter <= chain.length){
newguess <- newGuess(oldguess)
post.rat <- PosteriorRatio2(oldguess,newguess)
prob.accept <- min(1,post.rat)
rand <- runif(1)
if(rand<=prob.accept){
oldguess <- newguess
guesses[counter,] <- newguess
}else{
guesses[counter,] <- oldguess
}
counter=counter+1
}
# visualize!
image(x=shapevec,y=scalevec,z=surface2D,zlim=c(-1000,-30),col=topo.colors(12))
contour(x=shapevec,y=scalevec,z=surface2D,levels=c(-30,-40,-80,-500),add=T)
lines(guesses,col="red")
# And more... -------------------
chain.length <- 10000
oldguess <- startingvals
guesses <- matrix(0,nrow=chain.length,ncol=2)
colnames(guesses) <- names(startingvals)
guesses[1,] <- startingvals
counter <- 2
while(counter <= chain.length){
newguess <- newGuess(oldguess)
post.rat <- PosteriorRatio2(oldguess,newguess)
prob.accept <- min(1,post.rat)
rand <- runif(1)
if(rand<=prob.accept){
oldguess <- newguess
guesses[counter,] <- newguess
}else{
guesses[counter,] <- oldguess
}
counter=counter+1
}
# visualize!
image(x=shapevec,y=scalevec,z=surface2D,zlim=c(-1000,-30),col=topo.colors(12))
contour(x=shapevec,y=scalevec,z=surface2D,levels=c(-30,-40,-80,-500),add=T)
lines(guesses,col="red")
# Evaluate "traceplot" for the MCMC samples... ---------------------
## Shape parameter
plot(1:chain.length,guesses[,'shape'],type="l",main="shape parameter",xlab="iteration",ylab="shape")
guesses
oldguess
install.packages("titanic")
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
library(titanic)
data(titanic::titanic_train)
titanic::titanic_train
titanic <- titanic_train
View(titanic)
?titanic
?titanic_train
library(titanic)
titanic <- titanic::titanic_train
## write jags code
fn <- "titanic_jags.txt"
library(titanic)
titanic <- titanic::titanic_train
## write jags code
fn <- "titanic_jags.txt"
cat("
model{
# likelihood
for(p in 1:npassengers){
logit(psurv[p]) <- psurv0.l[class[p]] + b.fare * fare[p]  + b.age * age[p] + b.female * is.fem[p]
survived[p] ~ dbern(psurv[p])
}
# priors
b.fare ~ dnorm(0,0.1)  # slightly regularized prior
b.age ~ dnorm(0,0.1)
b.female ~ dnorm(0,0.1)
psurv0[1] ~ dunif(0,1)  # flat prior from 0 to 1 on p scale
psurv0[2] ~ dunif(0,1)
psurv0[3] ~ dunif(0,1)
for(i in 1:3){    # convert to logit scale
psurv0.l[i] <- log(psurv[i]/(1-psurv[i]))
}
## interpolate missing data
meanage ~ dnorm(0,.1)
sdage ~ dunif(0,5)
precage <- pow(sdage,-2)
for(p in 1:npassengers){
age[p] ~ dnorm(meanage,precage)   # DATA NODE
}
} ",file=fn)
dat <- list(
npassengers = nrow(titanic),
class = titanic$Pclass,
fare = (titanic$Fare-mean(titanic$Fare))/sd(titanic$Fare),
age = (titanic$Age-mean(titanic$Age,na.rm = T))/sd(titanic$Age,na.rm=T),
is.fem = ifelse(titanic$Sex=="female",1,0),
survived = titanic$Survived
)
dat
params <- c("psurv0","b.fare","b.age","b.female","sdage","meanage")
library(jagsUI)
jags(dat, parameters.to.save=params, model.file=fn,
n.chains=3, n.adapt=1000, n.iter=10000, n.burnin=5000, n.thin=2,
parallel=FALSE)
## write jags code
fn <- "titanic_jags.txt"
cat("
model{
# likelihood
for(p in 1:npassengers){
logit(psurv[p]) <- psurv0.l[class[p]] + b.fare * fare[p]  + b.age * age[p] + b.female * is.fem[p]
survived[p] ~ dbern(psurv[p])
}
# priors
b.fare ~ dnorm(0,0.1)  # slightly regularized prior
b.age ~ dnorm(0,0.1)
b.female ~ dnorm(0,0.1)
psurv0[1] ~ dunif(0,1)  # flat prior from 0 to 1 on p scale
psurv0[2] ~ dunif(0,1)
psurv0[3] ~ dunif(0,1)
for(i in 1:3){    # convert to logit scale
psurv0.l[i] <- log(psurv0[i]/(1-psurv0[i]))
}
## interpolate missing data
meanage ~ dnorm(0,.1)
sdage ~ dunif(0,5)
precage <- pow(sdage,-2)
for(p in 1:npassengers){
age[p] ~ dnorm(meanage,precage)   # DATA NODE
}
} ",file=fn)
dat <- list(
npassengers = nrow(titanic),
class = titanic$Pclass,
fare = (titanic$Fare-mean(titanic$Fare))/sd(titanic$Fare),
age = (titanic$Age-mean(titanic$Age,na.rm = T))/sd(titanic$Age,na.rm=T),
is.fem = ifelse(titanic$Sex=="female",1,0),
survived = titanic$Survived
)
dat
params <- c("psurv0","b.fare","b.age","b.female","sdage","meanage")
library(jagsUI)
jags(dat, parameters.to.save=params, model.file=fn,
n.chains=3, n.adapt=1000, n.iter=10000, n.burnin=5000, n.thin=2,
parallel=FALSE)
rmd2rscript <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- "echo"
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- !grepl(input, pattern = stringToFind2, perl = TRUE)   # is it hidden (echo=FALSE)
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
# rmd2rscript_labanswers <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts: see NRESlabs folder!!
#   outfile <- gsub(".Rmd",".R",infile)
#   close( file( outfile, open="w" ) )   # clear output file
#   con1 <- file(infile,open="r")
#   con2 <- file(outfile,"w")
#   stringToFind <- "```{r*"
#   stringToFind2 <- c("answer","test","solution")
#   isrblock <- FALSE
#   #count=0
#   blocknum=0
#
#   while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
#     isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
#     showit <- grepl(input, pattern = stringToFind2[1], perl = TRUE) | grepl(input, pattern = stringToFind2[2])
#     if(isrblock){
#       blocknum=blocknum+1
#       while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
#         if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#         #count=count+1
#       }
#       isrblock=FALSE
#     }
#   }
#   closeAllConnections()
# }
rmd2rscript("LAB5.Rmd")
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
slugs<-read.table( 'http://www.bio.ic.ac.uk/research/mjcraw/statcomp/data/slugsurvey.txt', header=TRUE)
head(slugs)
write.csv(slugs,file = "slugs.csv", row.names = F)
table(slugs$slugs,slugs$field)
out <- table(slugs$slugs,slugs$field)
barplot(out)
barplot(t(out), beside=TRUE, angle=c(45,135), density=c(20,20), col=c('black','red'), legend.text=TRUE, xlab='# of slugs', ylab='frequency')
t(out)
coords<-barplot(t(out), beside=TRUE, angle=c(45,135), density=c(20,20), ylim=c(0,27), col=c('black','red'), xlab='# of slugs', ylab='frequency')
box()
legend(coords[1,8], 26, c('nursery','rookery'), density=c(20,20), angle=c(45,135), fill=c('black','red'), cex=c(.8,.8),bty='n')
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
slugs<-read.table( 'http://www.bio.ic.ac.uk/research/mjcraw/statcomp/data/slugsurvey.txt', header=TRUE)
head(slugs)
# write.csv(slugs,file = "slugs.csv", row.names = F)
table(slugs$slugs,slugs$field)
barplot(t(out), beside=TRUE, angle=c(45,135), density=c(20,20), col=c('black','red'), legend.text=TRUE, xlab='# of slugs', ylab='frequency')
poi.1<-function(data,p) -sum(log(dpois(data$slugs,lambda=p)))
mean(slugs$slugs)
?nlm
out1 <- nlm(function(p) poi.1(slugs,p),2)
out1
poi.2<-function(data,p) {
field.dummy<-as.numeric(data$field)-1
mylambda<-p[1]+p[2]*field.dummy
negloglike<- -sum(dpois(data$slugs,lambda=mylambda,log=T))
negloglike
}
as.numeric(slugs$field)
as.numeric(as.factor(slugs$field))
poi.2<-function(data,p) {
field.dummy<-as.numeric(as.factor(slugs$field))-1
mylambda<-p[1]+p[2]*field.dummy
negloglike<- -sum(dpois(data$slugs,lambda=mylambda,log=T))
negloglike
}
tapply(slugs$slugs,slugs$field,mean)
out2 <- nlm(function(p) poi.2(slugs,p),c(1.2,1))
out2
out1$minimum
out2$minimum
my.aic<-function(output) -2*(-output$minimum) + 2*length(output$estimate)
my.aic
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
slugs<-read.table( 'http://www.bio.ic.ac.uk/research/mjcraw/statcomp/data/slugsurvey.txt', header=TRUE)
head(slugs)
# write.csv(slugs,file = "slugs.csv", row.names = F)
table(slugs$slugs,slugs$field)
barplot(t(out), beside=TRUE, angle=c(45,135), density=c(20,20), col=c('black','red'), legend.text=TRUE, xlab='# of slugs', ylab='frequency')
my.aic<-function(output) -2*(-output$minimum) + 2*length(output$estimate)
unlink("LAB5_cache", recursive = TRUE)
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
slugs<-read.table( 'http://www.bio.ic.ac.uk/research/mjcraw/statcomp/data/slugsurvey.txt', header=TRUE)
head(slugs)
# write.csv(slugs,file = "slugs.csv", row.names = F)
table(slugs$slugs,slugs$field)
table(slugs$slugs,slugs$field)
barplot(t(out), beside=TRUE, angle=c(45,135), density=c(20,20), col=c('black','red'), legend.text=TRUE, xlab='# of slugs', ylab='frequency')
out <- table(slugs$slugs,slugs$field)
out
barplot(t(out), beside=TRUE, angle=c(45,135), density=c(20,20), col=c('black','red'), legend.text=TRUE, xlab='# of slugs', ylab='frequency')
out2 <- nlm(function(p) poi.2(slugs,p),c(1.2,1))
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
slugs<-read.table( 'http://www.bio.ic.ac.uk/research/mjcraw/statcomp/data/slugsurvey.txt', header=TRUE)
head(slugs)
# write.csv(slugs,file = "slugs.csv", row.names = F)
out <- table(slugs$slugs,slugs$field)
out
barplot(t(out), beside=TRUE, angle=c(45,135), density=c(20,20), col=c('black','red'), legend.text=TRUE, xlab='# of slugs', ylab='frequency')
poi.1<-function(data,p) -sum(log(dpois(data$slugs,lambda=p)))
mean(slugs$slugs)
out1 <- nlm(function(p) poi.1(slugs,p),2)
out1
as.numeric(as.factor(slugs$field))
poi.2<-function(data,p) {
field.dummy<-as.numeric(as.factor(slugs$field))-1
mylambda<-p[1]+p[2]*field.dummy
negloglike<- -sum(dpois(data$slugs,lambda=mylambda,log=T))
return(negloglike)
}
tapply(slugs$slugs,slugs$field,mean)
out2 <- nlm(function(p) poi.2(slugs,p),c(1.2,1))
out2
out1$minimum
out2$minimum
my.aic<-function(output) -2*(-output$minimum) + 2*length(output$estimate)
my.aic(out1)
my.aic(out2)
zip1<-function(data,p) {
lambda<-p[1]
theta<-p[2]
zero.term<-sum(log(theta+(1-theta)* dpois(data$slugs[data$slugs==0], lambda)))
nonzero.term<-sum(log((1- theta)* dpois(data$slugs[data$slugs>0], lambda)))
negloglike<- -(zero.term+nonzero.term)
negloglike
}
slugs
mod1 <- glm(slugs~1, data=slugs, family=poisson())
mod2 <- glm(slugs~field, data=slugs, family=poisson())
logLik(mod1)
out1$minimum
logLik(mod2)
mod2 <- glm(slugs~field, data=slugs, family=poisson())
mod2
my.aic<-function(output) -2*(-output$minimum) + 2*length(output$estimate)
my.aic(out1)
my.aic(out2)
my.aic(out1)
aic(mod1)
AIC(mod1)
my.aic(out1)
AIC(mod1,mod2)
zip1<-function(data,p) {
lambda<-p[1]
theta<-p[2]
zero.term<-sum(log(theta+(1-theta)* dpois(data$slugs[data$slugs==0], lambda)))   # stochastic process #1
nonzero.term<-sum(log((1- theta)* dpois(data$slugs[data$slugs>0], lambda)))      # stochastic process #2
negloglike<- -(zero.term+nonzero.term)
negloglike
}
zip1<-function(data,p) {
lambda<-p[1]
theta<-p[2]
zero.term<-sum(log(theta+(1-theta)* dpois(data$slugs[data$slugs==0], lambda)))   # stochastic process #1
nonzero.term<-sum(log((1- theta)* dpois(data$slugs[data$slugs>0], lambda)))      # stochastic process #2
negloglike<- -(zero.term+nonzero.term)
negloglike
}
library(glmmTMB)
library(DHARMa)
mean(slugs$slugs[slugs$slugs>0])
table(slugs$slugs)[1]/sum(table(slugs$slugs))
out7 <- nlm(function(p) zip1(slugs,p),c(3,.4))
out7
?glmmTMB
mod7 <- glmmTMB(slugs~1,slugs,family=poisson(),ziformula = ~1)
out7
logLik(mod7)
logLik(mod1)
my.aic(out7)
AIC(mod1,mod2,mod7)
# different lambda, same theta
zip2<-function(data,p) {
field.dummy<-as.numeric(as.factor(slugs$field))-1
mylambda<-p[1]+p[3]*field.dummy
theta<-p[2]
zero.term<-sum(ifelse(data$slugs==0,log(theta+(1-theta)* dpois(data$slugs,lambda=mylambda)),0))
nonzero.term<-sum(ifelse(data$slugs>0,log((1-theta)* dpois(data$slugs,lambda=mylambda)),0))
negloglike<- -(zero.term+nonzero.term)
negloglike
}
# different lambda, same theta
zip2<-function(data,p) {
field.dummy<-as.numeric(as.factor(slugs$field))-1
mylambda<-p[1]+p[3]*field.dummy
theta<-p[2]
zero.term<-sum(ifelse(data$slugs==0,log(theta+(1-theta)* dpois(data$slugs,lambda=mylambda)),0))
nonzero.term<-sum(ifelse(data$slugs>0,log((1-theta)* dpois(data$slugs,lambda=mylambda)),0))
negloglike<- -(zero.term+nonzero.term)
negloglike
}
mean(slugs$slugs[slugs$slugs>0])
table(slugs$slugs)[1]/sum(table(slugs$slugs))
out7 <- nlm(function(p) zip1(slugs,p),c(3,.4))
out7
mod7 <- glmmTMB(slugs~1,slugs,family=poisson(),ziformula = ~1)
mod7 <- glmmTMB(slugs~1,slugs,family=poisson(),ziformula = ~1)
logLik(mod7)
# different lambda, same theta
zip2<-function(data,p) {
field.dummy<-as.numeric(as.factor(slugs$field))-1
mylambda<-p[1]+p[3]*field.dummy
theta<-p[2]
zero.term<-sum(ifelse(data$slugs==0,log(theta+(1-theta)* dpois(data$slugs,lambda=mylambda)),0))
nonzero.term<-sum(ifelse(data$slugs>0,log((1-theta)* dpois(data$slugs,lambda=mylambda)),0))
negloglike<- -(zero.term+nonzero.term)
negloglike
}
zip2.alt<-function(data,p) {
field.dummy<-as.numeric(slugs$field)-1
mylambda<-p[1]+p[3]*field.dummy
theta<-p[2]
negloglike<- -sum(ifelse(data$slugs==0,log(theta+(1-theta)* dpois(data$slugs,lambda=mylambda)),log((1-theta)*dpois(data$slugs,lambda=mylambda))))
negloglike
}
tapply(slugs$slugs[slugs$slugs>0],slugs$field[slugs$slugs>0],mean)
out8 <- nlm(function(p) zip2(slugs,p),c(3.4,.42,-.4))
zip2.alt<-function(data,p) {
field.dummy<-as.numeric(as.factor(slugs$field))-1
mylambda<-p[1]+p[3]*field.dummy
theta<-p[2]
negloglike<- -sum(ifelse(data$slugs==0,log(theta+(1-theta)* dpois(data$slugs,lambda=mylambda)),log((1-theta)*dpois(data$slugs,lambda=mylambda))))
negloglike
}
tapply(slugs$slugs[slugs$slugs>0],slugs$field[slugs$slugs>0],mean)
out8 <- nlm(function(p) zip2(slugs,p),c(3.4,.42,-.4))
zip2
out8
