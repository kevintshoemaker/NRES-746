rmd2rscript <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- "echo"
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- !grepl(input, pattern = stringToFind2, perl = TRUE)   # is it hidden (echo=FALSE)
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
# rmd2rscript_labanswers <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts: see NRESlabs folder!!
#   outfile <- gsub(".Rmd",".R",infile)
#   close( file( outfile, open="w" ) )   # clear output file
#   con1 <- file(infile,open="r")
#   con2 <- file(outfile,"w")
#   stringToFind <- "```{r*"
#   stringToFind2 <- c("answer","test","solution")
#   isrblock <- FALSE
#   #count=0
#   blocknum=0
#
#   while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
#     isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
#     showit <- grepl(input, pattern = stringToFind2[1], perl = TRUE) | grepl(input, pattern = stringToFind2[2])
#     if(isrblock){
#       blocknum=blocknum+1
#       while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
#         if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#         #count=count+1
#       }
#       isrblock=FALSE
#     }
#   }
#   closeAllConnections()
# }
rmd2rscript("SpatialRegression.Rmd")
rmd2rscript <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- "echo"
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- !grepl(input, pattern = stringToFind2, perl = TRUE)   # is it hidden (echo=FALSE)
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
# rmd2rscript_labanswers <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts: see NRESlabs folder!!
#   outfile <- gsub(".Rmd",".R",infile)
#   close( file( outfile, open="w" ) )   # clear output file
#   con1 <- file(infile,open="r")
#   con2 <- file(outfile,"w")
#   stringToFind <- "```{r*"
#   stringToFind2 <- c("answer","test","solution")
#   isrblock <- FALSE
#   #count=0
#   blocknum=0
#
#   while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
#     isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
#     showit <- grepl(input, pattern = stringToFind2[1], perl = TRUE) | grepl(input, pattern = stringToFind2[2])
#     if(isrblock){
#       blocknum=blocknum+1
#       while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
#         if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#         #count=count+1
#       }
#       isrblock=FALSE
#     }
#   }
#   closeAllConnections()
# }
rmd2rscript("SpatialRegression.Rmd")
# Load libraries ----
library(codep)
library(vegan)
library(datasets)
library(tidyverse)
data(Doubs)
?Doubs #Information about the Doubs Fish data set.
Doubs
data(Doubs)
View(Doubs.env)
View(Doubs.fish)
species <- as.data.frame(Doubs.fish[-8,])
vars <- as.data.frame(cbind(Doubs.env[-8,],Doubs.geo[-8,]))
CHA.alt <- species$CHA + 1 #get rid of zeros to prep for log link
COGO_mod <- glm(CHA.alt ~ pH + flo + oxy, data = vars, family = Gamma(link = "log"))
summary(COGO_mod) #oxygen is significantly positive!
(Y.hmm <- data.frame(hydrophillic_1 = c(1, 0, 0), hydrophillic_2 = c(1, 1, 0),
mesic_1 = c(0, 1, 0), mesic_2 = c(0,4,0),
xeric_1 = c(0, 1, 3),xeric_2 = c(0, 0, 2),
row.names = c("sample_1_wet", "sample_2_intermediate",
"sample_3_dry")))
# Calculate Euclidean distance using the dist() function
(Y.hmm.DistEu <- as.matrix(dist(x = Y.hmm, method = "euclidean")))
# Calculate Euclidean Distance by Hand
calc_eu_dist <- function(spe_abun_df) {
# Create output matrix
output <- as.data.frame(matrix(NA, nrow = nrow(spe_abun_df), ncol = nrow(spe_abun_df)))
# Index through the rows of the data frame
for (i in 1:nrow(spe_abun_df)) {
x1 <- spe_abun_df[i, ]
for (t in 1:nrow(spe_abun_df)) {
x2 <- spe_abun_df[t,]
# Calculate euclidean distance and place distance into output data frame
output[i,t] <- sqrt(sum((x1 - x2)^2))
}
}
# Return output
return(output)
}
# Run Euclidean distance by hand function
(Y.hmm_eu_dist <- calc_eu_dist(Y.hmm))
(Y.hmm.BCdist <- vegan::vegdist(Y.hmm, method = "bray", binary = FALSE))
(Y.hmm.BCdist.matrix <- as.matrix(Y.hmm.BCdist))
# Calculate Bray-Curtis coefficient by hand
calc_bc_dist <- function(spe_abun_df) {
# Create output matrix
output <- as.data.frame(matrix(NA, nrow = nrow(spe_abun_df), ncol = nrow(spe_abun_df)),
row.names = rownames(spe_abun_df))
colnames(output) <- rownames(spe_abun_df)
# Index through the rows of the data frame
for (i in 1:nrow(spe_abun_df)) {
x1 <- spe_abun_df[i, ]
for (t in 1:nrow(spe_abun_df)) {
x2 <- spe_abun_df[t,]
# Create empty data frame to find the minimum values of each species between two sites
comp_df <- as.data.frame(matrix(nrow = 2, ncol = ncol(spe_abun_df)))
# Place the site values into the data frame
comp_df[1,] = x1
comp_df[2,] = x2
# Find the minimum abundance values of each species and sum them.
min_abundances <- apply(comp_df, 2, min)
W <- sum(min_abundances)
# Sum the abundances of site 1
A = sum(x1)
# Sum the abundances of site 2
B = sum(x2)
# Calculate the Bray-Curtis coefficient
bc_dist <- (1 - ((2 * W) / (A + B)))
# Place the BC coefficient into the output data frame
output[i,t] <- bc_dist
}
}
# Return output
return(output)
}
# Run Bray-Curtis coefficient by hand function
calc_bc_dist(Y.hmm)
data(Doubs)
species <- Doubs.fish[-8,]
spe.hel <- as.data.frame(vegan::decostand(species, method = "hellinger"))
head(spe.hel)
# Compute covarience matrix by hand
comp_cov <- function(data) {
output_df <- as.data.frame(matrix(NA, nrow = ncol(spe.hel), ncol = ncol(spe.hel)), row.names = colnames(data))
colnames(output_df) <- colnames(data)
for (i in 1:ncol(data)) {
mean.dif.x1 <- data[,i] - mean(data[,i])
for (p in 1:ncol(data)) {
mean.dif.x2 <- data[,p] - mean(data[,p])
output <- mean.dif.x1 * mean.dif.x2
output_df[i, p] <- sum(output)/(nrow(data)-1)
}
}
return(output_df)
}
cov_matrix <- comp_cov(spe.hel)
# Compare with built-in function
cov_base_func <- cov(spe.hel)
eigen_decomp <- eigen(cov_matrix)
# Extract Eigenvalues
(eig_values <- eigen_decomp$values)
# Extract Eigenvalues
(eig_values <- eigen_decomp$values)
# Extract Eigenvectors
(eig_vectors <- -eigen_decomp$vectors)
rownames(eig_vectors) = colnames(spe.hel)
# Extract the first two eigenvectors
eig_vec_1 <- eig_vectors[,1]
eig_vec_2 <- eig_vectors[,2]
# Calculate the estimated variance for each eigenvalue
(e_var <- eig_values / (nrow(spe.hel) - 1))
# Data frame with variance percentages
var_per <- data.frame(
PC  = c("PC01", "PC02", "PC03", "PC04", "PC05", "PC06","PC07", "PC08", "PC09",
"PC10", "PC11", "PC12", "PC13", "PC14", "PC15", "PC16", "PC17", "PC18",
"PC19", "PC20", "PC21", "PC22", "PC23", "PC24", "PC25", "PC26", "PC27"),
PER = c(e_var) * 100 / sum(e_var)) # Calculate the percentage
# Scree plot to show amount of variance accounted by each principal component
barplot(PER ~ PC, data = var_per,
xlab = "Principal Components",
ylab = "Percent of Variation %")
# Kaiser-Guttman Criterion
eig_val_PC <- data.frame(
PC = c("PC01", "PC02", "PC03", "PC04", "PC05", "PC06","PC07", "PC08", "PC09",
"PC10", "PC11", "PC12", "PC13", "PC14", "PC15", "PC16", "PC17", "PC18",
"PC19", "PC20", "PC21", "PC22", "PC23", "PC24", "PC25", "PC26", "PC27"),
EV = eig_values)
# Plot principal components and overlay average eigenvalue line
barplot(EV ~ PC, data = eig_val_PC,
xlab = "Principal Components",
ylab = "Eigenvalues")
abline(h = mean(eig_values), col = "red")
# Broken stick Model
broken_stick <- function(eig_values) {
# Calculate Broken Stick Model
n = length(eig_values)
bsm = data.frame(j=seq(1:n), prop_var=0)
bsm$prop_var[1] = 1/n
for (i in 2:n) {
bsm$prop_var[i] = bsm$prop_var[i-1] + (1/(n + 1 - i))
}
bsm$prop_var = 100*bsm$prop_var/n
# Plot Broken Stick Modol Over
barplot(t(cbind(100*eig_values/sum(eig_values), bsm$p[n:1])),
beside=TRUE,
main="Broken Stick Model",
col=c("red","blue"),
las=2,
xlab = "Principal Components", ylab = "Percent of Variation (%)")
legend("topright", c("Eigenvalues", "Broken stick model"),
pch=15,
col=c("red","blue"),
bty="n")
}
broken_stick(eig_values)
eig_vec_kgc <- eig_values[eig_values > mean(eig_values)]
sum(var_per$PER[1:length(eig_vec_kgc)])
# Plot only the first principal component
plot(BAR ~ BLA, col = as.factor(rownames(spe.hel)), pch = 19,
xlim = c(-0.25,0.5), ylim = c(-0.5,0.5),
data = (spe.hel), xlab = "BLA (Standardized)", ylab = "BAR (Standardized)")
abline(v=0 , h=0, col = "dark gray")
# Overlap first eigenvector/principal component
abline(0, eig_vec_1[11]/eig_vec_1[6], col='purple')
# Plot lines from the first eigenvector to points
line1 <- c(0, eig_vec_1[11]/eig_vec_1[6])
perp.segment.coord <- function(x0, y0, line1){
a <- line1[1]  #intercept
b <- line1[2]  #slope
x1 <- (x0 + b * y0 - a * b)/(1 + b^2)
y1 <- a + b * x1
list(x0 = x0, y0 = y0,
x1 = x1, y1 = y1)
}
ss <- perp.segment.coord(spe.hel[,6], spe.hel[,11], line1)
segments(x0 = ss$x0, x1 = ss$x1, y0 = ss$y0, y1 = ss$y1, col = 'purple')
with(spe.hel, text(BAR ~ BLA, labels = as.factor(rownames(spe.hel)), pos = 1, cex=1))
title(main = "First Principal Component over the Standardized Data",
sub = "Purple Lines Horizontal to the First Principal Components is the Variance", cex.sub = 0.75)
# Plot both the first and second principal component
plot(BAR ~ BLA, col = as.factor(rownames(spe.hel)), pch = 19,
xlim = c(-0.25,0.5), ylim = c(-0.5,0.5),
data = (spe.hel), xlab = "BLA (Standardized)", ylab = "BAR (Standardized)")
abline(v=0 , h=0, col = "dark gray")
# Overlap pertinent eigenvectors
abline(0, eig_vec_1[11]/eig_vec_1[6], col='purple')
abline(0, eig_vec_2[11]/eig_vec_2[6], col='orange')
# Plot the lines from second eigenvector to points
line2 <- c(0, eig_vec_2[11]/eig_vec_2[6])
ss <- perp.segment.coord(spe.hel[,6], spe.hel[,11], line2)
segments(x0 = ss$x0, x1 = ss$x1, y0 = ss$y0, y1 = ss$y1,col = 'orange')
with(spe.hel, text(BAR ~ BLA, labels = as.factor(rownames(spe.hel)),pos = 1, cex=1))
title(main = "First (Purple) and Second (Orange) Principal Component over the Standardized Data",
cex.main = 0.8, sub = "Lines Horizontal to the Principal Components are the Variance", cex.sub = 0.75)
# Get variable loading scores
variable.loads <- data.frame(
PC01 = eig_vec_1, # First eigenvector
PC02 = eig_vec_2  # Second eigenvector
)
head(variable.loads)
# Get site loading scores
loading.scores <- as.data.frame(as.matrix(spe.hel) %*% eig_vectors)
colnames(loading.scores) = c("PC01", "PC02", "PC03", "PC04", "PC05", "PC06","PC07", "PC08",
"PC09", "PC10", "PC11", "PC12", "PC13", "PC14", "PC15", "PC16",
"PC17", "PC18", "PC19", "PC20", "PC21", "PC22", "PC23", "PC24",
"PC25", "PC26", "PC27")
head(loading.scores)
# Set plot parameters
par(mar = c(5, 5, 10, 5),
mgp = c(2, 1, 0))
# Plot site loading scores
plot(loading.scores[,2] ~ loading.scores[,1],
xlab = 'PC1', ylab = "PC2",
xlim = c(-1,1), ylim  = c(-1,1),col = as.factor(rownames(loading.scores)), pch = 19)
# Set plot parameters
par(mar = c(5, 5, 10, 5),
mgp = c(2, 1, 0))
# Plot site loading scores
plot(loading.scores[,2] ~ loading.scores[,1],
xlab = 'PC1', ylab = "PC2",
xlim = c(-1,1), ylim  = c(-1,1),col = as.factor(rownames(loading.scores)), pch = 19)
abline(v = 0, col = "orange")
abline(h = 0, col = "purple")
with(loading.scores, text(PC02 ~ PC01, labels = as.factor(rownames(loading.scores)),pos = 1, cex=1))
par(new=TRUE)
# Overlay the variable loading scores
plot(PC02 ~ PC01,
xlim = c(-1, 1), ylim = c(-1,1),
col = "red", pch = 8, axes = F, xlab = "", ylab = "",
data = variable.loads)
View(variable.loads)
rmd2rscript <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- "echo"
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- !grepl(input, pattern = stringToFind2, perl = TRUE)   # is it hidden (echo=FALSE)
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
# rmd2rscript_labanswers <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts: see NRESlabs folder!!
#   outfile <- gsub(".Rmd",".R",infile)
#   close( file( outfile, open="w" ) )   # clear output file
#   con1 <- file(infile,open="r")
#   con2 <- file(outfile,"w")
#   stringToFind <- "```{r*"
#   stringToFind2 <- c("answer","test","solution")
#   isrblock <- FALSE
#   #count=0
#   blocknum=0
#
#   while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
#     isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
#     showit <- grepl(input, pattern = stringToFind2[1], perl = TRUE) | grepl(input, pattern = stringToFind2[2])
#     if(isrblock){
#       blocknum=blocknum+1
#       while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
#         if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#         #count=count+1
#       }
#       isrblock=FALSE
#     }
#   }
#   closeAllConnections()
# }
rmd2rscript("IPM_lecture.Rmd")
library(IPMbook)
library(jagsUI)
data(woodchat5)
str(woodchat5)
marr <- marrayAge(woodchat5$ch, woodchat5$age)
jags.data <- list(marr.j=marr[,,1], marr.a=marr[,,2], n.occasions=dim(marr)[2],
rel.j=rowSums(marr[,,1]), rel.a=rowSums(marr[,,2]), J=woodchat5$repro[,1],
year=woodchat5$repro[,2], age=woodchat5$repro[,3], C=woodchat5$count, pNinit=dUnif(1, 300))
str(jags.data)
jags.data
cat(file="model4.txt", "
model {
# Priors and linear models
for (t in 1:(n.occasions-1)){
logit.sj[t] ~ dnorm(mu.sj, tau.sj)    # survival with temporal stochasticity
sj[t] <- ilogit(logit.sj[t])          # Back-transformation from logit scale
logit.sa[t] ~ dnorm(mu.sa, tau.sa)
sa[t] <- ilogit(logit.sa[t])          # Back-transformation from logit scale
p[t] <- mean.p                        # detection process
}
for (t in 1:n.occasions){
log.f[1,t] ~ dnorm(mu.f[1], tau.f[1])     # fecundity with temporal stochasticity
f[1,t] <- exp(log.f[1,t]) # Back-transformation from log scale
log.f[2,t] ~ dnorm(mu.f[2], tau.f[2])
f[2,t] <- exp(log.f[2,t]) # Back-transformation from log scale
}
mean.sj ~ dunif(0, 1)
mu.sj <- logit(mean.sj) # Logit transformation
mean.sa ~ dunif(0, 1)
mu.sa <- logit(mean.sa) # Logit transformation
sigma.sj ~ dunif(0, 3)
tau.sj <- pow(sigma.sj, -2)
sigma.sa ~ dunif(0, 3)
tau.sa <- pow(sigma.sa, -2)
for (j in 1:2){
mean.f[j] ~ dunif(0, 10)
mu.f[j] <- log(mean.f[j]) # Log transformation
sigma.f[j] ~ dunif(0, 3)
tau.f[j] <- pow(sigma.f[j], -2)
}
mean.p ~ dunif(0, 1)
sigma ~ dunif(0.5, 100)
tau <- pow(sigma, -2)
# Population count data (state-space model)
# Model for initial stage-spec. population sizes: discrete uniform priors
N[1,1] ~ dcat(pNinit)
N[2,1] ~ dcat(pNinit)
# Process model over time: our model of population dynamics
for (t in 1:(n.occasions-1)){
N[1,t+1] ~ dpois(N[1,t] * f[1,t] / 2 * sj[t] + N[2,t] * f[2,t] / 2 * sj[t])
N[2,t+1] ~ dbin(sa[t], N[1,t] + N[2,t])
}
# Observation model
for (t in 1:n.occasions){
C[t] ~ dnorm(N[1,t] + N[2,t], tau)
}
# Productivity data (Poisson regression model)
for (i in 1:length(J)){
J[i] ~ dpois(f[age[i],year[i]])
}
# Capture-recapture data (CJS model with multinomial likelihood)
# Define the multinomial likelihood
for (t in 1:(n.occasions-1)){
marr.j[t,1:n.occasions] ~ dmulti(pr.j[t,], rel.j[t])
marr.a[t,1:n.occasions] ~ dmulti(pr.a[t,], rel.a[t])
}
# Define the cell probabilities of the m-arrays
for (t in 1:(n.occasions-1)){
# Main diagonal
q[t] <- 1 - p[t] # Probability of non-recapture
pr.j[t,t] <- sj[t] * p[t]
pr.a[t,t] <- sa[t] * p[t]
# Above main diagonal
for (j in (t+1):(n.occasions-1)){
pr.j[t,j] <- sj[t] * prod(sa[(t+1):j]) * prod(q[t:(j-1)]) * p[j]
pr.a[t,j] <- prod(sa[t:j]) * prod(q[t:(j-1)]) * p[j]
} #j
# Below main diagonal
for (j in 1:(t-1)){
pr.j[t,j] <- 0
pr.a[t,j] <- 0
} #j
} #t
# Last column: probability of non-recapture
for (t in 1:(n.occasions-1)){
pr.j[t,n.occasions] <- 1-sum(pr.j[t,1:(n.occasions-1)])
pr.a[t,n.occasions] <- 1-sum(pr.a[t,1:(n.occasions-1)])
}
# Derived parameters
# Annual population growth rate (added 0.001 to avoid possible division by 0)
for (t in 1:(n.occasions-1)){
ann.growth.rate[t] <- (N[1,t+1] + N[2,t+1]) / (N[1,t] + N[2,t] + 0.001)
}
# Total population size
for (t in 1:n.occasions){
Ntot[t] <- N[1,t] + N[2,t]
}
}  #
")
# Initial values
inits <- function(){list(mean.sj=runif(1, 0, 0.5))}
# Parameters monitored
parameters <- c("mean.sj", "mean.sa", "mean.f", "mean.p", "sigma.sj", "sigma.sa", "sigma.f",
"sigma", "sj", "sa", "f", "N", "ann.growth.rate", "Ntot")
# MCMC settings
ni <- 12000; nb <- 2000; nc <- 3; nt <- 2; na <- 1000
# Call JAGS (ART 1 min), check convergence and summarize posteriors
out4 <- jags(jags.data, inits, parameters, "model4.txt", n.iter=ni, n.burnin=nb, n.chains=nc,
n.thin=nt, n.adapt=na, parallel=TRUE)
#traceplot(out4) # Warning: there are a lot of estimated parameters
print(out4, 3)
mag <- 1.25
cex.tif <- mag * 1.25
lwd.tif <- 3 * mag
op <- par(mar=c(4, 4, 3, 0), las=1, cex=cex.tif, lwd=lwd.tif)
u <- col2rgb("grey82")
T <- length(woodchat5$count)
col.pol <- rgb(u[1], u[2], u[3], alpha=100, maxColorValue=255)
plot(out4$mean$Ntot, type="n",
ylim=range(c(out4$q2.5$Ntot, out4$q97.5$Ntot, woodchat5$count)),
ylab="Population size", xlab="Year", las=1, cex=1.5, axes=FALSE)
axis(2, las=1, lwd=lwd.tif)
axis(2, at=c(90, 110, 130, 150), labels=NA, tcl=-0.25, lwd=lwd.tif)
axis(1, at=1:T, labels=NA, tcl=-0.25, lwd=lwd.tif)
axis(1, at=c(5, 10, 15, 20), labels=c(5, 10, 15, 20), tcl=-0.5, lwd=lwd.tif)
polygon(c(1:T, T:1), c(out4$q2.5$Ntot, out4$q97.5$Ntot[T:1]), border=NA, col=col.pol)
points(out4$mean$Ntot, type="b", col="black", pch=16, lty=1, lwd=lwd.tif)
points(woodchat5$count, type="b", col="blue", pch=1, lty=2, lwd=lwd.tif)
legend("topleft", legend=c("Observed population counts", "Estimated population size"),
pch=c(1, 16), lwd=c(lwd.tif, lwd.tif), col=c("blue", "black"), lty=c(2, 1), bty="n")
par(op)
