for (i in 1:n) {
mean [ i ] <- a*day[ i ]/ (b + day[ i ])
rate [ i ] <- shape/mean[ i ]
titer [ i ] ~ dgamma (shape, rate[ i ])
}
##priors
a ~ dgamma (0.1, 0.1)
b ~ dgamma (0.1, 0.1)
shape ~ dgamma (0.01, 0.01)
}
")
sink()
datalist <- list(
titer=Myx$titer,
day=Myx$day,
n=nrow(Myx)
)
myxo2.bugs <- jags(data=datalist, inits=inits, parameters.to.save=c("a", "b", "shape"), model.file= "myxomodel2.txt", n.thin=5, n.chains=5, n.burnin=500, n.iter=5000)
library(emdbook)
MyxDat <- MyxoTiter_sum
Myx <- subset(MyxDat,grade==1)  #Data set from grade 1 of myxo data
head(Myx)
inits
inits <- list(list(a=8, b=0.5, shape=90), list(a=10, b=1, shape=100), list(a=7, b=1.2, shape=70))
#Make a model file:
sink("myxomodel2.txt")
cat("
model {
for (i in 1:n) {
mean [ i ] <- a*day[ i ]/ (b + day[ i ])
rate [ i ] <- shape/mean[ i ]
titer [ i ] ~ dgamma (shape, rate[ i ])
}
##priors
a ~ dgamma (0.1, 0.1)
b ~ dgamma (0.1, 0.1)
shape ~ dgamma (0.01, 0.01)
}
")
sink()
?jags
?split
init.vals.for.bugs <- function(){
init.list <- list(
shape=runif(1,20,100),
scale=runif(1,0.05,0.3)
)
return(init.list)
}
init.vals.for.bugs()
init.vals.for.bugs()
init.vals.for.bugs()
jags.fit <- jags(data=myx.data.for.bugs,inits=init.vals.for.bugs,parameters.to.save=params.to.store,n.iter=50000,model.file="BUGSmodel.txt",n.chains = 3, n.burnin=10000,n.thin = 20)
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
rbvn<-function (n, rho)   #function for drawing an arbitrary number of independent samples from the bivariate standard normal distribution.
{
x <- rnorm(n, 0, 1)
y <- rnorm(n, rho * x, sqrt(1 - rho^2))
cbind(x, y)
}
bvn<-rbvn(10000,0.98)
par(mfrow=c(3,2))
plot(bvn,col=1:10000)
plot(bvn,type="l")
plot(ts(bvn[,1]))
plot(ts(bvn[,2]))
hist(bvn[,1],40)
hist(bvn[,2],40)
par(mfrow=c(1,1))
library(mvtnorm)
metropolisHastings <- function (n, rho=0.98){    # a MCMC sampler implementation of a bivariate random number generator
mat <- matrix(ncol = 2, nrow = n)   # matrix for storing the random samples
x <- 0
y <- 0
prev <- dmvnorm(c(x,y),mean=c(0,0),sigma = matrix(c(1,rho,rho,1),ncol=2))
mat[1, ] <- c(x, y)        # initialize the markov chain
counter <- 1
while(counter<=n) {
newx <- rnorm(1,x,0.5)     # make a jump
newy <- rnorm(1,y,0.5)
newprob <- dmvnorm(c(newx,newy),sigma = matrix(c(1,rho,rho,1),ncol=2))    # assess whether the new jump is good!
ratio <- newprob/prev
prob.accept <- min(1,ratio)     # decide whether to accept the new jump!
rand <- runif(1)
if(rand<=prob.accept){
x=newx;y=newy
mat[counter,] <- c(x,y)
counter=counter+1
prev <- newprob
}
}
return(mat)
}
bvn<-metropolisHastings(10000,0.98)
par(mfrow=c(3,2))
plot(bvn,col=1:10000)
plot(bvn,type="l")
plot(ts(bvn[,1]))
plot(ts(bvn[,2]))
hist(bvn[,1],40)
hist(bvn[,2],40)
par(mfrow=c(1,1))
library(emdbook)
MyxDat <- MyxoTiter_sum
Myx <- subset(MyxDat,grade==1)
head(Myx)
hist(Myx$titer,freq=FALSE)
hist(Myx$titer,freq=FALSE)
curve(dgamma(x,shape=40,scale=0.15),add=T,col="red")
##############
# define 2-D parameter space!
##############
shapevec <- seq(3,100,by=0.1)
scalevec <- seq(0.01,0.5,by=0.001)
##############
# define the likelihood surface across this grid within parameter space
##############
GammaLogLikelihoodFunction <- function(params){
sum(dgamma(Myx$titer,shape=params['shape'],scale=params['scale'],log=T))
}
surface2D <- matrix(nrow=length(shapevec),ncol=length(scalevec))   # initialize storage variable
newparams <- c(shape=50,scale=0.2)
for(i in 1:length(shapevec)){
newparams['shape'] <- shapevec[i]
for(j in 1:length(scalevec)){
newparams['scale'] <- scalevec[j]
surface2D[i,j] <- GammaLogLikelihoodFunction(newparams)
}
}
############
# Visualize the likelihood surface
############
image(x=shapevec,y=scalevec,z=surface2D,zlim=c(-1000,-30),col=topo.colors(12))
contour(x=shapevec,y=scalevec,z=surface2D,levels=c(-30,-40,-80,-500),add=T)
GammaLikelihoodFunction <- function(params){
prod(dgamma(Myx$titer,shape=params['shape'],scale=params['scale'],log=F))
}
params <- c(shape=40,scale=0.15)
params
GammaLikelihoodFunction(params)
GammaPriorFunction <- function(params){
prior <- c(shape=NA,scale=NA)
prior['shape'] <- dgamma(params['shape'],shape=0.01,scale=100)
prior['scale'] <- dgamma(params['scale'],shape=0.001,scale=1000)
# prior['shape'] <- dunif(params['shape'],3,100)
# prior['scale'] <- dunif(params['scale'],0.01,0.5)
return(prod(prior))
}
curve(dgamma(x,shape=0.01,scale=1000),3,100)
params <- c(shape=40,scale=0.15)
params
GammaPriorFunction(params)
PosteriorRatio <- function(oldguess,newguess){
oldLik <- max(1e-90,GammaLikelihoodFunction(oldguess))
oldPrior <- max(1e-90,GammaPriorFunction(oldguess))
newLik <- GammaLikelihoodFunction(newguess)
newPrior <- GammaPriorFunction(newguess)
return((newLik*newPrior)/(oldLik*oldPrior))
}
oldguess <- params
newguess <- c(shape=39,scale=0.15)
PosteriorRatio(oldguess,newguess)
# function for making new guesses
newGuess <- function(oldguess){
sdshapejump <- 4
sdscalejump <- 0.07
jump <- c(shape=rnorm(1,mean=0,sd=sdshapejump),scale=rnorm(1,0,sdscalejump))
newguess <- abs(oldguess + jump)
return(newguess)
}
# set a new "guess" near to the original guess
newGuess(oldguess=params)     # each time is different- this is the first optimization procedure with randomness built in
newGuess(oldguess=params)
newGuess(oldguess=params)
startingvals <- c(shape=75,scale=0.28)    # starting point for the algorithm
newguess <- newGuess(startingvals)    # take a jump in parameter space
newguess
PosteriorRatio(startingvals,newguess)   # difference in posterior ratio
chain.length <- 10
oldguess <- startingvals
guesses <- matrix(0,nrow=chain.length,ncol=2)
colnames(guesses) <- names(startingvals)
counter <- 1
while(counter <= chain.length){
newguess <- newGuess(oldguess)
post.rat <- PosteriorRatio(oldguess,newguess)
prob.accept <- min(1,post.rat)
rand <- runif(1)
if(rand<=prob.accept){
oldguess <- newguess
guesses[counter,] <- newguess
counter=counter+1
}
}
# visualize!
image(x=shapevec,y=scalevec,z=surface2D,zlim=c(-1000,-30),col=topo.colors(12))
contour(x=shapevec,y=scalevec,z=surface2D,levels=c(-30,-40,-80,-500),add=T)
lines(guesses,col="red")
chain.length <- 100
oldguess <- startingvals
guesses <- matrix(0,nrow=chain.length,ncol=2)
colnames(guesses) <- names(startingvals)
counter <- 1
while(counter <= chain.length){
newguess <- newGuess(oldguess)
post.rat <- PosteriorRatio(oldguess,newguess)
prob.accept <- min(1,post.rat)
rand <- runif(1)
if(rand<=prob.accept){
oldguess <- newguess
guesses[counter,] <- newguess
counter=counter+1
}
}
# visualize!
image(x=shapevec,y=scalevec,z=surface2D,zlim=c(-1000,-30),col=topo.colors(12))
contour(x=shapevec,y=scalevec,z=surface2D,levels=c(-30,-40,-80,-500),add=T)
lines(guesses,col="red")
chain.length <- 1000
oldguess <- startingvals
guesses <- matrix(0,nrow=chain.length,ncol=2)
colnames(guesses) <- names(startingvals)
counter <- 1
while(counter <= chain.length){
newguess <- newGuess(oldguess)
post.rat <- PosteriorRatio(oldguess,newguess)
prob.accept <- min(1,post.rat)
rand <- runif(1)
if(rand<=prob.accept){
oldguess <- newguess
guesses[counter,] <- newguess
counter=counter+1
}
}
# visualize!
image(x=shapevec,y=scalevec,z=surface2D,zlim=c(-1000,-30),col=topo.colors(12))
contour(x=shapevec,y=scalevec,z=surface2D,levels=c(-30,-40,-80,-500),add=T)
lines(guesses,col="red")
plot(1:chain.length,guesses[,'shape'],type="l",main="shape parameter",xlab="iteration",ylab="shape")
plot(1:chain.length,guesses[,'scale'],type="l",main="scale parameter",xlab="iteration",ylab="scale")
burn.in <- 100
MCMCsamples <- guesses[-c(1:burn.in),]
chain.length=chain.length-burn.in
plot(1:chain.length,MCMCsamples[,'shape'],type="l",main="shape parameter",xlab="iteration",ylab="shape")
plot(1:chain.length,MCMCsamples[,'scale'],type="l",main="scale parameter",xlab="iteration",ylab="scale")
chain.length <- 20000
oldguess <- startingvals
guesses <- matrix(0,nrow=chain.length,ncol=2)
colnames(guesses) <- names(startingvals)
counter <- 1
while(counter <= chain.length){
newguess <- newGuess(oldguess)
post.rat <- PosteriorRatio(oldguess,newguess)
prob.accept <- min(1,post.rat)
rand <- runif(1)
if(rand<=prob.accept){
oldguess <- newguess
guesses[counter,] <- newguess
counter=counter+1
}
}
# visualize!
image(x=shapevec,y=scalevec,z=surface2D,zlim=c(-1000,-30),col=topo.colors(12))
contour(x=shapevec,y=scalevec,z=surface2D,levels=c(-30,-40,-80,-500),add=T)
lines(guesses,col="red")
burn.in <- 5000
MCMCsamples <- guesses[-c(1:burn.in),]
chain.length=chain.length-burn.in
plot(1:chain.length,MCMCsamples[,'shape'],type="l",main="shape parameter",xlab="iteration",ylab="shape")
plot(1:chain.length,MCMCsamples[,'scale'],type="l",main="scale parameter",xlab="iteration",ylab="scale")
thinnedMCMC <- MCMCsamples[seq(1,chain.length,by=10),]
plot(1:nrow(thinnedMCMC),thinnedMCMC[,'shape'],type="l",main="shape parameter",xlab="iteration",ylab="shape")
plot(1:nrow(thinnedMCMC),thinnedMCMC[,'scale'],type="l",main="scale parameter",xlab="iteration",ylab="scale")
plot(density(thinnedMCMC[,'scale']),main="scale parameter",xlab="scale")
plot(density(thinnedMCMC[,'shape']),main="shape parameter",xlab="shape")
par(mfrow=c(3,2))
plot(thinnedMCMC,col=1:10000)
plot(thinnedMCMC,type="l")
plot(ts(thinnedMCMC[,1]))
plot(ts(thinnedMCMC[,2]))
hist(thinnedMCMC[,1],40)
hist(thinnedMCMC[,2],40)
par(mfrow=c(1,1))
rbvn<-function (n, rho){  #function for drawing an arbitrary number of independent samples from the bivariate standard normal distribution.
x <- rnorm(n, 0, 1)
y <- rnorm(n, rho * x, sqrt(1 - rho^2))
cbind(x, y)
}
bvn<-rbvn(10000,0.98)
par(mfrow=c(3,2))
plot(bvn,col=1:10000)
plot(bvn,type="l")
plot(ts(bvn[,1]))
plot(ts(bvn[,2]))
hist(bvn[,1],40)
hist(bvn[,2],40)
par(mfrow=c(1,1))
gibbs<-function (n, rho){    # a gibbs sampler implementation of a bivariate random number generator
mat <- matrix(ncol = 2, nrow = n)   # matrix for storing the random samples
x <- 0
y <- 0
mat[1, ] <- c(x, y)        # initialize the markov chain
for (i in 2:n) {
x <- rnorm(1, rho * y, sqrt(1 - rho^2))        # sample from x conditional on y
y <- rnorm(1, rho * x, sqrt(1 - rho^2))        # sample from y conditional on x
mat[i, ] <- c(x, y)
}
mat
}
bvn<-gibbs(10000,0.98)
par(mfrow=c(3,2))
plot(bvn,col=1:10000)
plot(bvn,type="l")
plot(ts(bvn[,1]))
plot(ts(bvn[,2]))
hist(bvn[,1],40)
hist(bvn[,2],40)
par(mfrow=c(1,1))
sink("BUGSmodel.txt")
cat("
model {
#############
# LIKELIHOOD
############
for(obs in 1:n.observations){
titer[obs] ~ dgamma(shape,rate)
}
#############
# PRIORS
############
shape ~ dgamma(0.001,0.001)
scale ~ dgamma(0.01,0.01)
rate <- 1/scale
}
")
sink()
myx.data.for.bugs <- list(
titer = Myx$titer,
n.observations = length(Myx$titer)
)
myx.data.for.bugs
init.vals.for.bugs <- function(){
init.list <- list(
shape=runif(1,20,100),
scale=runif(1,0.05,0.3)
)
return(init.list)
}
init.vals.for.bugs()
init.vals.for.bugs()
init.vals.for.bugs()
library(R2jags)
library(coda)
params.to.store <- c("shape","scale")
jags.fit <- jags(data=myx.data.for.bugs,inits=init.vals.for.bugs,parameters.to.save=params.to.store,n.iter=5000,model.file="BUGSmodel.txt",n.chains = 3,n.burnin = 0 )
jagsfit.mcmc <- as.mcmc(jags.fit)   # convert to "MCMC" object (coda package)
summary(jagsfit.mcmc)
plot(jagsfit.mcmc)
jags.fit <- jags(data=myx.data.for.bugs,inits=init.vals.for.bugs,parameters.to.save=params.to.store,n.iter=50000,model.file="BUGSmodel.txt",n.chains = 3, n.burnin=10000,n.thin = 20)
jagsfit.mcmc <- as.mcmc(jags.fit)   # convert to "MCMC" object (coda package)
summary(jagsfit.mcmc)
plot(jagsfit.mcmc)
gelman.diag(jagsfit.mcmc)
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
head(Fir)
head(FirDBHFec)
?Fir
data(FirDBHFec)
head(FirDBHFec)
library(emdbook)
data(FirDBHFec)
fir <- FirDBHFec
head(fir)
plot(fir$TOTCONES ~ fir$DBH)
fir$WAVE_NON
ndx <- fir$WAVE_NON=="w"
ndx <- fir$WAVE_NON=="w"
plot(fir$TOTCONES[ndx] ~ fir$DBH[ndx],xlab="DBH",ylab="Tot Cones")
ndx <- fir$WAVE_NON=="w"
plot(fir$TOTCONES[ndx] ~ fir$DBH[ndx],xlab="DBH",ylab="Tot Cones")
points(fir$DBH[-ndx],fir$TOTCONES[-ndx],pch=3,col="red")
ndx
ndx <- fir$WAVE_NON=="w"
plot(fir$TOTCONES[ndx] ~ fir$DBH[ndx],xlab="DBH",ylab="Tot Cones")
points(fir$DBH[!ndx],fir$TOTCONES[!ndx],pch=4,col="red")
?legend
ndx <- fir$WAVE_NON=="w"
plot(fir$TOTCONES[ndx] ~ fir$DBH[ndx],xlab="DBH",ylab="Tot Cones")
points(fir$DBH[!ndx],fir$TOTCONES[!ndx],pch=4,col="red")
legend("topleft",pch=c(1,4),col=c("black","red"),legend=c("Wave","Non-wave"))
library(emdbook)
data(FirDBHFec)
fir <- na.omit(FirDBHFec[,c("TOTCONES","DBH","WAVE_NON")])
fir$TOTCONES <- round(fir$TOTCONES)
head(fir)
plot(fir$TOTCONES ~ fir$DBH)
ndx <- fir$WAVE_NON=="w"
plot(fir$TOTCONES[ndx] ~ fir$DBH[ndx],xlab="DBH",ylab="Tot Cones")
points(fir$DBH[!ndx],fir$TOTCONES[!ndx],pch=4,col="red")
legend("topleft",pch=c(1,4),col=c("black","red"),legend=c("Wave","Non-wave"))
NegBinomLik_full <- function(params){
wave.code <- as.numeric(fir$WAVE_NON)
a <- c(params[1],params[2])[wave.code]
b <- c(params[3],params[4])[wave.code]
k <- c(params[5],params[6])[wave.code]
expcones <- a*fir$DBH^b
-sum(dnbinom(df$TOTCONES,mu=expcones,size=k,log=TRUE))
}
as.numeric(fir$WAVE_NON)
as.numeric(fir$WAVE_NON)
fir$WAVE_NON
params <- c(a.n=1,a.w=1,b.n=1,b.w=1,k.n=1,k.w=1)
NegBinomLik_full(params)
NegBinomLik_full <- function(params){
wave.code <- as.numeric(fir$WAVE_NON)
a <- c(params[1],params[2])[wave.code]
b <- c(params[3],params[4])[wave.code]
k <- c(params[5],params[6])[wave.code]
expcones <- a*fir$DBH^b
-sum(dnbinom(df$TOTCONES,mu=expcones,size=k,log=TRUE))
}
params <- c(a.n=1,a.w=1,b.n=1,b.w=1,k.n=1,k.w=1)
NegBinomLik_full(params)
NegBinomLik_full <- function(params){
wave.code <- as.numeric(fir$WAVE_NON)
a <- c(params[1],params[2])[wave.code]
b <- c(params[3],params[4])[wave.code]
k <- c(params[5],params[6])[wave.code]
expcones <- a*fir$DBH^b
-sum(dnbinom(fir$TOTCONES,mu=expcones,size=k,log=TRUE))
}
params <- c(a.n=1,a.w=1,b.n=1,b.w=1,k.n=1,k.w=1)
NegBinomLik_full(params)
?optim
MLE <- optim(fn=NegBinomLik_full,par=c(1,1,1,1,1,1),method="Nelder-Mead")
MLE$par
MLE$value
MLE <- optim(fn=NegBinomLik_full,par=c(a.n=1,a.w=1,b.n=1,b.w=1,k.n=1,k.w=1),method="Nelder-Mead")
MLE$par
MLE$value
MLE_full <- optim(fn=NegBinomLik_full,par=c(a.n=1,a.w=1,b.n=1,b.w=1,k.n=1,k.w=1),method="Nelder-Mead")
MLE_full$par
MLE_full$value
NegBinomLik_consta <- function(params){
wave.code <- as.numeric(fir$WAVE_NON)
a <- params[1]
b <- c(params[2],params[3])[wave.code]
k <- c(params[4],params[5])[wave.code]
expcones <- a*fir$DBH^b
-sum(dnbinom(fir$TOTCONES,mu=expcones,size=k,log=TRUE))
}
params <- c(a=1,b.n=1,b.w=1,k.n=1,k.w=1)
NegBinomLik_consta(params)
MLE_consta <- optim(fn=NegBinomLik_consta,par=c(a=1,b.n=1,b.w=1,k.n=1,k.w=1),method="Nelder-Mead")
MLE_consta$par
MLE_consta$value
NegBinomLik_consta <- function(params){
wave.code <- as.numeric(fir$WAVE_NON)
a <- params[1]
b <- c(params[2],params[3])[wave.code]
k <- c(params[4],params[5])[wave.code]
expcones <- a*fir$DBH^b
-sum(dnbinom(fir$TOTCONES,mu=expcones,size=k,log=TRUE))
}
params <- c(a=1,b.n=1,b.w=1,k.n=1,k.w=1)
NegBinomLik_consta(params)
MLE_consta <- optim(fn=NegBinomLik_consta,par=c(a=1,b.n=1,b.w=1,k.n=1,k.w=1),method="Nelder-Mead")
MLE_consta$par
MLE_consta$value
MLE_consta$par
MLE_consta <- optim(fn=NegBinomLik_consta,par=c(a=.6,b.n=1,b.w=1,k.n=1,k.w=1),method="Nelder-Mead")
MLE_consta$par
MLE_consta$value
MLE_consta <- optim(fn=NegBinomLik_consta,par=c(a=.6,b.n=1,b.w=1,k.n=1,k.w=1),method="Nelder-Mead")
MLE_consta$par
MLE_consta$value
NegBinomLik_constb <- function(params){
wave.code <- as.numeric(fir$WAVE_NON)
a <- c(params[1],params[2])[wave.code]
b <- params[3]
k <- c(params[4],params[5])[wave.code]
expcones <- a*fir$DBH^b
-sum(dnbinom(fir$TOTCONES,mu=expcones,size=k,log=TRUE))
}
params <- c(a.n=1,a.w=1,b=1,k.n=1,k.w=1)
NegBinomLik_constb(params)
MLE_constb <- optim(fn=NegBinomLik_constb,par=c(a.n=1,a.w=1,b=1,k.n=1,k.w=1),method="Nelder-Mead")
MLE_constb$par
MLE_constb$value
MLE_constb
MLE_full <- optim(fn=NegBinomLik_full,par=c(a.n=1,a.w=1,b.n=1,b.w=1,k.n=1,k.w=1),method="Nelder-Mead")
MLE_full$par
MLE_full$value
MLE_full
MLE_full <- optim(fn=NegBinomLik_full,par=c(a.n=1,a.w=1,b.n=1,b.w=1,k.n=1,k.w=1),method="L-BFGS-B")
MLE_full$par
MLE_full$value
MLE_full
MLE_constb <- optim(fn=NegBinomLik_constb,par=c(a.n=1,a.w=1,b=1,k.n=1,k.w=1),method="L-BFGS-B")
MLE_constb$par
MLE_constb$value
MLE_constb
deviance_full <- 2*MLE_full$value
deviance_constb <- 2*MLE_constb$value
deviance_full
deviance_constb
Likelihood.ratio <- deviance_constb - deviance_full
Likelihood.ratio
Chisq.crit <- qchisq(0.95,1)
Chisq.crit
Deviance.dif <- deviance_constb - deviance_full
Deviance.dif>=Chisq.crit
