contour(x=shapevec,y=scalevec,z=surface2D,levels=c(-30,-40,-80,-500),add=T)
lines(guesses,col="red")
# Get more MCMC samples --------------
chain.length <- 100
oldguess <- startingvals
guesses <- matrix(0,nrow=chain.length,ncol=2)
colnames(guesses) <- names(startingvals)
guesses[1,] <- startingvals
counter <- 2
while(counter <= chain.length){
newguess <- newGuess(oldguess)
post.rat <- PosteriorRatio2(oldguess,newguess)
prob.accept <- min(1,post.rat)
rand <- runif(1)
if(rand<=prob.accept){
oldguess <- newguess
guesses[counter,] <- newguess
}else{
guesses[counter,] <- oldguess
}
counter=counter+1
}
# visualize!
image(x=shapevec,y=scalevec,z=surface2D,zlim=c(-1000,-30),col=topo.colors(12))
contour(x=shapevec,y=scalevec,z=surface2D,levels=c(-30,-40,-80,-500),add=T)
lines(guesses,col="red")
# And more... -------------------
chain.length <- 1000
oldguess <- startingvals
guesses <- matrix(0,nrow=chain.length,ncol=2)
colnames(guesses) <- names(startingvals)
guesses[1,] <- startingvals
counter <- 2
while(counter <= chain.length){
newguess <- newGuess(oldguess)
post.rat <- PosteriorRatio2(oldguess,newguess)
prob.accept <- min(1,post.rat)
rand <- runif(1)
if(rand<=prob.accept){
oldguess <- newguess
guesses[counter,] <- newguess
}else{
guesses[counter,] <- oldguess
}
counter=counter+1
}
# visualize!
image(x=shapevec,y=scalevec,z=surface2D,zlim=c(-1000,-30),col=topo.colors(12))
contour(x=shapevec,y=scalevec,z=surface2D,levels=c(-30,-40,-80,-500),add=T)
lines(guesses,col="red")
# And more... -------------------
chain.length <- 10000
oldguess <- startingvals
guesses <- matrix(0,nrow=chain.length,ncol=2)
colnames(guesses) <- names(startingvals)
guesses[1,] <- startingvals
counter <- 2
while(counter <= chain.length){
newguess <- newGuess(oldguess)
post.rat <- PosteriorRatio2(oldguess,newguess)
prob.accept <- min(1,post.rat)
rand <- runif(1)
if(rand<=prob.accept){
oldguess <- newguess
guesses[counter,] <- newguess
}else{
guesses[counter,] <- oldguess
}
counter=counter+1
}
# visualize!
image(x=shapevec,y=scalevec,z=surface2D,zlim=c(-1000,-30),col=topo.colors(12))
contour(x=shapevec,y=scalevec,z=surface2D,levels=c(-30,-40,-80,-500),add=T)
lines(guesses,col="red")
# Evaluate "traceplot" for the MCMC samples... ---------------------
## Shape parameter
plot(1:chain.length,guesses[,'shape'],type="l",main="shape parameter",xlab="iteration",ylab="shape")
guesses
oldguess
install.packages("titanic")
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
library(titanic)
data(titanic::titanic_train)
titanic::titanic_train
titanic <- titanic_train
View(titanic)
?titanic
?titanic_train
library(titanic)
titanic <- titanic::titanic_train
## write jags code
fn <- "titanic_jags.txt"
library(titanic)
titanic <- titanic::titanic_train
## write jags code
fn <- "titanic_jags.txt"
cat("
model{
# likelihood
for(p in 1:npassengers){
logit(psurv[p]) <- psurv0.l[class[p]] + b.fare * fare[p]  + b.age * age[p] + b.female * is.fem[p]
survived[p] ~ dbern(psurv[p])
}
# priors
b.fare ~ dnorm(0,0.1)  # slightly regularized prior
b.age ~ dnorm(0,0.1)
b.female ~ dnorm(0,0.1)
psurv0[1] ~ dunif(0,1)  # flat prior from 0 to 1 on p scale
psurv0[2] ~ dunif(0,1)
psurv0[3] ~ dunif(0,1)
for(i in 1:3){    # convert to logit scale
psurv0.l[i] <- log(psurv[i]/(1-psurv[i]))
}
## interpolate missing data
meanage ~ dnorm(0,.1)
sdage ~ dunif(0,5)
precage <- pow(sdage,-2)
for(p in 1:npassengers){
age[p] ~ dnorm(meanage,precage)   # DATA NODE
}
} ",file=fn)
dat <- list(
npassengers = nrow(titanic),
class = titanic$Pclass,
fare = (titanic$Fare-mean(titanic$Fare))/sd(titanic$Fare),
age = (titanic$Age-mean(titanic$Age,na.rm = T))/sd(titanic$Age,na.rm=T),
is.fem = ifelse(titanic$Sex=="female",1,0),
survived = titanic$Survived
)
dat
params <- c("psurv0","b.fare","b.age","b.female","sdage","meanage")
library(jagsUI)
jags(dat, parameters.to.save=params, model.file=fn,
n.chains=3, n.adapt=1000, n.iter=10000, n.burnin=5000, n.thin=2,
parallel=FALSE)
## write jags code
fn <- "titanic_jags.txt"
cat("
model{
# likelihood
for(p in 1:npassengers){
logit(psurv[p]) <- psurv0.l[class[p]] + b.fare * fare[p]  + b.age * age[p] + b.female * is.fem[p]
survived[p] ~ dbern(psurv[p])
}
# priors
b.fare ~ dnorm(0,0.1)  # slightly regularized prior
b.age ~ dnorm(0,0.1)
b.female ~ dnorm(0,0.1)
psurv0[1] ~ dunif(0,1)  # flat prior from 0 to 1 on p scale
psurv0[2] ~ dunif(0,1)
psurv0[3] ~ dunif(0,1)
for(i in 1:3){    # convert to logit scale
psurv0.l[i] <- log(psurv0[i]/(1-psurv0[i]))
}
## interpolate missing data
meanage ~ dnorm(0,.1)
sdage ~ dunif(0,5)
precage <- pow(sdage,-2)
for(p in 1:npassengers){
age[p] ~ dnorm(meanage,precage)   # DATA NODE
}
} ",file=fn)
dat <- list(
npassengers = nrow(titanic),
class = titanic$Pclass,
fare = (titanic$Fare-mean(titanic$Fare))/sd(titanic$Fare),
age = (titanic$Age-mean(titanic$Age,na.rm = T))/sd(titanic$Age,na.rm=T),
is.fem = ifelse(titanic$Sex=="female",1,0),
survived = titanic$Survived
)
dat
params <- c("psurv0","b.fare","b.age","b.female","sdage","meanage")
library(jagsUI)
jags(dat, parameters.to.save=params, model.file=fn,
n.chains=3, n.adapt=1000, n.iter=10000, n.burnin=5000, n.thin=2,
parallel=FALSE)
mod1 <- lm(Volume~Girth,trees)
aov(mod1)
mod1 <- lm(Volume~Girth+Height,trees)
aov(mod1)
anova(mod1)
##download data to follow along:
rikz_data <- "https://uoftcoders.github.io/rcourse/data/rikz_data.txt"
download.file(rikz_data, "rikz_data.txt")
rikz_data <- read.table("rikz_data.txt", header = TRUE, sep="\t")
str(rikz_data)
rikz_data$Beach <- as.factor(rikz_data$Beach)
str(rikz_data)
head(rikz_data)
basic.lm <- lm(Richness~ NAP, data = rikz_data)
summary(basic.lm)
library(ggplot2)
# Plot relationship from above model
ggplot(rikz_data, aes(x = NAP, y = Richness)) +
geom_point() +
geom_smooth(method = "lm") +
theme_classic()
# Check assumptions.
par(mfrow=c(2,2))
plot(basic.lm)
# Function to find polygons
find_hull <- function(df) df[chull(df$Richness, df$NAP), ]
# Identify polygons in data
library(plyr)
hulls <- ddply(rikz_data, "Beach", find_hull)
# Plot
ggplot(rikz_data, aes(x = NAP, y = Richness, colour = Beach)) +
geom_point(size = 3) +
theme_classic() +
theme(legend.position = "none") +
scale_colour_brewer(palette="Set1") +
scale_fill_brewer(palette="Set1") +
geom_polygon(data=hulls, aes(fill = Beach), alpha = 0.2)
basic.lm <- lm(Richness ~ NAP + Beach, data = rikz_data)
summary(basic.lm)
# Random intercept model with NAP as fixed effect and Beach as random effect
library(lme4)
mixed_model_IntOnly <- lmer(Richness ~ NAP + (1|Beach),
data = rikz_data, REML = FALSE)
summary(mixed_model_IntOnly)
# Let's predict values based on our model and add these to our dataframe
# These are the fitted values for each beach, which are modelled separately.
rikz_data$fit_InterceptOnly <- predict(mixed_model_IntOnly)
# Let's plot
ggplot(rikz_data, aes(x = NAP, y = Richness, colour = Beach)) +
# Add fixed effect regression line (i.e. NAP)
geom_abline(aes(intercept = `(Intercept)`, slope = NAP),
linewidth = 2,
as.data.frame(t(fixef(mixed_model_IntOnly)))) +
# Add fitted values (i.e. regression) for each beach
geom_line(aes(y = fit_InterceptOnly), size = 1) +
geom_point(size = 3) +
theme_classic() +
theme(legend.position = "none") +
scale_colour_brewer(palette="Set1")
# Random intercept and slope model
mixed_model_IntSlope <- lmer(Richness ~ NAP + (1 + NAP|Beach),
data = rikz_data, REML = FALSE)
summary(mixed_model_IntSlope)
rikz_data$fit_IntSlope <- predict(mixed_model_IntSlope)
ggplot(rikz_data, aes(x = NAP, y = Richness, colour = Beach)) +
geom_abline(aes(intercept = `(Intercept)`, slope = NAP),
size = 2,
as.data.frame(t(fixef(mixed_model_IntSlope)))) +
geom_line(aes(y = fit_IntSlope), size = 1) +
geom_point(size = 3) +
theme_classic() +
theme(legend.position = "none") +
scale_colour_brewer(palette="Set1")
mixed_model_NoFix <- lmer(Richness ~ 1 + (1|Beach),
data = rikz_data, REML = TRUE)
summary(mixed_model_NoFix)
mixed_model_IntOnly <- lmer(Richness ~ NAP*Exposure + (1|Beach), REML = TRUE,
data = rikz_data)
mixed_model_IntSlope <- lmer(Richness ~ NAP*Exposure + (1 + NAP|Beach), REML = TRUE,
data = rikz_data)
library(MuMIn)
AICc(mixed_model_IntOnly, mixed_model_IntSlope)
# Full model with both fixed effects and their interaction
mixed_model_IntOnly_Full <- lmer(Richness ~ NAP*Exposure + (1|Beach), REML = FALSE,
data = rikz_data)
# No interaction
mixed_model_IntOnly_NoInter <- lmer(Richness ~ NAP + Exposure + (1|Beach),
REML = FALSE,
data = rikz_data)
# No interaction or main effect of exposure
mixed_model_IntOnly_NAP <- lmer(Richness ~ NAP + (1|Beach),
REML = FALSE,
data = rikz_data)
# No interaction or main effect of NAP
mixed_model_IntOnly_Exp <- lmer(Richness ~ Exposure + (1|Beach),
REML = FALSE,
data = rikz_data)
# No fixed effects
mixed_model_IntOnly_NoFix <- lmer(Richness ~ 1 + (1|Beach),
REML = FALSE,
data = rikz_data)
AICc(mixed_model_IntOnly_Full, mixed_model_IntOnly_NoInter,
mixed_model_IntOnly_NAP, mixed_model_IntOnly_Exp,
mixed_model_IntOnly_NoFix)
summary(update(mixed_model_IntOnly_Full, REML = TRUE))
library(dharm)
library(DHARMa)
res <- DHARMa::simulateResiduals(mixed_model_IntOnly_Full)
plot(res)
set.seed(123)
# Define parameters
samplesize <- 200         # Number of observations
nsites <- 10              # Number of sites
b_length <- sort(rnorm(samplesize))  # Explanatory variable (body length)
# Generate a random grouping variable 'sites' with replacement
sites <- sample(1:10, samplesize, replace = TRUE)
# Display the count of observations per site
table(sites)
df <- read.csv("Exercise_1.csv")
View(df)
df <- read.csv("Exercise_1.csv")
View(df)
df$id <- as.numeric(as.factor(df$Individual_ID))
df$id
table(df$id)
table(df$Individual_ID)
df$id <- as.factor(as.numeric(as.factor(df$Individual_ID)))
plot(df$Hemoglobin~df$Season)
df$Season
df$Season <- as.factor(df$Season)
plot(df$Hemoglobin~df$Season)
df
df <- df[,-1]
df
hist(df$Hemoglobin)
mod1 <- (Hemoglobin~Season,df)
mod1 <- lm(Hemoglobin~Season,df)
summary(mod1)
hist(mod1$residuals)
library(glmmTMB)
mod2 <- glmmTMB(Hemoglobin~Season+(1|id),family=gaussian())
mod2 <- glmmTMB(Hemoglobin~Season+(1|id),family=gaussian(),data=df)
AIC(mod1,mod2)
library(DHARMa)
res <- simulateResiduals(mod1)
plot(res)
res <- simulateResiduals(mod2)
plot(res)
df <- read.csv("beesurv.csv")
View(df)
table(df$site)
hist(df$visits)
names(df)
plot(visits~temp)
plot(visits~temp,df)
plot(visits~wind,df)
df$site
df$site <- as.factor(df$site)
df$site
mod1 <- glmmTMB(visits~temp+wind+((temp+wind)|site),
family = gamma(link="log"),data=df)
mod1 <- glmmTMB(visits~temp+wind+((temp+wind)|site),
family = Gamma(link="log"),data=df)
mod2 <- glmmTMB(visits~temp+wind+(1|site) + ((0+temp)|site) + ((0+wind)|site),
family = Gamma(link="log"),data=df)
summary(mod2)
ranef(mod2)
res <- simulateResiduals(mod2)
plot(res)
df$visits
mod3 <- glmmTMB(visits~temp+wind+(1|site) + ((0+temp)|site) + ((0+wind)|site),
family = Gamma,data=df)
mod3 <- glmmTMB(visits~temp+wind+(1|site) + ((0+temp)|site) + ((0+wind)|site),
family = nbinom2(link="log"),data=df)
summary(mod3)
summary(mod2)
hist(df$visits)   # definitely non-normal!
df$visits
res <- simulateResiduals(mod3)
plot(res)   # some issues, but not terrible
mod4 <- glmmTMB(log(visits)~temp+wind+(1|site) + ((0+temp)|site) + ((0+wind)|site),
family = gaussian(link="identity"),data=df)
summary(mod4)  # not converged
res <- simulateResiduals(mod4)
plot(res)   # some issues, but not terrible
mod5 <- glmmTMB(visits~temp*wind+(1|site) + ((0+temp)|site) + ((0+wind)|site),
family = Gamma(link="log"),data=df)
summary(mod5)
ranef(mod5)
res <- simulateResiduals(mod5)
plot(res)   # some issues, but not terrible
AIC(mod1,mod2,mod3,mod4,mod5)
AIC(mod1,mod2,mod3,mod5) # AIC says mod3 is best
summary(mod3)  # not converged
mod3 <- glmmTMB(visits~temp+wind+(1|site) + ((0+temp)|site) + ((0+wind)|site),
family = nbinom1(link="log"),data=df)
summary(mod3)  # not converged
res <- simulateResiduals(mod3)
plot(res)   # some issues, but not terrible
AIC(mod1,mod2,mod3,mod5) # AIC says mod3 is best
mod5 <- glmmTMB(visits~temp+wind+(1|site) + ((0+temp)|site) + ((0+wind)|site),
family = genpois(link="log"),data=df)
summary(mod5)
mod6 <- glmmTMB(visits~temp+wind+(1|site) + ((0+temp)|site) + ((0+wind)|site),
family = genpois(link="log"),data=df)
summary(mod6)
res <- simulateResiduals(mod6)
plot(res)   # some issues, but not terrible
AIC(mod2,mod3,mod6)
set.seed(123)
# Define parameters
samplesize <- 200         # Number of observations
nsites <- 10              # Number of sites
b_length <- sort(rnorm(samplesize))  # Explanatory variable (body length)
# Generate a random grouping variable 'sites' with replacement
sites <- sample(1:10, samplesize, replace = TRUE)
# Display the count of observations per site
table(sites)
# True intercept parameters
int_true_mean <- 45       # True mean intercept
int_true_sigma <- 10      # True standard deviation of intercepts
int_true_sites <- rnorm(n = nsites, mean = int_true_mean, sd = int_true_sigma)  # True intercept of each site
# Create a matrix to represent the intercept of each snake individual based on its site
sitemat <- matrix(0, nrow = samplesize, ncol = nsites)
for (i in 1:nrow(sitemat)) sitemat[i, sites[i]] <- 1
int_true <- sitemat %*% int_true_sites
# True slope parameter
slope_true <- 10
# Calculate true means and standard deviation
mu <- int_true + slope_true * b_length
sigma <- 5
# Generate response variable 'b_mass' based on normal distributions
b_mass <- rnorm(samplesize, mean = mu, sd = sigma)
# Create a data frame 'snakes3' with explanatory and response variables
snakes3 <- data.frame(b_length = b_length, b_mass = b_mass, site = sites)
# Display the first few rows of the data frame
head(snakes3)
plot(b_mass ~ b_length, col = site, data = snakes3)
# True intercept parameters
int_true_mean <- 45       # True mean intercept
int_true_sigma <- 10      # True standard deviation of intercepts
int_true_sites <- rnorm(n = nsites, mean = int_true_mean, sd = int_true_sigma)  # True intercept of each site
# Create a matrix to represent the intercept of each snake individual based on its site
sitemat <- matrix(0, nrow = samplesize, ncol = nsites)
for (i in 1:nrow(sitemat)) sitemat[i, sites[i]] <- 1
int_true <- sitemat %*% int_true_sites
# True slope parameter
slope_true <- 10
# Calculate true means and standard deviation
mu <- int_true + slope_true * b_length
sigma <- 5
# Generate response variable 'b_mass' based on normal distributions
b_mass <- rnorm(samplesize, mean = mu, sd = sigma)
# Create a data frame 'snakes3' with explanatory and response variables
snakes3 <- data.frame(b_length = b_length, b_mass = b_mass, site = sites)
# Display the first few rows of the data frame
head(snakes3)
# Prepare data for analysis with JAGS, including the number of sites
Nsites <- length(levels(as.factor(snakes3$site)))
jagsdata_s3 <- with(snakes3, list(b_mass = b_mass, b_length = b_length, site = site,
N = length(b_mass), Nsites = Nsites))
filename = "JAGS.txt"
cat("
model{
# Likelihood:
for (i in 1:N){
b_mass[i] ~ dnorm(mu[i], tau)  # Likelihood of the response variable
mu[i] <- alpha + a[site[i]] + beta * b_length[i]  # Model for the mean
}
# Priors:
alpha ~ dnorm(0, 0.01)      # Prior for the overall intercept
sigma_a ~ dunif(0, 100)      # Prior for the standard deviation of random effect
tau_a <- 1 / (sigma_a * sigma_a)  # Convert standard deviation to precision
for (j in 1:Nsites){
a[j] ~ dnorm(0, tau_a)    # Prior for random intercept for each site
}
beta ~ dnorm(0, 0.01)        # Prior for the slope
sigma ~ dunif(0, 100)        # Prior for the standard deviation of fixed effect
tau <- 1 / (sigma * sigma)   # Convert standard deviation to precision
}
",file=filename)
# Initial values function for JAGS
init_values <- function(){
list(alpha = rnorm(1), sigma_a = runif(1), beta = rnorm(1), sigma = runif(1))
}
# Parameters to be saved from the JAGS model
params <- c("alpha", "beta", "sigma", "sigma_a")
# Fit the JAGS model to the data
fit_lm3 <- jags(data = jagsdata_s3, inits = init_values, parameters.to.save = params, model.file = filename,
n.chains = 3, n.iter = 20000, n.burnin = 5000, n.thin = 10, DIC = FALSE)
library(jagsUI)
# Fit the JAGS model to the data
fit_lm3 <- jags(data = jagsdata_s3, inits = init_values, parameters.to.save = params, model.file = filename,
n.chains = 3, n.iter = 20000, n.burnin = 5000, n.thin = 10, DIC = FALSE)
fit_lm3
plot(fit_lm3)
plot(fit_lm3)
coda::autocorr(fit_lm3$samples)
traceplot(fit_lm3,"beta")
?autocorr
plot(fit_lm3)
?autocorr
df <- read.csv("beesurv.csv")
table(df$site)  # 10 sites, 10 observations
hist(df$visits)   # definitely non-normal! no zeroes...
names(df)
plot(visits~temp,df)
plot(visits~wind,df)
df$site <- as.factor(df$site)
mod1 <- glmmTMB(visits~temp+wind+((temp+wind)|site),
family = Gamma(link="log"),data=df)
mod2 <- glmmTMB(visits~temp+wind+(1|site) + ((0+temp)|site) + ((0+wind)|site),
family = Gamma(link="log"),data=df)
summary(mod2)
ranef(mod2)
res <- simulateResiduals(mod2)
plot(res)   # some issues, but not terrible
df$visits
mod3 <- glmmTMB(visits~temp+wind+(1|site) + ((0+temp)|site) + ((0+wind)|site),
family = nbinom1(link="log"),data=df)
summary(mod3)  # not converged
res <- simulateResiduals(mod3)
plot(res)   # some issues, but not terrible
mod4 <- glmmTMB(log(visits)~temp+wind+(1|site) + ((0+temp)|site) + ((0+wind)|site),
family = gaussian(link="identity"),data=df)
summary(mod4)  # not converged
mod7 <- glmmTMB(visits~temp*wind+(1|site) + ((0+temp)|site) + ((0+wind)|site),
family = poisson(link="log"),data=df)
summary(mod6)
summary(mod7)
res <- simulateResiduals(mod7)
plot(res)   # some issues, but not terrible
AIC(mod2,mod3,mod6,mod7)   # mod 3 and 6 are identical...
plot(visits~temp,df)
plot(visits~wind,df)
ranef(mod2)
