---
title: "Bayesian_Networks"
author: "Laura Cirillo"
date: "11/18/2018"
output: 
  html_document: 
    theme: cerulean
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

```{r echo=FALSE}

############################################################
####                                                    ####  
####  NRES 746, Student-led topic #4                    ####
####                                                    ####
############################################################


############################################################
####  Bayesian networks                                 ####
############################################################


```


For those wishing to follow along with the R-based demo in class, [click here](SpatialAutocorrelation.R) for the companion R script for this lecture.

```{r}

#install.packages("bnlearn")
library(bnlearn)

```

## R packages 

### bnlearn    
- A variety of classical approaches (HC and MMHC)

###pcalg   
- Causal interpretation (PC and FCI)

###deal
- Mixed data

###gRain      
- Exact and approximate computations

###lavaan      
- Structural equation models

###sparsebn   
- High dimensional data, mixed observational and experimental data
- Computational biology and genomics    

## bnlearn
This package contains a number of algorithms for Bayesian Network (BN) structure learning, parameter learning and inference. it also contains existing datasets that we can use to build and train a BN and ultimately make an inference

```{r} 

data(coronary)
head(coronary)

```

within the bnlearn package we can use one of the algorithms, "max-min hill climbing", to create a dependency between all of the variables in our dataframe, and use the plot function to create a simple visualization of the relationships.    

```{r}

bn_df <- data.frame(coronary)
res <- hc(bn_df)
plot(res)

```

The causality may not be correct based on the algorithm alone, so in this example we will edit some of the structure manually. Family is not a condition of stenuous mental work so we remove that link

```{r}

res$arcs <- res$arcs[-which((res$arcs[,'from'] == "M..Work" & res$arcs[,'to'] == "Family")),]

```

now that we have established the structure we can move to training. The bn.fit function runs the expectation maximization algorithm on our data to find out the contitional probalility at each node.

```{r}

fittedbn <- bn.fit(res, data = bn_df)
print(fittedbn$Proteins)

```

Now we can move to the inference from our trained BN. Each query of any event based on selected evidence provides a probability.

```{r}

cpquery(fittedbn, event = (Proteins=="<3"), evidence = ( Smoking=="no") )

```

```{r}
cpquery(fittedbn, event = (Proteins=="<3"), evidence = ( Smoking=="no" & Pressure==">140" ) )
```

```{r}

cpquery(fittedbn, event = (Pressure==">140"), evidence = ( Proteins=="<3" ) )

```

More advanced visualizations can also be done in bnlearn but we are going to follow a couple of examples of some more complex data in the sparsebn package to keep it interesting

```{r}

#install.packages("sparsebn")
library(sparsebn)

```

```{r}

# source("http://bioconductor.org/biocLite.R")
# biocLite("Rgraphviz")   
library("Rgraphviz")

```

The Rgraphviz package is a more flexible visualitaion tool that the simple versions like graphviz.plot()


```{r}

setPlotPackage("graph")   
plot(cytometryContinuous$dag)

```

You have complete control over your visualization in the igraph package. Here we plot a cleaner version of the same data as the previous visual of the continuous data.   


```{r}

setPlotPackage("igraph")
plot(cytometryContinuous$dag,
layout = igraph::layout_(to_igraph(cytometryContinuous$dag),
                         igraph::in_circle()),
vertex.label = names(cytometryContinuous$dag),
vertex.size = 30,
vertex.label.color = gray(0),
vertex.color = colors(),
edge.color = "red",
edge.arrow.size = 0.3)

```

##outside of R

### BEANdisco (Bayesian Exact and Approximate Network Discovery)    
- Multiple scoring options (i.e. parameter priors): BDeu, K2, LL, MDL, AIC
- Sampling methods: MCMC, MC3, AIS

### AMIDST     
- “A Java Toolbox for Analytics of Massive Data Streams using Probabilistic Graphical Models”

### GOBNILP (Globally Optimal Bayesian Network learning using Integer Linear Programming)     
- C program using SCIP framework for Constant Integer Programming

##references
Scutari, Marco. 2013. "Learning Bayesian Networks in R:an Example in Systems Biology".      

Tsamardinos, Ioannis, Laura E. Brown, and Constantin F. Aliferis. "The max-min hill-climbing Bayesian network structure learning algorithm." Machine learning 65.1 (2006): 31-78.      

Aragam, Bryon, Jiaying Gu, and Qing Zhou. 2018. "Learning Large-Scale Bayesian Networks with the sparsebn Package".     




