<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="NRES 746" />


<title>The Virtual Ecologist</title>

<script src="site_libs/header-attrs-2.24/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cerulean.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">NRES 746</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Schedule
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="schedule.html">Course Schedule</a>
    </li>
    <li>
      <a href="Syllabus.pdf">Syllabus</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Lectures
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="INTRO.html">Introduction to NRES 746</a>
    </li>
    <li>
      <a href="LECTURE1.html">Why focus on algorithms?</a>
    </li>
    <li>
      <a href="LECTURE2.html">Working with probabilities</a>
    </li>
    <li>
      <a href="LECTURE3.html">The Virtual Ecologist</a>
    </li>
    <li>
      <a href="LECTURE4.html">Likelihood</a>
    </li>
    <li>
      <a href="LECTURE5.html">Optimization</a>
    </li>
    <li>
      <a href="LECTURE6.html">Bayesian #1: concepts</a>
    </li>
    <li>
      <a href="LECTURE7.html">Bayesian #2: mcmc</a>
    </li>
    <li>
      <a href="LECTURE8.html">Model Selection</a>
    </li>
    <li>
      <a href="LECTURE9.html">Performance Evaluation</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Lab exercises
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="LAB_Instructions.html">Instructions for Labs</a>
    </li>
    <li>
      <a href="LAB3demo.html">Lab 3: Likelihood (intro)</a>
    </li>
    <li>
      <a href="LAB5.html">Lab 5: Model selection (optional)</a>
    </li>
    <li>
      <a href="FigureDemo.html">Demo: Figures in R</a>
    </li>
    <li>
      <a href="GIT-tutorial.html">Demo: version control in Git</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Data sets
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="TreeData.csv">Tree Data</a>
    </li>
    <li>
      <a href="ReedfrogPred.csv">Reed Frog Predation Data</a>
    </li>
    <li>
      <a href="ReedfrogFuncresp.csv">Reed Frog Func Resp</a>
    </li>
  </ul>
</li>
<li>
  <a href="Links.html">Links</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">The Virtual Ecologist</h1>
<h4 class="author">NRES 746</h4>
<h4 class="date">Fall 2023</h4>

</div>


<p>For those wishing to follow along with the R-based demo in class, <a
href="LECTURE3.R">click here</a> for the companion R-script for this
lecture.</p>
<p>NOTE: some of this demo borrows from Hadley Wickham’s presentation:
<a
href="http://had.co.nz/stat480/lectures/15-simulation.pdf">Simulation</a></p>
<div id="why-simulate-fake-data" class="section level2">
<h2>Why simulate ‘fake data’?</h2>
<ul>
<li>Formalize your understanding of the data generating process (make
your assumptions <em>explicit</em>)
<ul>
<li>if you can tell a computer how to do it, you REALLY understand
it!</li>
<li>it forces you to confront any underlying assumptions head-on</li>
<li>it allows you to better understand the implications of your
hypotheses (every model you build is essentially a hypothesis)</li>
</ul></li>
<li>Assess how sampling methods potentially affect information recovery
<ul>
<li>Power Analysis! (how likely am I to pick up important signals from
this sampling design?)<br />
</li>
<li>Sampling design! (what sampling design(s) will most effectively
allow me to address my research question?)<br />
</li>
<li>Generate sampling distributions (e.g., CLT exercise, brute force
z-test)</li>
</ul></li>
<li>Assess goodness-of-fit (could your data have been produced by this
model?)<br />
</li>
<li>Test whether model-fitting algorithms and statistical tests do what
you think they should (e.g., estimate parameters correctly)! (test for
bias, precision, etc.)</li>
<li>Build intuition and proficiency for developing likelihood
functions!</li>
</ul>
<p>We have simulated data already (e.g., CLT, brute-force z-test)! Even
bootstrapping is a form of data simulation…</p>
</div>
<div id="random-number-generators-sample-data-from-known-distributions"
class="section level2">
<h2>Random number generators (sample “data” from known
distributions)</h2>
<pre class="r"><code># Random number generators  -------------------------------
#   (a key component of data simulation models- but usually not the whole story)

runif(1,0,25)   # draw random numbers from various probability distributions
rpois(1,3.4)
rnorm(1,22,5.4)</code></pre>
<p>First argument: <em>n</em>, number of random draws you want</p>
<p>Subsequent arguments: <strong>parameters</strong> of the
distribution</p>
<ul>
<li>Always check that the distribution is parameterized the way you
expect (e.g., that the normal distribution is parameterized with a mean
and standard deviation) – especially if you leave out the argument name
in the random-number-generation functions!)</li>
</ul>
<div id="short-exercise-1" class="section level3">
<h3>Short exercise #1:</h3>
<ul>
<li>Generate 50 samples from <span
class="math inline">\(N(10,5)\)</span><br />
</li>
<li>Generate 1000 numbers from <span
class="math inline">\(Poisson(50)\)</span><br />
</li>
<li>Generate 10 numbers from <span
class="math inline">\(Beta(0.1,0.1)\)</span></li>
</ul>
<pre class="r"><code># Short exercise:

# Generate 50 samples from Normal(mean=10,sd=5) 


# Generate 1000 samples from Poisson(mean=50)


# Generate 10 samples from Beta(shape1=0.1,shape2=0.1)


# Try some other distributions and parameters.  NOTE: you can visualize probability densities easily using the &quot;curve&quot; function:

curve(dnorm(x,0,2),-10,10)</code></pre>
<p><img src="LECTURE3_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<pre class="r"><code># What happens when you try to use a discrete distribution?</code></pre>
</div>
</div>
<div id="building-a-data-simulation-model" class="section level2">
<h2>Building a data simulation model</h2>
<p>For our purposes, a <strong>simulation model</strong> is any fully
specified, (usually) stochastic, computer program/script for data
generation.</p>
<p>Your data simulation model could be as simple as the random numbers
you were just generating. For example, we could make an assumption that
our sample data were independently generated from a random Poisson
process with constant mean (<span
class="math inline">\(\lambda\)</span>).</p>
<p>In general, our simulation models will comprise both
<strong>deterministic</strong> and <strong>stochastic</strong>
components.</p>
<p>For example, the data generating model underlying ordinary linear
regression consists of a <em>deterministic component</em> (<span
class="math inline">\(y = ax + b\)</span>) and a <em>stochastic
component</em> (the residual error is independently drawn from a normal
distribution).</p>
<div id="decomposing-ordinary-linear-regression" class="section level3">
<h3>decomposing ordinary linear regression:</h3>
<p>First, let’s look at the <strong>deterministic component</strong>.
The deterministic component maps covariate (predictor variable, or
independent variable) values to an expected response. It is
deterministic because the answer will be the same every time, given any
specific input (covariate) value(s).</p>
<pre class="r"><code># SIMULATE DATA: ------------------
#  decompose into deterministic and stochastic components (linear regression example)

## Deterministic component  -----------------------------------------

#   define function for transforming a predictor variable into an expected response (linear regression)

    # Arguments:
      # x: vector of covariate values (predictor variable)
      # a: the intercept of a linear relationship mapping the covariate to an expected response
      # b: the slope of a linear relationship mapping the covariate to an expected response

deterministic_component &lt;- function(x,a,b){
  linear &lt;- a + b*x   # specify a deterministic, linear functional form
  return(linear)
}

xvals = seq(0,100,10)  # define the values of a hypothetical predictor variable (e.g., tree girth)

expected_vals &lt;- deterministic_component(xvals,175,-1.5)   # use the deterministic component to determine the expected response (e.g., tree volume)
expected_vals</code></pre>
<pre><code>##  [1] 175 160 145 130 115 100  85  70  55  40  25</code></pre>
<pre class="r"><code>plot(xvals,expected_vals)   # plot out the relationship</code></pre>
<p><img src="LECTURE3_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre class="r"><code># plot(xvals,expected_vals,type=&quot;l&quot;)    # alternatively, plot as a line</code></pre>
<p>Now, let’s look at the <strong>stochastic component</strong> (also
known as the “noise”). Recall that a normal distribution is defined by a
mean and a variance (or standard deviation). We can consider the
deterministic component as representing the <strong>mean</strong>
(expected) value of the response for any given value(s) of relevant
covariates. Therefore, if we assume the “noise” is normally distributed,
all we need to generate stochastic data for any given covariate value(s)
is a <strong>variance</strong>, or standard deviation (the mean is
already defined).</p>
<pre class="r"><code>## Stochastic component -------------------------------------------- 
##    define a function for transforming an expected (deterministic) response and adding a layer of &quot;noise&quot; on top!

    # Arguments:
      # x: vector of expected responses
      # variance: variance of the &quot;noise&quot; component of your data simulation model
stochastic_component &lt;- function(x,variance){     
  sd &lt;- sqrt(variance)       # convert variance to standard deviation       
  stochvals &lt;- rnorm(length(x),x,sd)       # add a layer of &quot;noise&quot; on top of the expected response values
  return(stochvals)
}

           # alternative: add the &quot;residuals&quot; onto the expected values. 
# stochastic_component &lt;- function(x,variance){     
#   sd &lt;- sqrt(variance)       # convert variance to standard deviation       
#   stochvals &lt;- rnorm(length(x),0,sd)       # generate the &#39;residuals&#39;    
#   return(x+stochvals)             # add a layer of &quot;noise&quot; on top of the expected response values
# }

    ### Simulate stochastic data!!
sim_vals &lt;- stochastic_component(expected_vals,variance=500)   # try it- run the function to add noise to your expected values. 

plot(xvals,sim_vals)     # plot it- it should look much more &quot;noisy&quot; now!</code></pre>
<p><img src="LECTURE3_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<pre class="r"><code># ALTERNATIVELY:

sim_vals &lt;- stochastic_component(deterministic_component(xvals,175,-1.5),500)    # stochastic &quot;shell&quot; surrounds a deterministic &quot;core&quot;    </code></pre>
<p>You can think of the deterministic component as the
<strong>“signal”</strong> and the stochastic component as the
<strong>“noise”</strong>. Most data-generating processes that we will
consider have both components!</p>
<p>Much of statistics and machine learning involves trying to tease
apart these components– i.e., to detect signals from ‘noisy’ data. This
is especially true - and difficult - in the age of big data</p>
<hr />
</div>
</div>
<div id="replication" class="section level2">
<h2>Replication!</h2>
<p>Okay, we’ve now generated a random data set…</p>
<p>But wherever there is randomness (stochasticity), we can get
different results every time (that’s what it means to be random!). In
such cases, a single output of the data generating model by itself has
little meaning. However, we can extract a great deal of meaning if we
run lots of replicates. <em><em>The distribution of data across all
replicates becomes the real result!</em></em></p>
<div id="goodness-of-fit" class="section level3">
<h3>Goodness-of-fit</h3>
<p>For example, let’s run a goodness-of-fit test. A goodness-of-fit test
asks the question: can this model plausibly generate the observed
data?</p>
<p>For example, consider a set of “real” data:</p>
<pre class="r"><code># Goodness-of-fit test! -------------------------------------

    # Do the data fall into the range of plausible values produced by this model?

# Imagine you have the following &quot;real&quot; data (e.g., tree volumes). 

realdata &lt;- data.frame(Volume=c(125,50,90,110,80,75,100,400,350,290,350),Girth=xvals)
plot(realdata$Girth,realdata$Volume)</code></pre>
<p><img src="LECTURE3_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>The following parameters together fully specify a data-generating
model that we hypothesize is the model that generated our data. Is this
fully specified linear regression model a good fit to our data?</p>
<pre><code>intercept (a) = 10         # these parameters together specify a model that could have generated our data
slope (b) = 4
variance(var) = 1000
</code></pre>
<p>We can evaluate this question by brute force programming…</p>
<p>And we will, of course!</p>
<p>First we specify the data generating model. Then we simulate multiple
datasets under this model that are comparable to our observed dataset
(same sample size). Then we evaluate (visually for now) whether our data
generating model is capable of generating our observed data.</p>
<pre class="r"><code># Simulate many datasets from our hypothesized data generating model (intercept=10,slope=4,variance=1000):

reps &lt;- 1000    # specify number of replicate datasets to generate
samplesize &lt;- nrow(realdata)    # define the number of data points we should generate for each simulation &quot;experiment&quot;
simresults &lt;- array(0,dim=c(samplesize,reps))   # initialize a storage array for results 
exp_vals &lt;- deterministic_component(realdata$Girth,a=10,b=4)          # simulate the expected tree volumes for each measured girth value
for(i in 1:reps){       # for each independent simulation &quot;experiment&quot;:
  sim_vals &lt;- stochastic_component(exp_vals,1000)  # add stochastic noise
  simresults[,i] &lt;- sim_vals   # store the simulated data for later
}

    # now make a boxplot of the results
boxplot(t(simresults),xaxt=&quot;n&quot;)    # (repeat) make a boxplot of the simulation results
axis(1,at=c(1:samplesize),labels=realdata$Girth)                          # add x axis labels </code></pre>
<p><img src="LECTURE3_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Now let’s overlay the “real” data. This gives us a visual
goodness-of-fit test!</p>
<pre class="r"><code># Now overlay the &quot;real&quot; data
    # how well does the model fit the data?

boxplot(lapply(1:nrow(simresults), function(i) simresults[i,]),xaxt=&quot;n&quot;)    # (repeat) make a boxplot of the simulation results
axis(1,at=c(1:samplesize),labels=realdata$Girth)                          # add x axis labels 
points(c(1:samplesize),realdata$Volume,pch=20,cex=3,col=&quot;red&quot;,xaxt=&quot;n&quot;)     # this time, overlay the &quot;real&quot; data </code></pre>
<p><img src="LECTURE3_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>How well does this model fit the data?</p>
<p>Is this particular model likely to produce these data? (we will
revisit this concept more quantitatively when we get to likelihood-based
model fitting!)</p>
<p>What about if we try an intercept-only null model with expected
Volume of 100 and variance of 200000 ? What happens now?</p>
<pre class="r"><code># Let&#39;s simulate many datasets from a &#39;null&#39; model (intercept=100,slope=0,variance=75000):

reps &lt;- 1000    # specify number of replicate datasets to generate
samplesize &lt;- nrow(realdata)    # define the number of data points we should generate for each simulation &quot;experiment&quot;
simresults &lt;- array(0,dim=c(samplesize,reps))   # initialize a storage array for results 
for(i in 1:reps){       # for each independent simulation &quot;experiment&quot;:
  exp_vals &lt;- deterministic_component(realdata$Girth,a=100,b=0)          # simulate the expected tree volumes for each measured girth value
  sim_vals &lt;- stochastic_component(exp_vals,200000)  # add stochastic noise
  simresults[,i] &lt;- sim_vals   # store the simulated data for later
}

    # now make a boxplot of the results
boxplot(lapply(1:nrow(simresults), function(i) simresults[i,]),xaxt=&quot;n&quot;)    # (repeat) make a boxplot of the simulation results
axis(1,at=c(1:samplesize),labels=realdata$Girth)                          # add x axis labels 
points(c(1:samplesize),realdata$Volume,pch=20,cex=3,col=&quot;red&quot;,xaxt=&quot;n&quot;)     # this time, overlay the &quot;real&quot; data </code></pre>
<p><img src="LECTURE3_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>Could this model have generated the data?</p>
<p>Is this model <strong>likely</strong> to be the model that generated
the data? What’s your intuition?</p>
<p>Is this model <strong>useful</strong>?</p>
</div>
<div
id="generating-sampling-distributions-i.e.-simulate-the-distribution-of-test-statistics-under-a-null-hypothesis"
class="section level3">
<h3>Generating <em>sampling distributions</em> (i.e., simulate the
distribution of test statistics under a null hypothesis)</h3>
<p>A null hypothesis can usually be expressed as a data-generating
model.</p>
<p>If so, you should be able to generate sampling distributions of any
test statistic under your null distribution.</p>
<p>For example, the ‘brute force’ z-test from the first lecture!</p>
<p><strong>NOTE</strong>: Frequentist statistical tests are based on a
single sample that is one of an theoretically infinite number of
potential samples. The interpretation of the results is based on the
idea of hypothetical sample replication (e.g., “if the null hypothesis
were true, and the experiment were <em>replicated</em> lots and lots of
times, results as or more extreme than the observed results could be
expected from less than 1% of replicates”)</p>
</div>
<div id="power-analysis-can-my-sampling-design-detect-the-signal"
class="section level3">
<h3>Power analysis!! (can my sampling design detect the “signal”?)</h3>
<p>When designing experiments or field monitoring protocols, we often
ask questions like:</p>
<ul>
<li>What sample size do I need to be able to effectively test my
hypothesis?</li>
<li>What is the smallest effect size I can reliably detect with my
sampling design?</li>
<li>What sources of sampling or measurement error should I make the
greatest effort to minimize?</li>
</ul>
<p>In such cases, probably the most straightforward (yet not always the
most efficient) way to address these questions is to simulate data under
various sampling strategies and signal/noise ratios, and see how well
you can recover the “true” signal through the noise!</p>
</div>
<div id="power-analysis-example" class="section level3">
<h3>Power analysis, example</h3>
<p>Imagine we are designing a monitoring program for a population of an
at-risk species, and we want to have <em>at least a 75% chance of
detecting a decline in abundance of 25% or more over a 25 year
period</em>. Let’s assume that we are using visual counts, and that the
probability of encountering each member of the population is 2% per
person-day. The most recent population estimate was 1000: here we will
assume that is known with certainty.</p>
<p>What we know:</p>
<ul>
<li>A single surveyor has a 2% chance of detecting each animal in the
population in a single day of surveying<br />
</li>
<li>The initial abundance is 1000<br />
</li>
<li>We want to be able to detect a decline as small as 25% over 25 years
with at least 75% probability.</li>
</ul>
<p>First, let’s set the groundwork by making some helper functions
(break the problem into smaller chunks).</p>
<p>This function takes the true number in the population and returns the
observed number:</p>
<pre class="r"><code># Power analysis example ---------------------------------
#    designing a monitoring program for a rare species


   ### first, let&#39;s develop some helper functions:

## helper function 1 ---------------------------
# function for computing the number of observed/detected animals in a single survey

    # Arguments:
      # TrueN: true population abundance
      # surveyors: number of survey participants each day
      # days: survey duration, in days

NumObserved &lt;- function(TrueN=1000,surveyors=1,days=3){
  probPerPersonDay &lt;- 0.02      # define the probability of detection per animal per person-day [hard-coded- potentially bad coding practice!]
  probPerDay &lt;- 1-(1-probPerPersonDay)^surveyors      # define the probability of detection per animal per day (multiple surveyors)(animal must be detected at least once)
  probPerSurvey &lt;- 1-(1-probPerDay)^days       # define the probability of detection per animal for the entire survey
  nobs &lt;- rbinom(1,size=TrueN,prob=probPerSurvey)     # simulate the number of animals detected!
  return(nobs)
}
NumObserved(TrueN=500,surveyors=2,days=7)   # test the new function</code></pre>
<pre><code>## [1] 115</code></pre>
<p>This function gives us the current-year abundance using last year’s
abundance and trend information</p>
<pre class="r"><code>## helper function 2 -----------------------------
##   function for computing expected abundance dynamics of a declining population (deterministic component!)

    # Arguments:
      # LastYearAbund: true population abundance in the previous year
      # trend: proportional change in population size from last year

ThisYearAbund &lt;- function(LastYearAbund=1000,trend=-0.03){
  CurAbund &lt;- LastYearAbund + trend*LastYearAbund    # compute abundance this year
  CurAbund &lt;- floor(CurAbund)  # can&#39;t have fractional individuals!
  return(CurAbund)
}
ThisYearAbund(LastYearAbund=500,trend=-0.03)    # test the new function</code></pre>
<pre><code>## [1] 485</code></pre>
<pre class="r"><code># NOTE: we could introduce stochastic population dynamics (or density dependence, etc!) for a more realistic model, but we are omitting this here. </code></pre>
<p>This function will simulate a single dataset (time series of
observations over a given number of years)!</p>
<pre class="r"><code>## function: simulate monitoring data ----------------------------

# develop a function for simulating monitoring data from a declining population

    # Arguments:
      # initabund: true initial population abundance
      # trend: proportional change in population size from last year
      # years: duration of simulation
      # observers: number of survey participants each day
      # days: survey duration, in days
      # survint: survey interval, in years (e.g., 2 means surveys are conducted every other year)

SimulateMonitoringData &lt;- function(initabund=1000,trend=-0.03,years=25,observers=1,days=3,survint=2){
  prevabund &lt;- initabund        # initialize &quot;previous-year abundance&quot; at initial abundance 
  detected &lt;- numeric(years)    # set up storage variable
  for(y in 1:years){            # for each year of the simulation:
    thisAbund &lt;- ThisYearAbund(prevabund,trend)             # compute the current abundance on the basis of the trend
    detected[y] &lt;- NumObserved(thisAbund,observers,days)     # sample the current population using this monitoring scheme
    prevabund &lt;- thisAbund   # set this years abundance as the previous years abundance (to set up the simulation for next year)
  }
  surveyed &lt;- c(1:years)%%survint==0    # which years were surveys actually performed?
  detected[!surveyed] &lt;- NA            # if the survey is not performed that year, return a missing value
  return(detected)       # return the number of individuals detected
}

SimulateMonitoringData(initabund=1000,trend=-0.03,years=25,observers=1,days=3,survint=2)    # test the new function</code></pre>
<pre><code>##  [1] NA 60 NA 54 NA 46 NA 44 NA 41 NA 43 NA 47 NA 32 NA 31 NA 33 NA 34 NA 33 NA</code></pre>
<p>Note that we are using NA to indicate years where no survey was
conducted. A zero value would mean something very different than an
NA.</p>
<p>Now we can develop a function for determining if a decline was in
fact detected by the method:</p>
<pre class="r"><code>## function: assessing whether or not a decline was detected ------------------------

    # Arguments:
      # monitoringData: simulated results from a long-term monitoring study
      # alpha: define acceptable type-I error rate (false positive rate)

IsDecline &lt;- function(monitoringData,alpha=0.05){
  time &lt;- 1:length(monitoringData)      # vector of survey years
  model &lt;- lm(monitoringData~time)    # for now, let&#39;s use ordinary linear regression (perform linear regression on simulated monitoring data)
  p_value &lt;- summary(model)$coefficients[&quot;time&quot;,&quot;Pr(&gt;|t|)&quot;]      # extract the p-value  
  isdecline &lt;- ifelse(summary(model)$coefficients[&quot;time&quot;,&quot;Estimate&quot;]&lt;0,TRUE,FALSE)     # determine if the simulated monitoring data determined a &quot;significant&quot; decline
  sig_decline &lt;- ifelse((p_value&lt;=alpha)&amp;(isdecline),TRUE,FALSE)    # if declining and significant trend, then the monitoring protocol successfully diagnosed a decline
  return(sig_decline)
}

IsDecline(monitoringData=c(10,20,NA,15,1),alpha=0.05)    # test the function</code></pre>
<pre><code>## [1] FALSE</code></pre>
<p>Now we can develop a “power” function that gives us the statistical
power for given monitoring scenarios…</p>
<p>This is part of this week’s lab assignment!</p>
<pre class="r"><code>## Review lab exercise (lab 2) ----------------------------
##     develop a &quot;power&quot; function to return the statistical power to detect a decline under alternative monitoring schemes...

nreps &lt;- 10000      # set number of replicate monitoring &quot;experiments&quot;
initabund &lt;- 1000    # set initial population abundance.

GetPower &lt;- function(nreps=nreps,initabund=initabund,trend=-0.03,years=25,observers=1,days=3,survint=2,alpha=0.05){
     # fill this in!
  return(Power)
}</code></pre>
<pre><code>## The statistical power to detect a decline for the default parameters is: 0.394</code></pre>
<p>And we can evaluate what types of monitoring programs might be
acceptable:</p>
<p><img src="LECTURE3_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p><a href="LECTURE4.html">–go to next lecture–</a></p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
