<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="NRES 746" />


<title>Why focus on algorithms?</title>

<script src="site_libs/header-attrs-2.11/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cerulean.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">NRES 746</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Schedule
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="schedule.html">Course Schedule</a>
    </li>
    <li>
      <a href="Syllabus.pdf">Syllabus</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Lectures
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="INTRO.html">Introduction to NRES 746</a>
    </li>
    <li>
      <a href="LECTURE1.html">Why focus on algorithms?</a>
    </li>
    <li>
      <a href="LECTURE2.html">Working with probabilities</a>
    </li>
    <li>
      <a href="LECTURE3.html">The Virtual Ecologist</a>
    </li>
    <li>
      <a href="LECTURE4.html">Likelihood</a>
    </li>
    <li>
      <a href="LECTURE5.html">Optimization</a>
    </li>
    <li>
      <a href="LECTURE6.html">Bayesian #1: concepts</a>
    </li>
    <li>
      <a href="LECTURE7.html">Bayesian #2: mcmc</a>
    </li>
    <li>
      <a href="LECTURE8.html">Model Selection</a>
    </li>
    <li>
      <a href="LECTURE9.html">Performance Evaluation</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Lab exercises
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="LAB_Instructions.html">Instructions for Labs</a>
    </li>
    <li>
      <a href="FINALPROJ.html">Final project overview</a>
    </li>
    <li>
      <a href="LAB3demo.html">Lab 3: Likelihood (intro)</a>
    </li>
    <li>
      <a href="LAB5.html">Lab 5: Model selection (optional)</a>
    </li>
    <li>
      <a href="FigureDemo.html">Demo: Figures in R</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Student-led topics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="LECTURE10.html">Machine Learning</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Data sets
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="TreeData.csv">Tree Data</a>
    </li>
    <li>
      <a href="ReedfrogPred.csv">Reed Frog Predation Data</a>
    </li>
    <li>
      <a href="ReedfrogFuncresp.csv">Reed Frog Func Resp</a>
    </li>
  </ul>
</li>
<li>
  <a href="Links.html">Links</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Why focus on algorithms?</h1>
<h4 class="author">NRES 746</h4>
<h4 class="date">Fall 2021</h4>

</div>


<p><strong>NOTE:</strong> for those wishing to follow along with the R-based demo in class, <a href="LECTURE1.R">click here</a> for an R-script that contains all of the code blocks in this lecture.</p>
<div id="algorithmic-vs-standard-statistics-a-brief-demonstration" class="section level2">
<h2>Algorithmic vs standard statistics: a brief demonstration</h2>
<div id="standard-z-test" class="section level3">
<h3>Standard z-test</h3>
<p>Here is a made-up data set.</p>
<p><img src="salmon1.jpg" /></p>
<p>Let’s imagine we’re interested in testing whether the mean body mass of farm-raised Atlantic salmon fed on a new all-vegetarian diet has a lower body mass than the ‘typical’ farm-raised fish raised on a conventional diet after one year of growth.</p>
<p>Let’s assume that we know the following information:</p>
<p>First of all, we have been measuring the body mass of farm-raised salmon raised on a conventional diet for years, and we know that body mass for these individuals after one year closely follows a normal distribution with mean of 4.5 kg and standard deviation of 0.9 kg.</p>
<p>Secondly, we measured the body mass for 10 individuals raised on the new vegetarian diet after one year, and the measurements were as follows:</p>
<pre><code>Ind 1  Ind 2  Ind 3  Ind 4  Ind 5  Ind 6  Ind 7  Ind 8  Ind 9 Ind 10 
3.14   3.27   2.56   3.77   3.34   4.32   3.84   2.19   5.24   3.09 </code></pre>
<p>Finally, our alternative hypothesis is that the fish raised on the new diet will have lower body mass than fish raised on the conventional diet.</p>
<p>Let’s read this information into R:</p>
<pre class="r"><code>###################
# SALMON EXAMPLE (made-up!)

population.mean = 4.5
population.sd = 0.9

my.sample = c(3.14,3.27,2.56,3.77,3.34,4.32,3.84,2.19,5.24,3.09)

sample.size &lt;- length(my.sample)     # determine sample size   

obs.samplemean = mean(my.sample)     # note the equal sign as assignment operator

## visualize the population of conventional-raised salmon

curve(dnorm(x,population.mean,population.sd),0,10,
      xlab=&quot;Body mass (kg)&quot;,ylab=&quot;Probability density&quot;)</code></pre>
<p><img src="LECTURE1_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code>## now overlay this on the observed data

hist(my.sample,freq=F,
     xlab=&quot;Body mass (kg)&quot;,ylab=&quot;Probability density&quot;,main=&quot;&quot;,
     xlim=c(0,10))
curve(dnorm(x,population.mean,population.sd),0,10,
      col=&quot;red&quot;,lwd=2,add=T)
abline(v=obs.samplemean,col=&quot;blue&quot;,lwd=3)</code></pre>
<p><img src="LECTURE1_files/figure-html/unnamed-chunk-2-2.png" width="672" /></p>
<p>You may recognize this as the kind of problem that you would address using a standard z-test; we are assuming for now that the samples are independently drawn from a normally distributed population with known variance. In the z-test, we are testing whether our sample could plausibly have been drawn from the <strong>null distribution</strong> (fish raised on conventional diet), which in this case is a normal distribution with known mean and variance. If we did not know the population variance (the population variance was uncertain) we would use a t-test instead of a z-test. We can run a z-test in R easily using the ‘BSDA’ package, using just one line of code!</p>
<pre class="r"><code>################
# Perform standard z-test
################

library(BSDA)</code></pre>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## 
## Attaching package: &#39;BSDA&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:datasets&#39;:
## 
##     Orange</code></pre>
<pre class="r"><code>z.test(x=my.sample,mu=population.mean, sigma.x=population.sd,alternative = &quot;less&quot;)</code></pre>
<pre><code>## 
##  One-sample z-Test
## 
## data:  my.sample
## z = -3.598, p-value = 0.0001604
## alternative hypothesis: true mean is less than 4.5
## 95 percent confidence interval:
##        NA 3.944134
## sample estimates:
## mean of x 
##     3.476</code></pre>
<p>…and we quickly see that our sample mean is much smaller than we could ever expect to sample under the null hypothesis. Therefore we can conclude that the sample was NOT drawn from the null distribution, and that fish raised on the new diet tend to have lower body mass than other farm-raised fish raised on a conventional diet.</p>
<p>Here’s an alternative z-test performed using base R:</p>
<pre class="r"><code>############
# alternative z-test

std.err = population.sd/sqrt(sample.size)

curve(dnorm(x,population.mean,std.err),0,10,     # visualize the sampling distribution under null hypothesis
      xlab=&quot;Body mass (kg)&quot;,ylab=&quot;Probability density&quot;)     # versus the observed sample mean
abline(v=obs.samplemean,col=&quot;blue&quot;,lwd=3)</code></pre>
<p><img src="LECTURE1_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre class="r"><code>p.val = pnorm(obs.samplemean,population.mean,std.err)
p.val     # this is the same as the p value from the z-test above...</code></pre>
<pre><code>## [1] 0.0001603558</code></pre>
</div>
<div id="brute-force-z-test" class="section level3">
<h3>Brute-force z-test</h3>
<p>But imagine that we didn’t know about the z-test. Let’s build a solution to the same problem from the ground up, using our statistical intuition and R! Of course this is <em>totally unnecessary</em> in this case, but you will quickly run into problems with no simple, “canned” solution. That’s where you might really need to develop an algorithm from scratch!</p>
<p>First, let’s state the problem:</p>
<p>We want to know if the mean mass of 10 salmon raised on the new diet is less than the mean mass we would expect to observed if we sampled 10 random salmon raised on the conventional diet.</p>
<p>We assume that our sample of individuals raised on the new diet is identical to other farm-raised fish- the only difference is the diet.</p>
<p>We also assume that every fish in our sample is independently drawn from an infinitely large theoretical population of farm-raised fish raised on the new diet.</p>
<p>Let’s build a simulation-based <strong>algorithm</strong> to generate a p-value!</p>
<p>Recall the difference between a “population” and a “sample” in statistics:</p>
<p><img src="statistics1.png" /></p>
<p>Ultimately, we want to make inference about a <strong>population</strong>, but all we have in hand is the <strong>sample</strong>. So we compute one or more <strong>statistics</strong> from our sample and use probabilistic reasoning to infer what our sample says about the population-level <strong>parameters</strong> we are interested in. Because we didn’t observe the whole population (the sample typically represents only a small fraction of the total population), there’s often substantial uncertainty about how well the sample statistic actually represents the population of interest- this is called <strong>sampling uncertainty</strong>.</p>
<p>Here, the <em>population</em> we are referring to is all farm-raised Atlantic salmon that are raised on the new vegetarian diet. The population <em>parameter</em> we are interested in is the mean body mass of these salmon after one year. The <em>sample</em> refers to all salmon actually measured as part of this study. Finally, the sample <em>statistic</em> is the observed mean body mass of all individuals in our sample.</p>
<p>Let’s start by simulating a <em>statistical population</em> under the null hypothesis (no treatment effect):</p>
<pre class="r"><code>######################
   # ALTERNATIVE ALGORITHMIC APPROACH!
######################

#############
# Simulate the STATISTICAL POPULATION under the null hypothesis
#############

infinity &lt;- 1000000  # large number approximating infinity 

popData_null &lt;- rnorm(n=infinity,mean=population.mean,sd=population.sd)    # the statistical &quot;population&quot; of interest (under null model w no &#39;treatment&#39; effect)</code></pre>
<p>Then we can draw a <strong>sample</strong> from the null distribution:</p>
<pre class="r"><code>#############
# Draw a SAMPLE from that null data
#############

null.sample &lt;- sample(popData_null,size=sample.size)    # use R&#39;s native &quot;sample()&quot; function to sample from the null distribution

round(null.sample,2)</code></pre>
<pre><code>##  [1] 3.34 4.67 3.50 6.03 4.27 3.19 4.40 3.96 4.30 5.42</code></pre>
<pre class="r"><code>null.samplemean &lt;- mean(null.sample)  
null.samplemean    # here is one sample mean that we can generate under the null hypothesis</code></pre>
<pre><code>## [1] 4.307283</code></pre>
<p>Try it! What did you get? It may differ quite a bit from what I got!</p>
<p>This null sample mean represents the mean of 10 fish sampled under a <em>null hypothesis</em> where there is no underlying difference in body mass between the conventional diet and the new diet. Of course, under the null hypothesis, the fish we measured were basically drawn from the null distribution- just like the random sample we just drew. The fact that this sample mean is not equal to 4.5 (the known population mean) represents <strong>sampling error</strong>.</p>
<p>Our ultimate goal is to determine how likely it is that the observed difference between the sample mean (the mean body mass of the fish we actually measured) and the known population mean is just a meaningless artifact of sampling error! This is exactly what the <strong>p-value</strong> tells us!</p>
<p><strong>Q</strong> To begin to <strong>falsify</strong> our null hypothesis about the population of interest, we need to determine the probability that random sampling error could produce a result at least as extreme as our observed sample statistic. Can you think of an algorithmic way to do this?</p>
<p>Let’s generate a <strong>sampling distribution</strong> (distribution of sample statistics generated under the null hypothesis).</p>
<p>Here, we repeat this sampling process many times (using a “FOR” loop in R), each time drawing a different random sample of body masses from our null data population.</p>
<pre class="r"><code>#################
# Repeat this process using a FOR loop
#################

n.samples &lt;- 1000                 # set the number of replicate samples to generate
null.samplemeans &lt;- numeric(n.samples)       # initialize a storage vector for sample means under the null hypothesis

for(i in 1:n.samples){            # for each replicate... 
  this.nullsample &lt;- sample(popData_null,size=sample.size)      # draw a sample of body masses assuming no treatment effect       
  null.samplemeans[i] &lt;- mean(this.nullsample)           # compute and store the sampling distribution produced under the null hypothesis
}

hist(null.samplemeans,xlim=c(0,10))       # plot out the sampling distribution
abline(v=obs.samplemean,col=&quot;green&quot;,lwd=3)     # overlay the observed sample statistic. </code></pre>
<p><img src="LECTURE1_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Now, all we need to do to compute a p-value is to compare this vector of sampling errors with the observed statistic (between-group difference):</p>
<pre class="r"><code>############
# Generate a p-value algorithmically!!
############

ordered_means &lt;- sort(null.samplemeans)       # sort the vector of null sample means
more_extreme &lt;- length(which(ordered_means&lt;=obs.samplemean))       # how many of these sampling errors equal or exceed the &quot;extremeness&quot; of the observed statistic?
p_value &lt;- more_extreme/n.samples       # compute a p-value! 
p_value    </code></pre>
<pre><code>## [1] 0</code></pre>
<p>Now, for convenience, let’s collapse this all into a <em>function</em> for conducting our algorithmic t-test.</p>
<p>Here is the pseudocode:</p>
<p>Function inputs:</p>
<ul>
<li>sample: the sampled data<br />
</li>
<li>pop.mean: the known population mean under the null hypothesis<br />
</li>
<li>pop.sd: the known population std deviation under the null hypothesis</li>
</ul>
<p>Function algorithm:</p>
<ul>
<li>compute the sample mean<br />
</li>
<li>determine the sample size<br />
</li>
<li>do the following 1000 times:
<ul>
<li>obtain a sample from the null data distribution of the same size as the observed data<br />
</li>
<li>store the result<br />
</li>
</ul></li>
<li>determine how many of the null samples were more extreme than the observed sample statistic<br />
</li>
<li>compute the p-value</li>
</ul>
<p>Function returns:</p>
<ul>
<li>a list object with:
<ul>
<li>null_dist: the sampling distribution under the null hypothesis<br />
</li>
<li>p_value: the p-value!<br />
</li>
<li>observed_mean: the sample mean</li>
</ul></li>
</ul>
<p>Now let’s write the function in R!</p>
<pre class="r"><code>#############
# Develop a function that wraps up all the above steps into one!
#############

z.test.algorithm &lt;- function(sample, pop.mean, pop.sd){
  
  #############
  # Compute the sample statistic
  #############
  
  observed_mean &lt;- mean(sample)
  
  sample.size &lt;- length(sample)   # compute sample size

  #################
  # Generate SAMPLING DISTRIBUTION
  #################
  
  reps &lt;- 1000                 # set the number of replicate samples
  null_dist &lt;- numeric(reps)       # initialize a storage structure for sampling distribution
  
  for(i in 1:reps){            # for each replicate... 
    nullsamp &lt;- rnorm(sample.size,pop.mean,pop.sd)      # draw a sample assuming no treatment effect       
    null_dist[i] &lt;- mean(nullsamp)           # compute and store the sample produced under the null hypothesis
  }
  
  more.extreme &lt;- length(which(null_dist&lt;=observed_mean))       # how many of these are more extreme than the sample statistic?
  p_value &lt;- more.extreme/reps
  
  to_return &lt;- list()   # initialize object to return
  
  to_return$null_dist &lt;- null_dist
  to_return$p_value &lt;- p_value
  to_return$observed_mean &lt;- observed_mean
  
  return(to_return)

}

ztest &lt;- z.test.algorithm(sample = my.sample, pop.mean=population.mean, pop.sd=population.sd )   # try to run the new function

ztest$p_value     # get the p_value

hist(ztest$null_dist)       # plot out all the samples under the null hypothesis as a histogram
abline(v=ztest$observed_mean,col=&quot;green&quot;,lwd=3)     # indicate the observed sample statistic. </code></pre>
<div id="take-home-message" class="section level4">
<h4>Take-home message</h4>
<p>The value of the algorithmic, brute-force approach to statistics is the flexibility! We have to be aware of assumptions in all of our analyses, but when we build our own computational algorithms, we can easily “relax” these assumptions! We only make the assumptions we are comfortable making. And we have to be totally explicit about our assumptions, because they are literally built into the code- we can’t ignore any assumptions!</p>
</div>
</div>
<div id="a-non-parametric-t-test-permutation-t-test" class="section level3">
<h3>A non-parametric t-test: permutation t-test</h3>
<p>What if we don’t want to make any assumptions about the process that generated the data? The normal distribution can arise in many different ways (according to the central limit theorem), but many data-generating processes <strong>don’t</strong> result in a normal distribution!</p>
<p>We might be able to imagine which of the many alternative distributions makes the most sense for our data. But many times we can’t do this with any level of certainty. What can we do in this case? A <em>permutation test</em> provides one answer.</p>
<p>This is a <em>nonparametric</em> test, meaning it does not make any assumptions about how the population parameter of interest is distributed.</p>
<div id="example-pygmy-short-horned-lizard" class="section level4">
<h4>example: pygmy short-horned lizard</h4>
<p><img src="shorthornedlizard.jpg" /></p>
<p>Let’s imagine we’re interested in testing whether the expected mass of a study organism (let’s say a pygmy short-horned lizard, <em>Phrynosoma douglasii</em>) in Treatment A (e.g., habitat restoration treatment) differs from Treatment B (e.g., no habitat restoration). In other words: does knowledge of an individuals treatment status contribute anything to understanding and/or predicting an individual’s mass?</p>
<p>In this case, our alternative hypothesis is two-tailed: the treatment means are different, but treatment A mean could be larger or smaller than treatment B mean.</p>
<pre class="r"><code>#############
# Start with a made-up data frame!
#############

df &lt;- data.frame(
  A = c(175, 168, 168, 190, 156, 181, 182, 175, 174, 179),
  B = c(185, 169, 173, 173, 188, 186, 175, 174, 179, 180) 
)

summary(df)    # summarize! </code></pre>
<pre><code>##        A               B        
##  Min.   :156.0   Min.   :169.0  
##  1st Qu.:169.5   1st Qu.:173.2  
##  Median :175.0   Median :177.0  
##  Mean   :174.8   Mean   :178.2  
##  3rd Qu.:180.5   3rd Qu.:183.8  
##  Max.   :190.0   Max.   :188.0</code></pre>
<pre class="r"><code>sample.size &lt;- length(df$A)     # determine sample size    

#######
# Get data in proper format

reshape_df &lt;- data.frame(                # &quot;reshape&quot; the data frame so each observation gets its own row (standard &#39;tidy&#39; format)
  Treatment = rep(c(&quot;A&quot;,&quot;B&quot;),each=sample.size),
  Mass = c(df$A,df$B),
  stringsAsFactors = T
)


########
# Alternative (commented out)- using the &#39;tidyverse&#39;

# library(tidyr)
# reshape_df &lt;- pivot_longer(df,everything(),names_to = &quot;Treatment&quot;,values_to=&quot;Mass&quot;)


plot(Mass~Treatment, data=reshape_df)    # explore/visualize the data</code></pre>
<p><img src="LECTURE1_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<pre class="r"><code>#######
# Compute the observed difference between group means

observed_dif &lt;- mean(reshape_df$Mass[reshape_df$Treatment==&quot;A&quot;])    - mean(reshape_df$Mass[reshape_df$Treatment==&quot;B&quot;])</code></pre>
<p>Here, our goal will be to determine if the observed difference between the two group means could plausibly result from random sampling under the null hypothesis. This time, we want to generate a p-value that represents the probability that random sampling (under the null hypothesis) could result in a difference as or more extreme than the observed difference.</p>
<p>Let’s build this permutation-test algorithm together.</p>
<p>Here is some <strong>pseudocode</strong>:</p>
<ol style="list-style-type: decimal">
<li>Define the number of permutations to run (number of replicate samples to generate)<br />
</li>
<li>Define a storage vector with the same number of elements as the number of samples to generate.</li>
<li>For each replicate sample:
<ol style="list-style-type: lower-alpha">
<li>Assign each observation to a random treatment group (A or B)</li>
<li>Compute the difference between the group means after assigning each observation to a random treatment group</li>
<li>Store this value in the storage vector</li>
</ol></li>
<li>Plot a histogram of the differences between group means under the null hypothesis (null sampling distribution)</li>
<li>Add a vertical line to the plot to indicate the observed difference between group means</li>
<li>Compute a p-value</li>
</ol>
<pre class="r"><code>##################
# NON-PARAMETRIC T-TEST -- PERMUTATION TEST
##################

reps &lt;- 5000            # Define the number of permutations to run (number of replicates)
null_difs &lt;- numeric(reps)   # initialize storage variable
for (i in 1:reps){          # For each replicate:       
  newGroup &lt;- reshape_df$Treatment[sample(c(1:nrow(reshape_df)))]              # randomly shuffle the observed data with respect to treatment group
    dif &lt;- mean(reshape_df$Mass[newGroup==&quot;A&quot;]) - mean(reshape_df$Mass[newGroup==&quot;B&quot;])     #  compute the difference between the group means after reshuffling the data
    null_difs[i] &lt;- dif     # store this value in a vector
}
hist(null_difs)    # Plot a histogram of null differences between group A and group B under the null hypothesis (sampling errors)
abline(v=observed_dif,col=&quot;green&quot;,lwd=3)   # Add a vertical line to the plot to indicate the observed difference</code></pre>
<p><img src="LECTURE1_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>Now we can compute a p-value, just as we did before:</p>
<pre class="r"><code>########
# Compute a p-value based on the permutation test, just like we did before (except now 2-tailed)!
########

more_extreme &lt;- length(which(abs(null_difs)&gt;=abs(observed_dif)))
p_value &lt;- more_extreme/reps  
p_value</code></pre>
<pre><code>## [1] 0.375</code></pre>
<p>Again, for convenience, let’s package this new permutation-based t test into an R function:</p>
<pre class="r"><code>#############
# Develop a function that performs a permutation-t-test!
#############

t.test.permutation &lt;- function(dat = reshape_df, group = &quot;Treatment&quot;, value = &quot;Mass&quot; ){
  
  #############
  # Compute the sample statistic
  #############
  
  indexA &lt;- which(dat[,group]==&quot;A&quot;)     # rows representing treatment A
  indexB &lt;- which(dat[,group]==&quot;B&quot;)     # rows representing treatment B
  observed_dif &lt;- mean(dat[indexA,value]) - mean(dat[indexB,value])
  
  reps &lt;- 5000            # Define the number of permutations to run (number of replicates)
  null_difs &lt;- numeric(reps)   # initialize storage variable
  for (i in 1:reps){            # For each replicate:       
    newGroup &lt;- reshape_df$Treatment[sample(c(1:nrow(reshape_df)))]            # randomly shuffle the observed data with respect to treatment group
    dif &lt;- mean(reshape_df$Mass[newGroup==&quot;A&quot;]) - mean(reshape_df$Mass[newGroup==&quot;B&quot;])     #  compute the difference between the group means after reshuffling the data
    null_difs[i] &lt;- dif     # store this value in a vector
  }
  
  more_extreme &lt;- length(which(abs(null_difs)&gt;=abs(observed_dif)))
  p_value &lt;- more_extreme/reps  
  
  to_return &lt;- list()   # initialize object to return
  
  to_return$null_difs &lt;- null_difs
  to_return$p_value &lt;- p_value
  to_return$observed_dif &lt;- observed_dif
  
  return(to_return)
  
}

my.ttest &lt;- t.test.permutation()   # use default values for all function arguments

my.ttest$p_value

hist(my.ttest$null_difs)    # Plot a histogram of null differences between group A and group B under the null hypothesis (sampling errors)
abline(v=my.ttest$observed_dif,col=&quot;green&quot;,lwd=3)   # Add a vertical line to the plot to indicate the observed difference</code></pre>
</div>
</div>
</div>
<div id="bootstrapping-a-confidence-interval" class="section level2">
<h2>Bootstrapping a confidence interval</h2>
<p>Let’s imagine we want to compare different predictor variables in terms of how strong the relationship is with a response variable. In this case, we will use the coefficient of determination (<span class="math inline">\(R^2\)</span>) as a measure of how good a predictor is. However, we want to be able to say that one predictor is definitively <em>better</em> than another one – for that, we would like a confidence interval around the <span class="math inline">\(R^2\)</span> value.</p>
<p>But… none of the standard R packages provides a confidence interval for the <span class="math inline">\(R^2\)</span> value… What do do???</p>
<p>With an algorithmic approach to statistics, getting stuck is not an option. We can just write some code!</p>
<p>Let’s use the “trees” dataset provided in base R:</p>
<pre class="r"><code>##############
# Demonstration: bootstrapping a confidence interval!

## use the &quot;trees&quot; dataset in R:

head(trees)   # use help(trees) for more information</code></pre>
<pre><code>##   Girth Height Volume
## 1   8.3     70   10.3
## 2   8.6     65   10.3
## 3   8.8     63   10.2
## 4  10.5     72   16.4
## 5  10.7     81   18.8
## 6  10.8     83   19.7</code></pre>
<p>Tree volume is our response variable. We want to test whether girth or height are better predictors of tree volume.</p>
<p>Let’s first do some basic data exploration:</p>
<pre class="r"><code>#########
# Basic data exploration

plot(trees$Volume~trees$Height, main = &#39;Black Cherry Tree Height/Volume Relationship&#39;, xlab = &#39;Height&#39;, ylab = &#39;Volume&#39;, pch = 16, col =&#39;blue&#39;)</code></pre>
<p><img src="LECTURE1_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<pre class="r"><code>plot(trees$Volume~trees$Girth, main = &#39;Black Cherry Tree Girth/Volume Relationship&#39;, xlab = &#39;Girth&#39;, ylab = &#39;Volume&#39;, pch = 16, col =&#39;red&#39;)</code></pre>
<p><img src="LECTURE1_files/figure-html/unnamed-chunk-15-2.png" width="672" /></p>
<p>Let’s write a simple function that generates coefficients of determination given a response and some predictor variables:</p>
<pre class="r"><code>#########
# Function for returning a vector of R-squared statistics from models regressing a response variable on multiple possible predictor variables
   # here we assume that all columns in the input data frame that are NOT the response variable are potential predictor variables.

Rsquared &lt;- function(df,responsevar=&quot;Volume&quot;){    # univariate models only- interaction and multiple regression not implemented here
  response &lt;- df[,responsevar]       # extract the response variable
  names &lt;- names(df)                  
  rsq &lt;- numeric(length(names))        # named storage vector
  names(rsq) &lt;- names(df)               
  rsq &lt;- rsq[names(rsq)!=responsevar]           # assume that all columns that are not the response variable are possible predictor variables
  for(i in names(rsq)){         # loop through predictors
      predictor &lt;- df[,i]                  # extract this predictor
      model &lt;- lm(response~predictor)       # regress response on predictor
      rsq[i] &lt;- summary(model)$r.square       # extract R-squared statistic
  }
  return(rsq)     
}</code></pre>
<p>Let’s first compute the <span class="math inline">\(R^2\)</span> values for all predictor variables:</p>
<pre class="r"><code>#########
# test the function to see if it works!

stat &lt;- Rsquared(trees,&quot;Volume&quot;)
stat</code></pre>
<pre><code>##     Girth    Height 
## 0.9353199 0.3579026</code></pre>
<p>Now we can use a “bootstrapping” procedure to generate a confidence interval around these values, to see how certain we can be about the strength of the linear relationship between the response and the predictor variable in general (the population-level <em>parameter</em>) on the basis of the computed R-squared value (a sample <em>statistic</em>)</p>
<p>Let’s first write a function to generate bootstrap samples from a data set:</p>
<pre class="r"><code>############
# new function to generate &quot;bootstrap&quot; samples from a data frame

boot_sample &lt;- function(df,statfunc,n_samples,responsevar=&quot;Volume&quot;){
  indices &lt;- c(1:nrow(df))
  output &lt;- matrix(NA,nrow=n_samples,ncol=ncol(df)-1)        # storage object- to store a single bootstrapped sample from the original data
  
  for(i in 1:n_samples){              # for each bootstrap replicate:
    boot_rows &lt;- sample(indices,size=nrow(df),replace=T)         # randomly sample observations with replacement
    newdf &lt;- df[boot_rows,]                       # dataframe of bootstrapped observations
    output[i,] &lt;- statfunc(newdf,responsevar)                 # generate statistics from the bootstrapped sample  (e.g., compute Rsquared after regressing y on all possible x variables)
  }
  return(output)
}</code></pre>
<p>Now we can generate a bunch of “bootstrapped” statistics to compare with the ones we calculated from the full dataset. Here, the values represent R-squared values from alternative bootstrapped samples. Each row is a different bootstrapped sample, and each column is a different predictor variable.</p>
<pre class="r"><code>##########
# Generate a few bootstrapped samples!

boot &lt;- boot_sample(df=trees,statfunc=Rsquared,n_samples=10)       # generate test stats from lots of bootstrapped samples
colnames(boot) &lt;- names(stat)         # name the columns to recall which predictor variables they represent

boot</code></pre>
<pre><code>##           Girth    Height
##  [1,] 0.9345337 0.4824502
##  [2,] 0.9619766 0.3435997
##  [3,] 0.9637383 0.4007081
##  [4,] 0.8877564 0.1460413
##  [5,] 0.9539420 0.4487442
##  [6,] 0.9596950 0.7094706
##  [7,] 0.9489429 0.5030619
##  [8,] 0.9429827 0.2253760
##  [9,] 0.9553592 0.4583997
## [10,] 0.9373360 0.2369296</code></pre>
<pre class="r"><code>stat</code></pre>
<pre><code>##     Girth    Height 
## 0.9353199 0.3579026</code></pre>
<p>Finally, we can use the quantiles of the bootstrap samples to generate bootstrap confidence intervals.</p>
<pre class="r"><code>#############
# use bootstrapping to generate confidence intervals for R-squared statistic!

boot &lt;- boot_sample(df=trees,statfunc=Rsquared,n_samples=1000)   # generate test statistics (Rsquared vals) for 1000 bootstrap samples
confint &lt;- apply(boot,2,function(t)  quantile(t,c(0.025,0.5,0.975)))       # summarize the quantiles to generate confidence intervals for each predictor variable
colnames(confint) &lt;- names(stat)
t(confint)</code></pre>
<pre><code>##             2.5%       50%     97.5%
## Girth  0.8936286 0.9381547 0.9621611
## Height 0.1474844 0.3588833 0.6007489</code></pre>
<p>Again, don’t feel bad if you don’t understand all the code yet. At this point, I just want you to understand the value of being able to program your own data analysis algorithms.</p>
<ul>
<li>It allows you to run custom analyses that you can’t run any other way.<br />
</li>
<li>It allows you to ‘relax’ assumptions that standard analyses may make<br />
</li>
<li>It allows you to formalize your understanding of how your data were generated, and use this understanding to make the most of your data<br />
</li>
<li>It’s fun!</li>
</ul>
<p><a href="LECTURE2.html">–go to next lecture–</a></p>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
