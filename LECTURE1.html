<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="NRES 746" />

<meta name="date" content="2016-08-23" />

<title>Why focus on algorithms?</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cerulean.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="site_libs/highlight/default.css"
      type="text/css" />
<script src="site_libs/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.9em;
  padding-left: 5px;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">NRES 746</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Schedule
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="schedule.html">Course Schedule</a>
    </li>
    <li>
      <a href="labschedule.html">Lab Schedule</a>
    </li>
    <li>
      <a href="Syllabus.pdf">Syllabus</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Lectures
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="INTRO.html">Introduction to NRES 746</a>
    </li>
    <li>
      <a href="LECTURE1.html">Why focus on algorithms?</a>
    </li>
    <li>
      <a href="LECTURE2.html">Working with probabilities</a>
    </li>
    <li>
      <a href="LECTURE3.html">The Virtual Ecologist</a>
    </li>
    <li>
      <a href="LECTURE4.html">Likelihood</a>
    </li>
    <li>
      <a href="LECTURE5.html">Optimization</a>
    </li>
    <li>
      <a href="LECTURE6.html">Bayesian #1: concepts</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Lab exercises
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="LAB1.html">Lab 1: Algorithms in R</a>
    </li>
    <li>
      <a href="LAB2.html">Lab 2: Virtual ecologist</a>
    </li>
    <li>
      <a href="LAB3.html">Lab 3: Likelihood and optimization</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Data sets
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="TreeData.csv">Tree Data</a>
    </li>
    <li>
      <a href="ReedfrogPred.csv">Reed Frog Predation Data</a>
    </li>
    <li>
      <a href="ReedfrogFuncresp.csv">Reed Frog Func Resp</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Student-led topics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="TreeData.csv">GAMs</a>
    </li>
  </ul>
</li>
<li>
  <a href="Links.html">Links</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Why focus on algorithms?</h1>
<h4 class="author"><em>NRES 746</em></h4>
<h4 class="date"><em>August 23, 2016</em></h4>

</div>


<div id="algorithmic-vs-standard-statistics-a-brief-demonstration" class="section level2">
<h2>Algorithmic vs standard statistics: a brief demonstration</h2>
<div id="standard-t-test" class="section level3">
<h3>Standard t-test</h3>
<p>First, let’s go through a very basic review.</p>
<p>Here is a made-up data set. Let’s imagine we are interested in seeing if the average mass of study organisms in Group A are different from those in Group B.</p>
<pre class="r"><code>df &lt;- data.frame(
  GroupA = c(175, 168, 168, 190, 156, 181, 182, 175, 174, 179),
  GroupB = c(185, 169, 173, 173, 188, 186, 175, 174, 179, 180) 
)

summary(df)</code></pre>
<pre><code>##      GroupA          GroupB     
##  Min.   :156.0   Min.   :169.0  
##  1st Qu.:169.5   1st Qu.:173.2  
##  Median :175.0   Median :177.0  
##  Mean   :174.8   Mean   :178.2  
##  3rd Qu.:180.5   3rd Qu.:183.8  
##  Max.   :190.0   Max.   :188.0</code></pre>
<pre class="r"><code>sample.size &lt;- length(df$GroupA)
reshape_df &lt;- data.frame(
  Group = rep(c(&quot;A&quot;,&quot;B&quot;),each=sample.size),
  Mass = c(df$GroupA,df$GroupB)
)
plot(Mass~Group, data=reshape_df)</code></pre>
<p><img src="LECTURE1_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code># boxplot(df$GroupA,df$GroupB,names=c(&quot;GroupA&quot;,&quot;GroupB&quot;))  # (alternative method!)

observed_dif &lt;- mean(df$GroupA) - mean(df$GroupB)
observed_dif</code></pre>
<pre><code>## [1] -3.4</code></pre>
<p>You probably recognize the standard t-test below. For now, we are assuming that the samples come from normally distributed populations with equal variances.</p>
<pre class="r"><code>t.test(df$GroupA,df$GroupB, var.equal=TRUE, paired=FALSE)</code></pre>
<pre><code>## 
##  Two Sample t-test
## 
## data:  df$GroupA and df$GroupB
## t = -0.94737, df = 18, p-value = 0.356
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -10.93994   4.13994
## sample estimates:
## mean of x mean of y 
##     174.8     178.2</code></pre>
</div>
<div id="brute-force-t-test" class="section level3">
<h3>Brute-force t-test</h3>
<p>But let’s imagine now that we didn’t know about the t-test- but we still want to accomplish the same goal.</p>
<p>First, let’s review the question and state the problem clearly:</p>
<p>We want to know if these two populations are different- specifically if the expected value (mean) differs. We have small random (but representative) samples from these two putative populations.</p>
<p>Can we build an <strong>algorithm</strong> to generate a p-value?</p>
<p>Let’s start by simulating a data population under the null hypothesis.</p>
<pre class="r"><code>lots &lt;- 1000000  # large number approximating infinity in this example!

popMean_null &lt;- mean(reshape_df$Mass)        # assume groups A and B come from a population with common mean 
popSD_null &lt;- sd(reshape_df$Mass)
popData_null &lt;- rnorm(n=lots,mean=popMean_null,sd=popSD_null)    # the statistical &quot;population&quot; of interest (under null model)</code></pre>
<p>Then we can sample from that data population:</p>
<pre class="r"><code>sampleA &lt;- sample(popData_null,size=sample.size)   
sampleB &lt;- sample(popData_null,size=sample.size)

round(sampleA)</code></pre>
<pre><code>##  [1] 172 174 177 173 177 168 188 178 189 182</code></pre>
<pre class="r"><code>difference &lt;- mean(sampleA)-mean(sampleB)   # difference between sample means
difference</code></pre>
<pre><code>## [1] -0.4854199</code></pre>
<p>Then we can generate a distribution of “anomalies” (differences between the group means) expected under the null hypothesis (there is fundamentally no difference between the two groups):</p>
<pre class="r"><code>reps &lt;- 1000
null_difs &lt;- numeric(reps)

for(i in 1:reps){
  sampleA &lt;- sample(popData_null,size=sample.size)   
  sampleB &lt;- sample(popData_null,size=sample.size)
  null_difs[i] &lt;- mean(sampleA)-mean(sampleB)
}

hist(null_difs)
abline(v=observed_dif,col=&quot;green&quot;,lwd=3)</code></pre>
<p><img src="LECTURE1_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Now, all we need to do is compare this more quantitatively with the observed among-group difference…</p>
<pre class="r"><code>  ordered_difs &lt;- sort(abs(null_difs))   
  higher_anomaly &lt;- length(which(ordered_difs&gt;=abs(observed_dif)))
  p_value &lt;- higher_anomaly/reps  
  p_value</code></pre>
<pre><code>## [1] 0.359</code></pre>
<div id="exercise" class="section level4">
<h4>Exercise</h4>
<p>Repeat the same exercise, but using a different underlying distribution- say, the binomial or the Poisson. Compare with a standard t-test. Which test do you trust more?</p>
</div>
<div id="exercise-1" class="section level4">
<h4>Exercise</h4>
<p>Modify the above algorithm to allow for unequal sample sizes. Compare with a standard t-test. Can you identify any cases where the t-test results differ substantially from your algorithmic results?</p>
</div>
<div id="exercise-2" class="section level4">
<h4>Exercise</h4>
<p>Now, what about if we wanted to relax the assumption of equal variances? How would you modify the above algorithm to do this?</p>
</div>
<div id="take-home-message" class="section level4">
<h4>Take-home message</h4>
<p>The value of the algorithmic, brute-force approach to statistics is the flexibility! We have to be aware of assumptions in all of our analyses, but when we build our own computational algorithms, we can readily relax these assumptions.</p>
</div>
</div>
<div id="a-non-parametric-alternative-permutation-test-algorithm" class="section level3">
<h3>A non-parametric alternative: permutation test algorithm</h3>
<p>What if we don’t want to make any assumptions about the process that generated the data. The normal distribution can arise in many different ways, but many data-generating processes <strong>don’t</strong> result in a normal distribution!</p>
<p>We might be able to intuit which of the many alternative distributions makes the most sense for our data. But many times we can’t do this with any level of certainty. What can we do in this case? A permutation test provides one answer.</p>
<p>Let’s build this algorithm together.</p>
<p>Here is some pseudocode:</p>
<ol style="list-style-type: decimal">
<li>Define the number of permutations to run</li>
<li>Start loop through permutations
<ol style="list-style-type: decimal">
<li>randomize the data indices with respect to group</li>
<li>compute the difference between the group means after randomizing the data indices</li>
<li>store this value for later analysis</li>
</ol></li>
<li>Plot a histogram of differences between group A and group B under the null hypothesis</li>
<li>Add a vertical line to indicate the observed difference</li>
</ol>
<p><img src="LECTURE1_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>Now we can compute a p-value, just as we did before:</p>
<pre class="r"><code>higher_anomaly &lt;- length(which(abs(null_difs)&gt;=abs(observed_dif)))
p_value &lt;- higher_anomaly/reps  
p_value</code></pre>
<pre><code>## [1] 0.3712</code></pre>
</div>
</div>
<div id="bootstrapping-a-confidence-interval" class="section level2">
<h2>Bootstrapping a confidence interval</h2>
<p>(NOTE: some materials borrowed from <a href="http://people.tamu.edu/~alawing/materials/ESSM689/Btutorial.pdf">link</a>)</p>
<p>Let’s imagine we want to compare different predictor variables in terms of how strong the relationship is with a response variable. In this case, we will use the coefficient of determination (<span class="math inline">\(R^2\)</span>) as a measure of how good a predictor is. However, we want to be able to say that one predictor is definatively <em>better</em> than another one – for that, we would like a confidence interval around the <span class="math inline">\(R^2\)</span> value.</p>
<p>Let’s use the “trees” dataset provided in base R:</p>
<pre class="r"><code>head(trees)   # use help(trees) for more information</code></pre>
<pre><code>##   Girth Height Volume
## 1   8.3     70   10.3
## 2   8.6     65   10.3
## 3   8.8     63   10.2
## 4  10.5     72   16.4
## 5  10.7     81   18.8
## 6  10.8     83   19.7</code></pre>
<p>Let’s say that tree volume is our response variable. We want to see if girth or height are better predictors of volume.</p>
<p>Let’s first do some basic data explorations:</p>
<pre class="r"><code>plot(trees$Volume~trees$Height, main = &#39;Black Cherry Tree Height/Volume Relationship&#39;, xlab = &#39;Height&#39;, ylab = &#39;Volume&#39;, pch = 16, col =&#39;blue&#39;)</code></pre>
<p><img src="LECTURE1_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<pre class="r"><code>plot(trees$Volume~trees$Girth, main = &#39;Black Cherry Tree Girth/Volume Relationship&#39;, xlab = &#39;Girth&#39;, ylab = &#39;Volume&#39;, pch = 16, col =&#39;red&#39;)</code></pre>
<p><img src="LECTURE1_files/figure-html/unnamed-chunk-11-2.png" width="672" /></p>
<p>Let’s write a simple function that generates coefficients of determination given a response and some predictor variables:</p>
<pre class="r"><code>Rsquared &lt;- function(df,responsevar=&quot;Volume&quot;){    # interactions not yet implemented
  response &lt;- df[,responsevar]
  names &lt;- names(df)
  rsq &lt;- numeric(length(names))
  names(rsq) &lt;- names(df)
  rsq &lt;- rsq[names(rsq)!=responsevar]
  for(i in names(rsq)){         # loop through predictors
      predictor &lt;- df[,i]
      model &lt;- lm(response~predictor)  
      rsq[i] &lt;- summary(model)$r.square 
  }
  return(rsq)
}</code></pre>
<p>Let’s first compute the <span class="math inline">\(R^2\)</span> values for all predictor variables:</p>
<pre class="r"><code>stat &lt;- Rsquared(trees,&quot;Volume&quot;)
stat</code></pre>
<pre><code>##     Girth    Height 
## 0.9353199 0.3579026</code></pre>
<p>Now we can use “bootstrapping” to generate a confidence interval around these values…</p>
<p>Let’s first write a function to generate bootstrap samples from a dataset:</p>
<pre class="r"><code>boot_sample &lt;- function(df,statfunc,n_samples,n_stats){
  indices &lt;- c(1:nrow(df))
  output &lt;- matrix(NA,nrow=n_samples,ncol=n_stats)
  for(i in 1:n_samples){
    boot_rows &lt;- sample(indices,size=nrow(df),replace=T)
    newdf &lt;- df[boot_rows,]
    output[i,] &lt;- statfunc(newdf)
  }
  return(output)
}</code></pre>
<p>Now we can generate a bunch of “bootstrapped” statistics to compare with the ones calculated from the full dataset:</p>
<pre class="r"><code>boot &lt;- boot_sample(trees,Rsquared,10,length(stat))
colnames(boot) &lt;- names(stat)

boot</code></pre>
<pre><code>##           Girth    Height
##  [1,] 0.8982448 0.1268197
##  [2,] 0.9411940 0.1948557
##  [3,] 0.9626162 0.4536803
##  [4,] 0.9418259 0.1782504
##  [5,] 0.9403119 0.2636274
##  [6,] 0.9356647 0.2852744
##  [7,] 0.9488029 0.4193189
##  [8,] 0.9153685 0.2041185
##  [9,] 0.9495487 0.5597667
## [10,] 0.9416790 0.3751805</code></pre>
<pre class="r"><code>stat</code></pre>
<pre><code>##     Girth    Height 
## 0.9353199 0.3579026</code></pre>
<p>Finally, we can use the quantiles of the bootstrap samples to generate bootstrap confidence intervals.</p>
<pre class="r"><code>boot &lt;- boot_sample(trees,Rsquared,1000,length(stat))   # 1000 bootstrap samples
confint &lt;- apply(boot,2,function(t)  quantile(t,c(0.025,0.5,0.975)))
colnames(confint) &lt;- names(stat)
t(confint)</code></pre>
<pre><code>##             2.5%       50%     97.5%
## Girth  0.8935929 0.9380778 0.9621877
## Height 0.1386167 0.3604225 0.5730800</code></pre>
<pre class="r"><code>quantile(boot,c(0.025,0.975))</code></pre>
<pre><code>##      2.5%     97.5% 
## 0.1761482 0.9587434</code></pre>
<div id="exercise-intermediate" class="section level4">
<h4>Exercise (intermediate):</h4>
<p>Generate bootstrap confidence intervals around the regression parameters. Compare with the standard confidence intervals given by R in the “lm” package.</p>
</div>
<div id="exercise-advanced" class="section level4">
<h4>Exercise (advanced):</h4>
<p>Modify the algorithm above to select the top model from among all possible models (including interaction terms)</p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
