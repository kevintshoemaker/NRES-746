<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Corey Mitchell &amp; Lauren Phillips" />


<title>Species Distribution Modeling</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cerulean.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">NRES 746</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Schedule
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="schedule.html">Course Schedule</a>
    </li>
    <li>
      <a href="Syllabus.pdf">Syllabus</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Lectures
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="INTRO.html">Introduction to NRES 746</a>
    </li>
    <li>
      <a href="LECTURE1.html">Why focus on algorithms?</a>
    </li>
    <li>
      <a href="LECTURE2.html">Working with probabilities</a>
    </li>
    <li>
      <a href="LECTURE3.html">The Virtual Ecologist</a>
    </li>
    <li>
      <a href="LECTURE4.html">Likelihood</a>
    </li>
    <li>
      <a href="LECTURE5.html">Optimization</a>
    </li>
    <li>
      <a href="LECTURE6.html">Bayesian #1: concepts</a>
    </li>
    <li>
      <a href="LECTURE7.html">Bayesian #2: mcmc</a>
    </li>
    <li>
      <a href="LECTURE8.html">Model Selection</a>
    </li>
    <li>
      <a href="LECTURE9.html">Performance Evaluation</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Lab exercises
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="LAB_Instructions.html">Instructions for Labs</a>
    </li>
    <li>
      <a href="FINALPROJ.html">Final project overview</a>
    </li>
    <li>
      <a href="LAB1.html">Lab 1: Algorithms in R</a>
    </li>
    <li>
      <a href="LAB2.html">Lab 2: Virtual ecologist</a>
    </li>
    <li>
      <a href="LAB3.html">Lab 3: Likelihood</a>
    </li>
    <li>
      <a href="LAB4.html">Lab 4: Bayesian inference</a>
    </li>
    <li>
      <a href="LAB5.html">Lab 5: Model selection (optional)</a>
    </li>
    <li>
      <a href="FigureDemo.html">Demo: Figures in R</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Student-led topics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="SDM_NRESpres_v6.html">Species distribution models</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Data sets
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="TreeData.csv">Tree Data</a>
    </li>
    <li>
      <a href="ReedfrogPred.csv">Reed Frog Predation Data</a>
    </li>
    <li>
      <a href="ReedfrogFuncresp.csv">Reed Frog Func Resp</a>
    </li>
  </ul>
</li>
<li>
  <a href="Links.html">Links</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Species Distribution Modeling</h1>
<h4 class="author">Corey Mitchell &amp; Lauren Phillips</h4>
<h4 class="date">11/4/19</h4>

</div>


<p><strong>NOTE:</strong> for those wishing to follow along with the R-based demo in class, <a href="SDM_v5.R">click here</a> for an R-script that contains all of the code blocks in this lecture.</p>
<div id="what-is-it" class="section level1">
<h1>What is it?</h1>
<div id="also-known-as" class="section level3">
<h3>Also known as:</h3>
<ul>
<li>Habitat Suitability Modeling<br />
</li>
<li>Climate Envelope Modeling<br />
</li>
<li>Niche Modeling (although not correct…(Kearney 2006))</li>
</ul>
</div>
<div id="spatial-models" class="section level3">
<h3>Spatial models</h3>
<ul>
<li>Correlative (SDM) vs. mechanistic (niche)</li>
<li>Use species occurrences and environmental variables with a chosen algorithm to produce a map of potential habitat suitability and/or species distributions</li>
</ul>
</div>
<div id="three-components-franklin-2009" class="section level3">
<h3>Three components: (Franklin 2009)</h3>
<pre><code>1. Ecological Model - theory connecting species with landscape  
2. Data Model - how data are collected, measured, cleaned  
3. Statistical model - algorithm, calibration, validation, prediction  </code></pre>
</div>
<div id="what-is-it-for" class="section level2">
<h2>What is it for?</h2>
<ul>
<li><p>IDENTIFY YOUR PURPOSE FIRST - affects all three components</p></li>
<li>Predicting species invasions</li>
<li>Predicting presence on the landscape in current vs. future conditions</li>
<li>Identifying suitable habitat to conduct surveys for species of concern</li>
<li>Identifying conservation hotspots</li>
<li><p>Assessing impacts of land use change for development or protection</p></li>
</ul>
</div>
<div id="when-to-use" class="section level2">
<h2>When to use?</h2>
<ul>
<li>When you have spatially referenced:
<ul>
<li>Presence/detection data<br />
</li>
<li>Presence/detection + absence/nondetection data</li>
</ul></li>
</ul>
</div>
<div id="preprocessing" class="section level2">
<h2>Preprocessing</h2>
<div id="this-is-time-consuming" class="section level3">
<h3>This is time consuming!</h3>
<ul>
<li>Data acquisition
<ul>
<li>Opensource: eBird, Herpnet</li>
<li>Museum Records, Longterm monitoring data, and collaboration!</li>
</ul></li>
<li>Sampling design</li>
<li>Sampling bias (likely)</li>
<li>Extent delineation
<ul>
<li>points + buffer</li>
</ul></li>
<li>Environmental variable acquisition</li>
</ul>
<hr />
</div>
</div>
<div id="conceptual-model-example" class="section level2">
<h2>Conceptual Model Example</h2>
<hr />
</div>
<div id="workflow-example" class="section level2">
<h2>Workflow Example</h2>
<p><img src="workflow_swfl.png" width="100%" /></p>
<hr />
</div>
<div id="data-cleaning-and-preparation" class="section level2">
<h2>Data Cleaning and Preparation</h2>
<ul>
<li>Checking occurrences for inaccuracies
<ul>
<li>spatial irregularities common!</li>
</ul></li>
</ul>
</div>
<div id="environmental-variable-preparation" class="section level2">
<h2>Environmental Variable Preparation</h2>
<ul>
<li>Formatting
<ul>
<li>Same projection</li>
<li>Same extent</li>
<li>Resampling to same resolution</li>
</ul></li>
<li>CHECKING that the formatting doesn’t omit valuable information</li>
<li>Collinearity</li>
</ul>
</div>
<div id="data-cleaning-and-preparation-part-2" class="section level2">
<h2>Data Cleaning and Preparation Part 2</h2>
<ul>
<li>Pseudoabsence generation
<ul>
<li>how many? what strategy?</li>
</ul></li>
<li>Addressing spatial autocorrelation</li>
<li>Thinning occurrences if sampling uneven</li>
<li>Dividing dataset into training and testing</li>
</ul>
</div>
<div id="algorithms" class="section level2">
<h2>Algorithms</h2>
<ul>
<li>Selecting the best one for your dataset
<ul>
<li>Singular vs. ensemble</li>
<li>Presence-only vs. Presence/Absence</li>
</ul></li>
<li>Random Forest</li>
<li>GAM</li>
<li>ANN</li>
<li>GLM</li>
<li>SRE</li>
<li>GBM</li>
<li>MARS</li>
<li>GARP<br />
</li>
<li>MAXENT (an option, but not the only one.)</li>
</ul>
</div>
<div id="forecast-habitat-suitability" class="section level2">
<h2>Forecast Habitat Suitability</h2>
<ul>
<li>Generate prediction surface</li>
<li>Scale 0-1</li>
<li>You may choose to do this before or after looking at model performance metrics!</li>
</ul>
</div>
<div id="model-selectionevaluation" class="section level2">
<h2>Model Selection/Evaluation</h2>
<div id="performance-metrics" class="section level3">
<h3>Performance Metrics</h3>
<ul>
<li>Based on the testing dataset
<ul>
<li>Set aside in beginning</li>
<li>Threshold dependent vs. Independent</li>
</ul></li>
<li>AUC - ROC
<ul>
<li>Closer to 1 is “better”, .5 is random</li>
<li>.8 to 1 can be a red flag for overparameterization (Lobo et al 2008)</li>
</ul></li>
<li>TSS
<ul>
<li>False positive and true positive rates</li>
</ul></li>
<li>Accuracy
<ul>
<li>How often did it predict correctly?</li>
</ul></li>
<li>Others:
<ul>
<li>Kappa, F, Correlation Coeff, Precision, Prevalence, Odds Ratio</li>
<li>See Liu et al. 2011 for more information</li>
</ul></li>
</ul>
</div>
<div id="variable-importance" class="section level3">
<h3>Variable Importance</h3>
<ul>
<li>Assess contribution of each variable to model + Decide which to keep or drop + If some relationships shock you, may indicate a formatting issue</li>
<li>Response curves + Trends should make logical sense</li>
</ul>
</div>
</div>
<div id="iterative-process" class="section level2">
<h2>Iterative Process</h2>
<ul>
<li>Drop poorly performing algorithms</li>
<li>Drop poorly performing variables</li>
<li>Cry</li>
<li>Re-run</li>
<li>Re-assess</li>
<li>Rinse</li>
<li>Repeat</li>
</ul>
<hr />
</div>
<div id="lets-work-through-an-example" class="section level2">
<h2>Let’s work through an example!</h2>
<div id="species-common-chuckwalla-sauromalus-ater" class="section level3">
<h3>Species: Common Chuckwalla (<em>Sauromalus ater</em>)</h3>
<p>Code adapted from Dr. Ken Nussear’s Species Habitat Modeling Course (Geog 701M)</p>
<p><img src="Chuckwalla.jpg" width="75%" /></p>
<p>Source: <a href="http://www.ndow.org/Species/Reptiles/Chuckwalla/" class="uri">http://www.ndow.org/Species/Reptiles/Chuckwalla/</a></p>
<div id="first-install-the-necessary-packages-if-you-dont-already-have-them." class="section level5">
<h5>First install the necessary packages if you don’t already have them.</h5>
<pre class="r"><code>#install.packages(c(&quot;dismo&quot;,&quot;rgdal&quot;,&quot;raster&quot;,&quot;sp&quot;,&quot;ggmap&quot;,&quot;ggplot&quot;,&quot;mgcv&quot;,&quot;nlme&quot;,&quot;biomod2&quot;,&quot;gstat&quot;))</code></pre>
</div>
<div id="obtain-data-from-global-biodiversity-information-facility-can-directly-import-to-r-with-the-dismo-package" class="section level5">
<h5>Obtain data from Global Biodiversity Information Facility, can directly import to r with the dismo package!</h5>
<p>There was a species name change for chuckwalla at some point so we’ll import data for both ater and obesus.</p>
<pre class="r"><code>library(dismo)</code></pre>
<pre><code>## Loading required package: raster</code></pre>
<pre><code>## Loading required package: sp</code></pre>
<pre class="r"><code>chuck1 &lt;-  gbif(genus = &quot;Sauromalus&quot;, species = &#39;obesus&#39;, geo=T)</code></pre>
<pre><code>## Loading required namespace: jsonlite</code></pre>
<pre><code>## 1439 records found</code></pre>
<pre><code>## 0-300-600-900-1200-1439 records downloaded</code></pre>
<pre class="r"><code>chuck2 &lt;-  gbif(genus = &quot;Sauromalus&quot;, species = &#39;ater&#39;, geo=T)</code></pre>
<pre><code>## 5433 records found
## 0-300-600-900-1200-1500-1800-2100-2400-2700-3000-3300-3600-3900-4200-4500-4800-5100-5400-5433 records downloaded</code></pre>
</div>
<div id="the-number-of-columns-differ-need-to-identify-which-columns-to-keep-so-we-can-combine-the-data." class="section level5">
<h5>The number of columns differ, need to identify which columns to keep so we can combine the data.</h5>
<pre class="r"><code>dim(chuck1)</code></pre>
<pre><code>## [1] 1439  131</code></pre>
<pre class="r"><code>dim(chuck2)</code></pre>
<pre><code>## [1] 5433  159</code></pre>
<pre class="r"><code>keepcols &lt;- c(&#39;genus&#39;,&#39;specificEpithet&#39;,&#39;eventDate&#39;,&#39;lon&#39;,&#39;lat&#39;,&#39;elevation&#39;,&#39;geodeticDatum&#39;)
keepcols %in% names(chuck1)</code></pre>
<pre><code>## [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE</code></pre>
<pre class="r"><code>keepcols %in% names(chuck2)</code></pre>
<pre><code>## [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE</code></pre>
<pre class="r"><code>allchck &lt;- rbind(chuck1[,c(keepcols)], chuck2[,keepcols])

## Check out the data and remove any duplicates
chuckNoDup &lt;- allchck[!duplicated(allchck),]</code></pre>
</div>
<div id="plot-the-data-to-look-for-erroneous-points." class="section level5">
<h5>Plot the data to look for erroneous points.</h5>
<pre class="r"><code>plot(chuckNoDup$lon, chuckNoDup$lat)</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
</div>
<div id="remove-points-that-dont-look-correct." class="section level5">
<h5>Remove points that don’t look correct.</h5>
<pre class="r"><code>chuckNoDup &lt;- chuckNoDup[chuckNoDup$lon &lt; -105,]
plot(chuckNoDup$lon, chuckNoDup$lat)</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre class="r"><code>chuck.sp &lt;- chuckNoDup
summary(chuck.sp$lat)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   24.05   33.28   33.87   33.59   35.26   39.01     623</code></pre>
<pre class="r"><code>summary(chuck.sp$lon)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##  -120.8  -116.4  -115.9  -115.2  -114.4  -109.5     623</code></pre>
</div>
<div id="remove-the-nas" class="section level5">
<h5>Remove the NA’s</h5>
<pre class="r"><code>chuck.sp &lt;- chuck.sp[!is.na(chuck.sp$lon),]</code></pre>
</div>
<div id="make-it-into-a-spatial-points-data-frame-by-assigning-coordinates-and-a-projection." class="section level5">
<h5>Make it into a spatial points data frame by assigning coordinates and a projection.</h5>
<pre class="r"><code>coordinates(chuck.sp) &lt;- c(&#39;lon&#39;,&#39;lat&#39;)
proj4string(chuck.sp) &lt;- CRS(&#39;+proj=longlat + datum=WGS84&#39;)
plot(chuck.sp)</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
</div>
<div id="plot-data-over-a-basemap-to-check-for-other-problems." class="section level5">
<h5>Plot data over a basemap to check for other problems.</h5>
<pre class="r"><code>library(rgdal)</code></pre>
<pre><code>## rgdal: version: 1.4-4, (SVN revision 833)
##  Geospatial Data Abstraction Library extensions to R successfully loaded
##  Loaded GDAL runtime: GDAL 2.2.3, released 2017/11/20
##  Path to GDAL shared files: C:/Users/kshoemaker/Documents/R/win-library/3.6/rgdal/gdal
##  GDAL binary built with GEOS: TRUE 
##  Loaded PROJ.4 runtime: Rel. 4.9.3, 15 August 2016, [PJ_VERSION: 493]
##  Path to PROJ.4 shared files: C:/Users/kshoemaker/Documents/R/win-library/3.6/rgdal/proj
##  Linking to sp version: 1.3-1</code></pre>
<pre class="r"><code>library(sp)
e = extent(chuck.sp)
e</code></pre>
<pre><code>## class      : Extent 
## xmin       : -120.7708 
## xmax       : -109.4604 
## ymin       : 24.05 
## ymax       : 39.00934</code></pre>
<pre class="r"><code>buf = .5
chuck.df&lt;- as.data.frame(chuck.sp)

library(ggmap)</code></pre>
<pre><code>## Loading required package: ggplot2</code></pre>
<pre><code>## Google&#39;s Terms of Service: https://cloud.google.com/maps-platform/terms/.</code></pre>
<pre><code>## Please cite ggmap if you use it! See citation(&quot;ggmap&quot;) for details.</code></pre>
<pre><code>## 
## Attaching package: &#39;ggmap&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dismo&#39;:
## 
##     geocode</code></pre>
<pre class="r"><code>myMap &lt;- get_stamenmap(bbox = c(left = e[1]-buf,
                                bottom = e[3] -buf,
                                right = e[2]+buf,
                                top = e[4] +buf),
                       maptype = &quot;terrain&quot;,
                       crop = FALSE,
                       zoom = 6)</code></pre>
<pre><code>## Source : http://tile.stamen.com/terrain/6/10/24.png</code></pre>
<pre><code>## Source : http://tile.stamen.com/terrain/6/11/24.png</code></pre>
<pre><code>## Source : http://tile.stamen.com/terrain/6/12/24.png</code></pre>
<pre><code>## Source : http://tile.stamen.com/terrain/6/10/25.png</code></pre>
<pre><code>## Source : http://tile.stamen.com/terrain/6/11/25.png</code></pre>
<pre><code>## Source : http://tile.stamen.com/terrain/6/12/25.png</code></pre>
<pre><code>## Source : http://tile.stamen.com/terrain/6/10/26.png</code></pre>
<pre><code>## Source : http://tile.stamen.com/terrain/6/11/26.png</code></pre>
<pre><code>## Source : http://tile.stamen.com/terrain/6/12/26.png</code></pre>
<pre><code>## Source : http://tile.stamen.com/terrain/6/10/27.png</code></pre>
<pre><code>## Source : http://tile.stamen.com/terrain/6/11/27.png</code></pre>
<pre><code>## Source : http://tile.stamen.com/terrain/6/12/27.png</code></pre>
<pre class="r"><code># plot map
ggmap(myMap) +  geom_point(aes(x = lon, y = lat), data = chuck.df, alpha = .5)</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
</div>
<div id="a-little-more-cleanup-is-needed.-remove-points-west-of-longitude--119" class="section level5">
<h5>A little more cleanup is needed. Remove points west of longitude -119</h5>
<pre class="r"><code>chuck.sp &lt;- chuck.sp[coordinates(chuck.sp)[,1] &gt; -119,]
chuck.df &lt;- as.data.frame(chuck.sp)
ggmap(myMap) +  geom_point(aes(x = lon, y = lat), data = chuck.df, alpha = .5)</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
</div>
<div id="now-lets-get-our-environmental-layers-in-order.-decide-which-variables-are-important-to-your-species-apriori.-do-not-just-use-all-20-bioclim-layers-and-see-which-stick." class="section level5">
<h5>Now let’s get our Environmental Layers in order. Decide which variables are important to your species “apriori”. Do NOT just use all 20 Bioclim layers and see which stick.</h5>
<pre class="r"><code>library(raster)
library(sp)

blk.dens &lt;- raster(&quot;ofr20091102 Environmental Layers/BlkDensity.asc&quot;) # Bulk density (soil)
pct.cov &lt;-raster(&quot;ofr20091102 Environmental Layers/pctCov.asc&quot;) #% Shrub cover
pct.rock &lt;-raster(&quot;ofr20091102 Environmental Layers/pctRocks.asc&quot;) #% rocks
pct.rough &lt;-raster(&quot;ofr20091102 Environmental Layers/pctRuf.asc&quot;) #% roughness
slope &lt;-raster(&quot;ofr20091102 Environmental Layers/slope.asc&quot;) #slope
s.precip &lt;- raster(&quot;ofr20091102 Environmental Layers/sp30.asc&quot;) #summer precip
w.precip &lt;- raster(&quot;ofr20091102 Environmental Layers/wp30.asc&quot;) #winter precip</code></pre>
</div>
<div id="stack-your-environmental-variables.-they-must-be-at-the-same-extent-resolution-and-projection-to-stack.-this-may-require-significant-formatting-cropping-masking-spatial-transformation-resampling-etc." class="section level5">
<h5>Stack your environmental variables. They must be at the same extent, resolution, and projection to stack. This may require significant formatting (cropping, masking, spatial transformation, resampling, etc…).</h5>
<pre class="r"><code>env &lt;- stack(blk.dens, pct.cov, pct.rock, pct.rough, slope, s.precip, w.precip)</code></pre>
</div>
<div id="plot-your-environmental-variables-to-check-them-you-may-decide-to-drop-addtional-variable-prior-to-first-model." class="section level5">
<h5>Plot your Environmental Variables to check them! You may decide to drop addtional variable prior to first model.</h5>
<pre class="r"><code>par(mfrow=c(1,1))          
plot(env[[5]], main= &quot;Slope&quot;)</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-16-1.png" width="672" /><img src="SDM_v6_files/figure-html/unnamed-chunk-16-2.png" width="672" /></p>
</div>
<div id="now-we-mask-our-points-to-the-environmental-data-but-first-we-need-to-reproject-our-chuck-points-to-the-same-projection-as-the-environmental-data-because-they-are-different." class="section level5">
<h5>Now we mask our points to the environmental data! But first we need to reproject our chuck points to the same projection as the environmental data because they are different.</h5>
<pre class="r"><code>proj4string(chuck.sp)</code></pre>
<pre><code>## [1] &quot;+proj=longlat +ellps=WGS84&quot;</code></pre>
<pre class="r"><code>proj4string(env)</code></pre>
<pre><code>## [1] &quot;+proj=utm +zone=11 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0&quot;</code></pre>
<pre class="r"><code>chuck.sp.utm &lt;- spTransform(chuck.sp, CRS(proj4string(env)))
chuck.sp.utm$keep&lt;- extract(env[[&#39;pctRocks&#39;]], chuck.sp.utm)
summary(chuck.sp.utm$keep) </code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##  0.0000  0.0000  0.0000  0.9635  1.1400 26.2500     608</code></pre>
<pre class="r"><code>chuck.sp.utm &lt;- chuck.sp.utm[!is.na(chuck.sp.utm$keep),] ### remove the points outside of your env extent 
chuck.sp.utm$Chuckwalla = 1 # create a presence column
chuck.sp.utm &lt;- chuck.sp.utm[,&#39;Chuckwalla&#39;] # drop all other columns</code></pre>
</div>
<div id="plot-the-points-over-the-environmental-layers" class="section level4">
<h4>Plot the points over the environmental layers</h4>
<pre class="r"><code>plot(env[[&#39;pctRocks&#39;]], main = &quot;Percent Rocks&quot;)</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<pre class="r"><code>points(chuck.sp.utm, pch = 19)</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-18-2.png" width="672" /></p>
<div id="the-algorithms-we-are-interested-in-fitting-do-not-work-with-presence-only-data.-because-we-do-not-have-absence-data-we-need-to-generate-pseudoabsences.-luckily-you-can-use-biomod2-to-generate-them." class="section level5">
<h5>The algorithms we are interested in fitting do not work with presence-only data. Because we do not have “absence” data, we need to generate pseudoabsences. Luckily, you can use biomod2 to generate them.</h5>
<pre class="r"><code>library(biomod2)</code></pre>
<pre><code>## Loading required package: parallel</code></pre>
<pre><code>## Loading required package: reshape</code></pre>
<pre><code>## biomod2 3.3-7.1 loaded.
## 
## Type browseVignettes(package=&#39;biomod2&#39;) to access directly biomod2 vignettes.</code></pre>
<pre><code>## 
## Attaching package: &#39;biomod2&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dismo&#39;:
## 
##     evaluate</code></pre>
<pre class="r"><code>set.seed(24)

chuck.sp.utm.pa &lt;- BIOMOD_FormatingData(resp.var = chuck.sp.utm$Chuckwalla,
                     expl.var = env,
                     resp.xy = coordinates(chuck.sp.utm),
                     resp.name = &#39;Chuckwalla&#39;,
                     #eval.resp.var = chuck.sp.utm.ex.tst$Chuckwalla,
                     #eval.expl.var = env,
                     #eval.resp.xy = coordinates(chuck.sp.utm.ex.tst),
                     PA.nb.rep = 1,
                     PA.nb.absences = dim(chuck.sp.utm)[1],
                     PA.strategy = &#39;sre&#39;,
                     PA.dist.min = NULL, # for &#39;disk&#39; strategy
                     PA.dist.max = NULL, # for &#39;disk&#39; strategy
                     PA.sre.quant = 0.1,
                     PA.table = NULL,
                     na.rm = TRUE)</code></pre>
<pre><code>## 
## -=-=-=-=-=-=-=-=-=-=-=-= Chuckwalla Data Formating -=-=-=-=-=-=-=-=-=-=-=-=
## 
##       ! No data has been set aside for modeling evaluation
##    &gt; Pseudo Absences Selection checkings...
##    &gt; SRE pseudo absences selection
## -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= Done -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=</code></pre>
<pre class="r"><code> chuck.sp.utm.pa</code></pre>
<pre><code>## 
## -=-=-=-=-=-=-=-=-=-=-=-= &#39;BIOMOD.formated.data.PA&#39; -=-=-=-=-=-=-=-=-=-=-=-=
## 
## sp.name =  Chuckwalla
## 
##   1878 presences,  0 true absences and  1878 undifined points in dataset
## 
## 
##   7 explanatory variables
## 
##    BlkDensity        pctCov          pctRocks          pctRuf      
##  Min.   :0.000   Min.   : 22.61   Min.   : 0.000   Min.   :0.0000  
##  1st Qu.:1.390   1st Qu.:108.29   1st Qu.: 0.000   1st Qu.:0.0000  
##  Median :1.490   Median :115.62   Median : 0.000   Median :0.0000  
##  Mean   :1.453   Mean   :118.81   Mean   : 1.229   Mean   :0.1072  
##  3rd Qu.:1.600   3rd Qu.:125.37   3rd Qu.: 1.140   3rd Qu.:0.1166  
##  Max.   :1.680   Max.   :197.07   Max.   :26.250   Max.   :1.0000  
##      slope             sp30             wp30       
##  Min.   : 0.000   Min.   :  0.00   Min.   :  0.00  
##  1st Qu.: 1.692   1st Qu.: 44.00   1st Qu.: 83.01  
##  Median : 5.555   Median : 64.00   Median :118.12  
##  Mean   :10.189   Mean   : 70.61   Mean   :129.93  
##  3rd Qu.:16.644   3rd Qu.: 92.00   3rd Qu.:163.78  
##  Max.   :59.053   Max.   :193.00   Max.   :600.39  
## 
## 
##  1 Pseudo Absences dataset available ( PA1 ) with  1878 
## absences in each (true abs + pseudo abs)
## 
## -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=</code></pre>
</div>
<div id="there-are-four-strategies-for-selecting-pas.-for-sre-surface-range-envelope-pas-are-selected-in-conditions-that-differ-from-a-defined-proportion-pa.sre.quant-of-the-presence-data.-it-forces-pas-to-be-selected-outside-of-the-broadly-defined-environemental-conditions-for-the-species." class="section level5">
<h5>There are four strategies for selecting PAs. For SRE (surface range envelope), PAs are selected in conditions that differ from a defined proportion (PA.sre.quant) of the presence data. It forces PAs to be selected outside of the broadly defined environemental conditions for the species.</h5>
</div>
<div id="check-headers-to-find-where-presences-and-pas-are-being-stored" class="section level5">
<h5>Check headers to find where presences and PAs are being stored</h5>
<pre class="r"><code>dim(chuck.sp.utm)</code></pre>
<pre><code>## [1] 1878    1</code></pre>
<pre class="r"><code>str(chuck.sp.utm.pa) </code></pre>
<pre><code>## Formal class &#39;BIOMOD.formated.data.PA&#39; [package &quot;biomod2&quot;] with 11 slots
##   ..@ PA.strategy      : chr &quot;sre&quot;
##   ..@ PA               :&#39;data.frame&#39;:    3756 obs. of  1 variable:
##   .. ..$ PA1: logi [1:3756] TRUE TRUE TRUE TRUE TRUE TRUE ...
##   ..@ sp.name          : chr &quot;Chuckwalla&quot;
##   ..@ coord            :&#39;data.frame&#39;:    3756 obs. of  2 variables:
##   .. ..$ lon: num [1:3756] 677087 659983 660994 659862 651912 ...
##   .. ..$ lat: num [1:3756] 4035356 4110658 4115077 4110662 4073863 ...
##   ..@ data.species     : num [1:3756] 1 1 1 1 1 1 1 1 1 1 ...
##   ..@ data.env.var     :&#39;data.frame&#39;:    3756 obs. of  7 variables:
##   .. ..$ BlkDensity: num [1:3756] 1.43 1.43 1.4 1.43 1.49 ...
##   .. ..$ pctCov    : num [1:3756] 117 116 116 116 124 ...
##   .. ..$ pctRocks  : num [1:3756] 0 1.5 1.5 1.5 0 1.5 1.5 0 0 1.5 ...
##   .. ..$ pctRuf    : num [1:3756] 0 0 0 0 0 ...
##   .. ..$ slope     : num [1:3756] 10.09 2.66 6.79 2.66 1.98 ...
##   .. ..$ sp30      : num [1:3756] 79 84 90 84 90 86 87 72 84 93 ...
##   .. ..$ wp30      : num [1:3756] 109 100 116 100 133 ...
##   ..@ data.mask        :Formal class &#39;RasterStack&#39; [package &quot;raster&quot;] with 11 slots
##   .. .. ..@ filename: chr &quot;&quot;
##   .. .. ..@ layers  :List of 2
##   .. .. .. ..$ :Formal class &#39;RasterLayer&#39; [package &quot;raster&quot;] with 12 slots
##   .. .. .. .. .. ..@ file    :Formal class &#39;.RasterFile&#39; [package &quot;raster&quot;] with 13 slots
##   .. .. .. .. .. .. .. ..@ name        : chr &quot;&quot;
##   .. .. .. .. .. .. .. ..@ datanotation: chr &quot;FLT4S&quot;
##   .. .. .. .. .. .. .. ..@ byteorder   : chr &quot;little&quot;
##   .. .. .. .. .. .. .. ..@ nodatavalue : num -Inf
##   .. .. .. .. .. .. .. ..@ NAchanged   : logi TRUE
##   .. .. .. .. .. .. .. ..@ nbands      : int 1
##   .. .. .. .. .. .. .. ..@ bandorder   : chr &quot;BIL&quot;
##   .. .. .. .. .. .. .. ..@ offset      : int 0
##   .. .. .. .. .. .. .. ..@ toptobottom : logi TRUE
##   .. .. .. .. .. .. .. ..@ blockrows   : int 0
##   .. .. .. .. .. .. .. ..@ blockcols   : int 0
##   .. .. .. .. .. .. .. ..@ driver      : chr &quot;&quot;
##   .. .. .. .. .. .. .. ..@ open        : logi FALSE
##   .. .. .. .. .. ..@ data    :Formal class &#39;.SingleLayerData&#39; [package &quot;raster&quot;] with 13 slots
##   .. .. .. .. .. .. .. ..@ values    : num [1:412614] NA NA NA NA NA NA NA NA NA NA ...
##   .. .. .. .. .. .. .. ..@ offset    : num 0
##   .. .. .. .. .. .. .. ..@ gain      : num 1
##   .. .. .. .. .. .. .. ..@ inmemory  : logi TRUE
##   .. .. .. .. .. .. .. ..@ fromdisk  : logi FALSE
##   .. .. .. .. .. .. .. ..@ isfactor  : logi FALSE
##   .. .. .. .. .. .. .. ..@ attributes: list()
##   .. .. .. .. .. .. .. ..@ haveminmax: logi TRUE
##   .. .. .. .. .. .. .. ..@ min       : num -1
##   .. .. .. .. .. .. .. ..@ max       : num 1
##   .. .. .. .. .. .. .. ..@ band      : int 1
##   .. .. .. .. .. .. .. ..@ unit      : chr &quot;&quot;
##   .. .. .. .. .. .. .. ..@ names     : chr &quot;input_data&quot;
##   .. .. .. .. .. ..@ legend  :Formal class &#39;.RasterLegend&#39; [package &quot;raster&quot;] with 5 slots
##   .. .. .. .. .. .. .. ..@ type      : chr(0) 
##   .. .. .. .. .. .. .. ..@ values    : logi(0) 
##   .. .. .. .. .. .. .. ..@ color     : logi(0) 
##   .. .. .. .. .. .. .. ..@ names     : logi(0) 
##   .. .. .. .. .. .. .. ..@ colortable: logi(0) 
##   .. .. .. .. .. ..@ title   : chr(0) 
##   .. .. .. .. .. ..@ extent  :Formal class &#39;Extent&#39; [package &quot;raster&quot;] with 4 slots
##   .. .. .. .. .. .. .. ..@ xmin: num 314026
##   .. .. .. .. .. .. .. ..@ xmax: num 879976
##   .. .. .. .. .. .. .. ..@ ymin: num 3594743
##   .. .. .. .. .. .. .. ..@ ymax: num 4323678
##   .. .. .. .. .. ..@ rotated : logi FALSE
##   .. .. .. .. .. ..@ rotation:Formal class &#39;.Rotation&#39; [package &quot;raster&quot;] with 2 slots
##   .. .. .. .. .. .. .. ..@ geotrans: num(0) 
##   .. .. .. .. .. .. .. ..@ transfun:function ()  
##   .. .. .. .. .. ..@ ncols   : int 566
##   .. .. .. .. .. ..@ nrows   : int 729
##   .. .. .. .. .. ..@ crs     :Formal class &#39;CRS&#39; [package &quot;sp&quot;] with 1 slot
##   .. .. .. .. .. .. .. ..@ projargs: chr &quot;+proj=utm +zone=11 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0&quot;
##   .. .. .. .. .. ..@ history : list()
##   .. .. .. .. .. ..@ z       : list()
##   .. .. .. ..$ :Formal class &#39;RasterLayer&#39; [package &quot;raster&quot;] with 12 slots
##   .. .. .. .. .. ..@ file    :Formal class &#39;.RasterFile&#39; [package &quot;raster&quot;] with 13 slots
##   .. .. .. .. .. .. .. ..@ name        : chr &quot;&quot;
##   .. .. .. .. .. .. .. ..@ datanotation: chr &quot;FLT4S&quot;
##   .. .. .. .. .. .. .. ..@ byteorder   : chr &quot;little&quot;
##   .. .. .. .. .. .. .. ..@ nodatavalue : num -Inf
##   .. .. .. .. .. .. .. ..@ NAchanged   : logi FALSE
##   .. .. .. .. .. .. .. ..@ nbands      : int 1
##   .. .. .. .. .. .. .. ..@ bandorder   : chr &quot;BIL&quot;
##   .. .. .. .. .. .. .. ..@ offset      : int 0
##   .. .. .. .. .. .. .. ..@ toptobottom : logi TRUE
##   .. .. .. .. .. .. .. ..@ blockrows   : int 1
##   .. .. .. .. .. .. .. ..@ blockcols   : int 566
##   .. .. .. .. .. .. .. ..@ driver      : chr &quot;&quot;
##   .. .. .. .. .. .. .. ..@ open        : logi FALSE
##   .. .. .. .. .. ..@ data    :Formal class &#39;.SingleLayerData&#39; [package &quot;raster&quot;] with 13 slots
##   .. .. .. .. .. .. .. ..@ values    : num [1:412614] NA NA NA NA NA NA NA NA NA NA ...
##   .. .. .. .. .. .. .. ..@ offset    : num 0
##   .. .. .. .. .. .. .. ..@ gain      : num 1
##   .. .. .. .. .. .. .. ..@ inmemory  : logi TRUE
##   .. .. .. .. .. .. .. ..@ fromdisk  : logi FALSE
##   .. .. .. .. .. .. .. ..@ isfactor  : logi FALSE
##   .. .. .. .. .. .. .. ..@ attributes: list()
##   .. .. .. .. .. .. .. ..@ haveminmax: logi TRUE
##   .. .. .. .. .. .. .. ..@ min       : num -1
##   .. .. .. .. .. .. .. ..@ max       : num 1
##   .. .. .. .. .. .. .. ..@ band      : int 1
##   .. .. .. .. .. .. .. ..@ unit      : chr &quot;&quot;
##   .. .. .. .. .. .. .. ..@ names     : chr &quot;PA1&quot;
##   .. .. .. .. .. ..@ legend  :Formal class &#39;.RasterLegend&#39; [package &quot;raster&quot;] with 5 slots
##   .. .. .. .. .. .. .. ..@ type      : chr(0) 
##   .. .. .. .. .. .. .. ..@ values    : logi(0) 
##   .. .. .. .. .. .. .. ..@ color     : logi(0) 
##   .. .. .. .. .. .. .. ..@ names     : logi(0) 
##   .. .. .. .. .. .. .. ..@ colortable: logi(0) 
##   .. .. .. .. .. ..@ title   : chr(0) 
##   .. .. .. .. .. ..@ extent  :Formal class &#39;Extent&#39; [package &quot;raster&quot;] with 4 slots
##   .. .. .. .. .. .. .. ..@ xmin: num 314026
##   .. .. .. .. .. .. .. ..@ xmax: num 879976
##   .. .. .. .. .. .. .. ..@ ymin: num 3594743
##   .. .. .. .. .. .. .. ..@ ymax: num 4323678
##   .. .. .. .. .. ..@ rotated : logi FALSE
##   .. .. .. .. .. ..@ rotation:Formal class &#39;.Rotation&#39; [package &quot;raster&quot;] with 2 slots
##   .. .. .. .. .. .. .. ..@ geotrans: num(0) 
##   .. .. .. .. .. .. .. ..@ transfun:function ()  
##   .. .. .. .. .. ..@ ncols   : int 566
##   .. .. .. .. .. ..@ nrows   : int 729
##   .. .. .. .. .. ..@ crs     :Formal class &#39;CRS&#39; [package &quot;sp&quot;] with 1 slot
##   .. .. .. .. .. .. .. ..@ projargs: chr &quot;+proj=utm +zone=11 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0&quot;
##   .. .. .. .. .. ..@ history : list()
##   .. .. .. .. .. ..@ z       : list()
##   .. .. ..@ title   : chr(0) 
##   .. .. ..@ extent  :Formal class &#39;Extent&#39; [package &quot;raster&quot;] with 4 slots
##   .. .. .. .. ..@ xmin: num 314026
##   .. .. .. .. ..@ xmax: num 879976
##   .. .. .. .. ..@ ymin: num 3594743
##   .. .. .. .. ..@ ymax: num 4323678
##   .. .. ..@ rotated : logi FALSE
##   .. .. ..@ rotation:Formal class &#39;.Rotation&#39; [package &quot;raster&quot;] with 2 slots
##   .. .. .. .. ..@ geotrans: num(0) 
##   .. .. .. .. ..@ transfun:function ()  
##   .. .. ..@ ncols   : int 566
##   .. .. ..@ nrows   : int 729
##   .. .. ..@ crs     :Formal class &#39;CRS&#39; [package &quot;sp&quot;] with 1 slot
##   .. .. .. .. ..@ projargs: chr &quot;+proj=utm +zone=11 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0&quot;
##   .. .. ..@ history : list()
##   .. .. ..@ z       : list()
##   ..@ has.data.eval    : logi FALSE
##   ..@ eval.coord       :&#39;data.frame&#39;:    0 obs. of  0 variables
## Formal class &#39;data.frame&#39; [package &quot;methods&quot;] with 4 slots
##   .. .. ..@ .Data    : list()
##   .. .. ..@ names    : chr(0) 
##   .. .. ..@ row.names: int(0) 
##   .. .. ..@ .S3Class : chr &quot;data.frame&quot;
##   ..@ eval.data.species: num(0) 
##   ..@ eval.data.env.var:&#39;data.frame&#39;:    0 obs. of  0 variables
## Formal class &#39;data.frame&#39; [package &quot;methods&quot;] with 4 slots
##   .. .. ..@ .Data    : list()
##   .. .. ..@ names    : chr(0) 
##   .. .. ..@ row.names: int(0) 
##   .. .. ..@ .S3Class : chr &quot;data.frame&quot;</code></pre>
<pre class="r"><code>summary(chuck.sp.utm.pa@data.species)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##       1       1       1       1       1       1    1878</code></pre>
</div>
<div id="grab-the-pa-data-from-the-formatted-dataset" class="section level5">
<h5>Grab the PA data from the formatted dataset</h5>
<pre class="r"><code>chuck.sp.all &lt;- SpatialPointsDataFrame(coords = chuck.sp.utm.pa@coord, data = data.frame(Chuckwalla = chuck.sp.utm.pa@data.species), proj = CRS(proj4string(chuck.sp.utm)))</code></pre>
</div>
<div id="replace-the-na-from-the-pa-data-with-0-to-feed-into-next-data-selection" class="section level5">
<h5>Replace the NA from the PA data with 0 to feed into next data selection</h5>
<pre class="r"><code>chuck.sp.all$Chuckwalla[is.na(chuck.sp.all$Chuckwalla)] &lt;- 0
chuck.sp.all</code></pre>
<pre><code>## class       : SpatialPointsDataFrame 
## features    : 3756 
## extent      : 317525.5, 874476.3, 3601242, 4323178  (xmin, xmax, ymin, ymax)
## crs         : +proj=utm +zone=11 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0 
## variables   : 1
## names       : Chuckwalla 
## min values  :          0 
## max values  :          1</code></pre>
</div>
<div id="check-the-observations-and-pas-on-a-plot." class="section level5">
<h5>Check the Observations and PAs on a plot.</h5>
<pre class="r"><code>plot(env[[3]])</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<pre class="r"><code>points(chuck.sp.all, col=&#39;red&#39;) 
points(chuck.sp.utm, col=&#39;black&#39;)</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-23-2.png" width="672" /></p>
</div>
<div id="now-we-create-training-and-evaluation-sets.-start-by-checking-how-many-records-you-have-after-the-initial-cleaning.-then-decide-what-percent-of-the-data-you-want-to-use-for-training-and-testing." class="section level5">
<h5>Now we create training and ‘Evaluation’ sets. Start by checking how many records you have after the initial cleaning. Then, decide what percent of the data you want to use for training and testing.</h5>
<pre class="r"><code>howmanychucks &lt;- dim(chuck.sp.all)[1]/2

## 70 % of those
pct70 &lt;- round(howmanychucks * 0.7)</code></pre>
</div>
<div id="now-split-the-presence-data-from-pas." class="section level5">
<h5>Now split the presence data from PAs.</h5>
<pre class="r"><code>chuck.sp.Pres &lt;- chuck.sp.all[chuck.sp.all$Chuckwalla == 1,]
chuck.sp.Pa &lt;- chuck.sp.all[chuck.sp.all$Chuckwalla == 0,]</code></pre>
</div>
<div id="sample-70-from-the-whole-length-withouth-replacement." class="section level5">
<h5>Sample 70% from the whole length withouth replacement.</h5>
<pre class="r"><code>trnchuckrows &lt;- sample(1:howmanychucks, size = pct70, replace = F)</code></pre>
</div>
<div id="grab-presence-and-pa-data-to-assign-to-training-and-testing-sets." class="section level5">
<h5>Grab Presence and PA data to assign to training and testing sets.</h5>
<pre class="r"><code>## select those rows
chuck.sp.Pres.trn &lt;- chuck.sp.Pres[trnchuckrows,&#39;Chuckwalla&#39;]
chuck.sp.Pa.trn &lt;- chuck.sp.Pa[trnchuckrows,&#39;Chuckwalla&#39;]

## select the opposite for testing
chuck.sp.Pres.tst &lt;- chuck.sp.Pres[-trnchuckrows,&#39;Chuckwalla&#39;]
chuck.sp.Pa.tst &lt;- chuck.sp.Pa[-trnchuckrows,&#39;Chuckwalla&#39;]

## Combine rows #### 
chuck.sp.trn &lt;- rbind(chuck.sp.Pres.trn, chuck.sp.Pa.trn)
chuck.sp.tst &lt;- rbind(chuck.sp.Pres.tst, chuck.sp.Pa.tst)</code></pre>
</div>
<div id="check-training-and-testing-dataset-on-maps." class="section level5">
<h5>Check training and testing dataset on maps.</h5>
<pre class="r"><code>plot(env[[&#39;sp30&#39;]], main = &quot; Summer Precipitation: Training Data&quot;)</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<pre class="r"><code>points(chuck.sp.trn[chuck.sp.trn$Chuckwalla == 1,], pch=19)
points(chuck.sp.trn[chuck.sp.trn$Chuckwalla == 0,], pch=24, col=&#39;red&#39;)</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-28-2.png" width="672" /></p>
<pre class="r"><code>plot(env[[&#39;sp30&#39;]], main = &quot; Summer Precipitation: Testing Data&quot;)</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-28-3.png" width="672" /></p>
<pre class="r"><code>points(chuck.sp.tst[chuck.sp.tst$Chuckwalla == 1,], pch=19)
points(chuck.sp.tst[chuck.sp.tst$Chuckwalla == 0,], pch=24, col=&#39;red&#39;)</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-28-4.png" width="672" /></p>
</div>
<div id="before-we-can-start-modeling-we-need-to-check-our-data-for-spatial-autocorrelation.-we-do-this-by-creating-variograms-and-then-thinning-the-data." class="section level5">
<h5>Before we can start modeling, we need to check our data for spatial autocorrelation. We do this by creating variograms and then thinning the data.</h5>
<pre class="r"><code>library(gstat)</code></pre>
<pre><code>## Registered S3 method overwritten by &#39;xts&#39;:
##   method     from
##   as.zoo.xts zoo</code></pre>
<pre class="r"><code>c.variog &lt;- variogram(Chuckwalla ~1, chuck.sp.trn, xlab= &quot;Distance (m)&quot;, ylab=&quot;Semivariance&quot;)</code></pre>
<pre><code>## Warning in variogram.default(y, locations, X, trend.beta = beta, grid =
## grid, : the following arguments are ignored: Distance (m), Semivariance</code></pre>
<pre class="r"><code>plot(c.variog) #check training data for SA (it there)</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<pre class="r"><code>c.variog2 &lt;- variogram(Chuckwalla ~1, chuck.sp.tst, xlab= &quot;Distance (m)&quot;, ylab=&quot;Semivariance&quot;)</code></pre>
<pre><code>## Warning in variogram.default(y, locations, X, trend.beta = beta, grid =
## grid, : the following arguments are ignored: Distance (m), Semivariance</code></pre>
<pre class="r"><code>plot(c.variog2) #check testing data for SA (it there)</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-29-2.png" width="672" /></p>
<pre class="r"><code>### Zooming in a bit to focus on local effects
c.variog3 &lt;- variogram(Chuckwalla ~1, chuck.sp.trn,cutoff = 50000)
c.variog3.f &lt;- fit.variogram(c.variog3, vgm(psill = 0.1, &quot;Sph&quot;, range = 25000, nugget = 0))
plot(c.variog3, model = c.variog3.f)</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-29-3.png" width="672" /></p>
</div>
<div id="now-we-need-to-thin-the-dataset-to-reduce-our-spatial-autocorrelation-which-is-due-to-strong-samplingcollecting-bias.-we-start-by-making-a-grid." class="section level5">
<h5>Now we need to thin the dataset to reduce our Spatial Autocorrelation, which is due to strong sampling/collecting bias. We start by making a grid.</h5>
<pre class="r"><code>## Lets make a quick grid for sampling

minx &lt;- min(bbox(chuck.sp.utm)[1,])
maxx &lt;- max(bbox(chuck.sp.utm)[1,])
miny &lt;- min(bbox(chuck.sp.utm)[2,])
maxy &lt;- max(bbox(chuck.sp.utm)[2,])
sidel &lt;- 35000  # determines grid spacing (based on where SA tapers off)

proj &lt;- CRS(proj4string(chuck.sp.utm))
x &lt;- seq(from = minx, to = maxx, by = sidel) ## sequence of x centroids
y &lt;- seq(from = miny, to = maxy, by = sidel) ## sequence of y for centroids</code></pre>
</div>
<div id="create-a-grid-of-all-pairs-of-coordinates-as-a-data.frame-using-the-expand-grid-function-and-then-make-it-a-gridded-object." class="section level5">
<h5>Create a grid of all pairs of coordinates (as a data.frame) using the “expand grid” function and then make it a gridded object.</h5>
<pre class="r"><code>xy &lt;- expand.grid(x = x, y = y)
grid.pts&lt;-SpatialPointsDataFrame(coords= xy,data = data.frame(id = 1:dim(xy)[1]), proj4string = proj)
plot(grid.pts)</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<pre class="r"><code>gridded(grid.pts) &lt;- TRUE
grid &lt;- as(grid.pts, &quot;SpatialPolygons&quot;)</code></pre>
</div>
<div id="plot-for-inspection-if-needed" class="section level5">
<h5>Plot for inspection if needed</h5>
<pre class="r"><code>plot(grid)
points(grid.pts, col=&#39;red&#39;)</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
</div>
<div id="now-convert-it-to-an-spdf-and-trasform-it-to-the-projection-of-your-data." class="section level5">
<h5>Now convert it to an SPDF and trasform it to the projection of your data.</h5>
<pre class="r"><code>gridspdf &lt;- SpatialPolygonsDataFrame(grid, data=data.frame(id=row.names(grid), row.names=row.names(grid), values = rep(1,length(grid))))
names.grd&lt;-sapply
proj4string(gridspdf)</code></pre>
<pre><code>## [1] &quot;+proj=utm +zone=11 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0&quot;</code></pre>
<pre class="r"><code>gridspdf &lt;- spTransform(gridspdf, proj)
plot(gridspdf)
points(chuck.sp.utm, col=&#39;red&#39;)</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
</div>
<div id="subsample-your-grid-to-drop-the-squares-you-dont-need." class="section level5">
<h5>Subsample your grid to drop the squares you don’t need.</h5>
<pre class="r"><code>getgrid &lt;- over(gridspdf, chuck.sp.utm)
head(getgrid)</code></pre>
<pre><code>##      Chuckwalla
## g256         NA
## g257         NA
## g258         NA
## g259         NA
## g260         NA
## g261         NA</code></pre>
<pre class="r"><code>grids2.occ &lt;- gridspdf[!is.na(getgrid$Chuckwalla),]
plot(grids2.occ)
points(chuck.sp.utm, col=&#39;red&#39;)</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-34-1.png" width="672" /></p>
</div>
<div id="thin-the-data-down-to-5-chuckwallas-per-grid-space.-note-this-is-really-heavy-thinning." class="section level5">
<h5>Thin the data down to 5 Chuckwallas per grid-space. Note: this is really heavy thinning.</h5>
<pre class="r"><code>set.seed(24)
## find five per grid
nper = 5
keepchucks &lt;- chuck.sp.utm[1,]
for(i in 1:length(grids2.occ)){
  tmp.poly &lt;- grids2.occ[i,]
  #plot(tmp.poly)
  tmp.over &lt;- over(chuck.sp.utm, tmp.poly)
  tmp.chucks &lt;- chuck.sp.utm[!is.na(tmp.over$id),]
  #points(tmp.chucks)
  length(tmp.chucks)
  if(length(tmp.chucks) &gt; nper){
  tmp.chucks &lt;- tmp.chucks[sample(size = nper,x = 1:length(tmp.chucks)),]
  }
  #points(tmp.chucks, col=&#39;red&#39;)
  keepchucks &lt;- rbind(keepchucks,tmp.chucks)
}
## Get rid of first row that you used to build the df
keepchucks &lt;- keepchucks[-1,]

plot(gridspdf)
points(chuck.sp.utm, pch=19,col=&#39;blue&#39;)
points(keepchucks, pch=19, col=&#39;red&#39;)</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-35-1.png" width="672" /></p>
</div>
<div id="now-we-re-format-the-data-to-generate-pas-for-the-thinned-dataset-and-re-check-it-for-sa." class="section level5">
<h5>Now we re-format the data to generate PAs for the thinned dataset and re-check it for SA.</h5>
<pre class="r"><code>set.seed(24)
keepchuck.pa.bm &lt;- BIOMOD_FormatingData(resp.var = keepchucks$Chuckwalla,
                     expl.var = env,
                     resp.xy = coordinates(keepchucks),
                     resp.name = &#39;Chuckwalla&#39;,
                     #eval.resp.var = chuck.sp.utm.ex.tst$Chuckwalla,
                     #eval.expl.var = env,
                     #eval.resp.xy = coordinates(chuck.sp.utm.ex.tst),
                     PA.nb.rep = 1,
                     PA.nb.absences = dim(keepchucks)[1],
                     PA.strategy = &#39;sre&#39;,
                     #PA.dist.min = 1000,
                     #PA.dist.max = 20000,
                     PA.sre.quant = 0.1,
                     PA.table = NULL,
                     na.rm = TRUE)</code></pre>
<pre><code>## 
## -=-=-=-=-=-=-=-=-=-=-=-= Chuckwalla Data Formating -=-=-=-=-=-=-=-=-=-=-=-=
## 
##       ! No data has been set aside for modeling evaluation
##    &gt; Pseudo Absences Selection checkings...
##    &gt; SRE pseudo absences selection
## -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= Done -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=</code></pre>
<pre class="r"><code>keepchuck.pa.bm</code></pre>
<pre><code>## 
## -=-=-=-=-=-=-=-=-=-=-=-= &#39;BIOMOD.formated.data.PA&#39; -=-=-=-=-=-=-=-=-=-=-=-=
## 
## sp.name =  Chuckwalla
## 
##   482 presences,  0 true absences and  482 undifined points in dataset
## 
## 
##   7 explanatory variables
## 
##    BlkDensity        pctCov          pctRocks         pctRuf      
##  Min.   :0.000   Min.   : 22.61   Min.   : 0.00   Min.   :0.0000  
##  1st Qu.:1.387   1st Qu.:108.09   1st Qu.: 0.00   1st Qu.:0.0000  
##  Median :1.460   Median :115.10   Median : 0.00   Median :0.0000  
##  Mean   :1.449   Mean   :118.38   Mean   : 1.44   Mean   :0.1039  
##  3rd Qu.:1.560   3rd Qu.:124.24   3rd Qu.: 1.14   3rd Qu.:0.1063  
##  Max.   :1.680   Max.   :192.46   Max.   :26.25   Max.   :0.9982  
##      slope             sp30             wp30       
##  Min.   : 0.000   Min.   :  0.00   Min.   :  0.00  
##  1st Qu.: 1.517   1st Qu.: 43.00   1st Qu.: 78.57  
##  Median : 4.560   Median : 64.50   Median :114.66  
##  Mean   : 9.748   Mean   : 70.81   Mean   :124.85  
##  3rd Qu.:15.538   3rd Qu.: 94.25   3rd Qu.:159.59  
##  Max.   :50.531   Max.   :180.00   Max.   :547.98  
## 
## 
##  1 Pseudo Absences dataset available ( PA1 ) with  482 
## absences in each (true abs + pseudo abs)
## 
## -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=</code></pre>
</div>
<div id="now-we-grab-the-pas-from-this-dataset.-full-process-hidden-from-html-same-as-above" class="section level5">
<h5>Now we grab the PAs from this dataset. (Full process hidden from HTML-same as above)</h5>
<pre><code>## class       : SpatialPointsDataFrame 
## features    : 964 
## extent      : 325524.8, 869476.7, 3607242, 4323178  (xmin, xmax, ymin, ymax)
## crs         : +proj=utm +zone=11 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0 
## variables   : 1
## names       : Chuckwalla 
## min values  :          0 
## max values  :          1</code></pre>
</div>
<div id="again-create-training-and-evaluation-datasets-from-the-thinned-data.-this-is-the-same-process-we-used-before.-process-hidden-from-html-same-as-above" class="section level5">
<h5>Again, create training and evaluation datasets from the thinned data. This is the same process we used before. (Process hidden from html-same as above)</h5>
</div>
<div id="check-the-thinned-data-for-sa.-we-effectively-decreased-range-of-sa-from-about-35000-to-15000." class="section level5">
<h5>Check the thinned data for SA. We effectively decreased range of SA, from about 35000 to 15000.</h5>
<pre class="r"><code>### spatial autocorrelation
kc.variog &lt;- variogram(Chuckwalla ~1, k.chuck.trn, xlab= &quot;Distance (m)&quot;, ylab=&quot;Semivariance&quot;)</code></pre>
<pre><code>## Warning in variogram.default(y, locations, X, trend.beta = beta, grid =
## grid, : the following arguments are ignored: Distance (m), Semivariance</code></pre>
<pre class="r"><code>plot(kc.variog)</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
<pre class="r"><code>kc.variog2 &lt;- variogram(Chuckwalla ~1, k.chuck.tst, xlab= &quot;Distance (m)&quot;, ylab=&quot;Semivariance&quot;)</code></pre>
<pre><code>## Warning in variogram.default(y, locations, X, trend.beta = beta, grid =
## grid, : the following arguments are ignored: Distance (m), Semivariance</code></pre>
<pre class="r"><code>plot(kc.variog2) #check testing data for SA (it there)</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-39-2.png" width="672" /></p>
<pre class="r"><code>### Zooming in a bit to focus on local effects
kc.variog3 &lt;- variogram(Chuckwalla ~1, k.chuck.trn, cutoff = 50000, xlab= &quot;Distance (m)&quot;, ylab=&quot;Semivariance&quot;)</code></pre>
<pre><code>## Warning in variogram.default(y, locations, X, trend.beta = beta, grid =
## grid, : the following arguments are ignored: Distance (m), Semivariance</code></pre>
<pre class="r"><code>kc.variog3.f &lt;- fit.variogram(kc.variog3, vgm(psill = 0.1, &quot;Sph&quot;, range = 25000, nugget = 0))
plot(kc.variog3, model = kc.variog3.f)</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-39-3.png" width="672" /></p>
</div>
<div id="re-format-the-data-again-to-include-the-thinned-training-and-testing-data." class="section level5">
<h5>Re-format the data again to include the thinned training and testing data.</h5>
<pre class="r"><code>## create a new dataset with the testing data assigned in the eval slots
set.seed(24)
chuck.sp.bm &lt;- BIOMOD_FormatingData(resp.var = k.chuck.trn$Chuckwalla,
                     expl.var = env,
                     resp.xy = coordinates(k.chuck.trn),
                     resp.name = &#39;Chuckwalla&#39;,
                     eval.resp.var = k.chuck.tst$Chuckwalla,
                     eval.expl.var = env,
                     eval.resp.xy = coordinates(k.chuck.tst),
                     PA.nb.rep = 0,
                     PA.nb.absences = NULL,
                     PA.strategy = NULL,
                     PA.dist.min = NULL,
                     PA.dist.max = NULL,
                     PA.sre.quant = NULL,
                     PA.table = NULL,
                     na.rm = TRUE)</code></pre>
<pre><code>## 
## -=-=-=-=-=-=-=-=-=-=-=-= Chuckwalla Data Formating -=-=-=-=-=-=-=-=-=-=-=-=
## 
## &gt; No pseudo absences selection !
## -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= Done -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=</code></pre>
<pre class="r"><code> chuck.sp.bm</code></pre>
<pre><code>## 
## -=-=-=-=-=-=-=-=-=-=-=-=-= &#39;BIOMOD.formated.data&#39; -=-=-=-=-=-=-=-=-=-=-=-=-=
## 
## sp.name =  Chuckwalla
## 
##   337 presences,  337 true absences and  0 undifined points in dataset
## 
## 
##   7 explanatory variables
## 
##    BlkDensity       pctCov          pctRocks          pctRuf      
##  Min.   :0.00   Min.   : 22.61   Min.   : 0.000   Min.   :0.0000  
##  1st Qu.:1.38   1st Qu.:107.25   1st Qu.: 0.000   1st Qu.:0.0000  
##  Median :1.46   Median :114.86   Median : 0.000   Median :0.0000  
##  Mean   :1.45   Mean   :117.89   Mean   : 1.461   Mean   :0.1046  
##  3rd Qu.:1.56   3rd Qu.:124.45   3rd Qu.: 1.140   3rd Qu.:0.1012  
##  Max.   :1.68   Max.   :183.67   Max.   :26.250   Max.   :0.9982  
##      slope             sp30            wp30       
##  Min.   : 0.000   Min.   :  0.0   Min.   :  0.00  
##  1st Qu.: 1.348   1st Qu.: 43.0   1st Qu.: 77.66  
##  Median : 4.087   Median : 64.0   Median :114.71  
##  Mean   : 9.392   Mean   : 71.2   Mean   :125.06  
##  3rd Qu.:14.426   3rd Qu.: 96.0   3rd Qu.:156.88  
##  Max.   :50.531   Max.   :180.0   Max.   :547.98  
## 
## 
## Evaluation data :
## 
##   145 presences,  145 true absences and  0 undifined points in dataset
## 
## 
## 
##    BlkDensity        pctCov          pctRocks          pctRuf      
##  Min.   :0.000   Min.   : 70.83   Min.   : 0.000   Min.   :0.0000  
##  1st Qu.:1.400   1st Qu.:109.30   1st Qu.: 0.000   1st Qu.:0.0000  
##  Median :1.480   Median :115.41   Median : 0.000   Median :0.0000  
##  Mean   :1.447   Mean   :119.51   Mean   : 1.392   Mean   :0.1023  
##  3rd Qu.:1.580   3rd Qu.:124.05   3rd Qu.: 1.140   3rd Qu.:0.1113  
##  Max.   :1.650   Max.   :192.46   Max.   :26.250   Max.   :0.9135  
##      slope             sp30             wp30       
##  Min.   : 0.000   Min.   :  5.00   Min.   :  0.00  
##  1st Qu.: 2.108   1st Qu.: 41.50   1st Qu.: 80.45  
##  Median : 6.423   Median : 65.00   Median :114.23  
##  Mean   :10.575   Mean   : 69.91   Mean   :124.36  
##  3rd Qu.:17.342   3rd Qu.: 90.75   3rd Qu.:163.29  
##  Max.   :42.663   Max.   :168.00   Max.   :401.36  
## 
## -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=</code></pre>
</div>
</div>
</div>
</div>
<div id="model-fitting-time" class="section level2">
<h2>Model Fitting Time!</h2>
<div id="lets-see-which-algorithms-are-available-for-model-fitting." class="section level5">
<h5>Let’s see which algorithms are available for model fitting.</h5>
<pre class="r"><code>myBiomodOption &lt;- BIOMOD_ModelingOptions() 
myBiomodOption</code></pre>
<pre><code>## 
## -=-=-=-=-=-=-=-=-=-=-=-=  &#39;BIOMOD.Model.Options&#39;  -=-=-=-=-=-=-=-=-=-=-=-=
## 
## 
## GLM = list( type = &#39;quadratic&#39;,
##             interaction.level = 0,
##             myFormula = NULL,
##             test = &#39;AIC&#39;,
##             family = binomial(link = &#39;logit&#39;),
##             mustart = 0.5,
##             control = glm.control(epsilon = 1e-08, maxit = 50
## , trace = FALSE) ),
## 
## 
## GBM = list( distribution = &#39;bernoulli&#39;,
##             n.trees = 2500,
##             interaction.depth = 7,
##             n.minobsinnode = 5,
##             shrinkage = 0.001,
##             bag.fraction = 0.5,
##             train.fraction = 1,
##             cv.folds = 3,
##             keep.data = FALSE,
##             verbose = FALSE,
##             perf.method = &#39;cv&#39;),
## 
## GAM = list( algo = &#39;GAM_mgcv&#39;,
##             type = &#39;s_smoother&#39;,
##             k = -1,
##             interaction.level = 0,
##             myFormula = NULL,
##             family = binomial(link = &#39;logit&#39;),
##             method = &#39;GCV.Cp&#39;,
##             optimizer = c(&#39;outer&#39;,&#39;newton&#39;),
##             select = FALSE,
##             knots = NULL,
##             paraPen = NULL,
##             control = list(nthreads = 1, irls.reg = 0, epsilon = 1e-07
## , maxit = 200, trace = FALSE, mgcv.tol = 1e-07, mgcv.half = 15
## , rank.tol = 1.49011611938477e-08
## , nlm = list(ndigit=7, gradtol=1e-06, stepmax=2, steptol=1e-04, iterlim=200, check.analyticals=0)
## , optim = list(factr=1e+07)
## , newton = list(conv.tol=1e-06, maxNstep=5, maxSstep=2, maxHalf=30, use.svd=0)
## , outerPIsteps = 0, idLinksBases = TRUE, scalePenalty = TRUE
## , efs.lspmax = 15, efs.tol = 0.1, keepData = FALSE, scale.est = fletcher
## , edge.correct = FALSE) ),
## 
## 
## CTA = list( method = &#39;class&#39;,
##             parms = &#39;default&#39;,
##             cost = NULL,
##             control = list(xval = 5, minbucket = 5, minsplit = 5
## , cp = 0.001, maxdepth = 25) ),
## 
## 
## ANN = list( NbCV = 5,
##             size = NULL,
##             decay = NULL,
##             rang = 0.1,
##             maxit = 200),
## 
## SRE = list( quant = 0.025),
## 
## FDA = list( method = &#39;mars&#39;,
##             add_args = NULL),
## 
## MARS = list( type = &#39;simple&#39;,
##              interaction.level = 0,
##              myFormula = NULL,
##              nk = NULL,
##              penalty = 2,
##              thresh = 0.001,
##              nprune = NULL,
##              pmethod = &#39;backward&#39;),
## 
## RF = list( do.classif = TRUE,
##            ntree = 500,
##            mtry = &#39;default&#39;,
##            nodesize = 5,
##            maxnodes = NULL),
## 
## MAXENT.Phillips = list( path_to_maxent.jar = &#39;E:/GIT/NRES-746&#39;,
##                memory_allocated = 512,
##                background_data_dir = &#39;default&#39;,
##                maximumbackground = &#39;default&#39;,
##                maximumiterations = 200,
##                visible = FALSE,
##                linear = TRUE,
##                quadratic = TRUE,
##                product = TRUE,
##                threshold = TRUE,
##                hinge = TRUE,
##                lq2lqptthreshold = 80,
##                l2lqthreshold = 10,
##                hingethreshold = 15,
##                beta_threshold = -1,
##                beta_categorical = -1,
##                beta_lqp = -1,
##                beta_hinge = -1,
##                betamultiplier = 1,
##                defaultprevalence = 0.5),
## 
## MAXENT.Tsuruoka = list( l1_regularizer = 0,
##                         l2_regularizer = 0,
##                         use_sgd = FALSE,
##                         set_heldout = 0,
##                         verbose = FALSE)
## -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=</code></pre>
</div>
<div id="now-lets-set-up-our-model-code." class="section level5">
<h5>Now let’s set up our model code.</h5>
<pre class="r"><code>set.seed(28)
library(mgcv)</code></pre>
<pre><code>## Loading required package: nlme</code></pre>
<pre><code>## 
## Attaching package: &#39;nlme&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:raster&#39;:
## 
##     getData</code></pre>
<pre><code>## This is mgcv 1.8-28. For overview type &#39;help(&quot;mgcv-package&quot;)&#39;.</code></pre>
<pre class="r"><code>library(nlme)
# NOTE: We don&#39;t usually use the suppress warnings function, but needed it to spruce up the html file for the presentation.
suppressWarnings(system.time( myBiomodModelOut &lt;- BIOMOD_Modeling( chuck.sp.bm, 
               models = c(&#39;SRE&#39;,&#39;GAM&#39;,&#39;GBM&#39;,&#39;RF&#39;), # four algorithms
               models.options = myBiomodOption, # where to find algorithms
               NbRunEval=5, # number of iterations
               DataSplit=80, # used for internal data calibration
               VarImport=10, # num of bootstraps to determine var importance
               models.eval.meth = c(&#39;TSS&#39;,&#39;ROC&#39;,&#39;ACCURACY&#39;), # performance metrics
               do.full.models=FALSE, # run using all training data
               rescal.all.models = T, # need for ensemble compatibility
               modeling.id=&quot;test&quot;)))</code></pre>
<pre><code>## Setting levels: control = 0, case = 1</code></pre>
<pre><code>## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1
## Setting levels: control = 0, case = 1</code></pre>
</div>
<div id="lets-see-if-it-worked" class="section level5">
<h5>Let’s see if it worked!</h5>
<pre class="r"><code>myBiomodModelOut </code></pre>
<pre><code>## 
## -=-=-=-=-=-=-=-=-=-=-=-=-=-= BIOMOD.models.out -=-=-=-=-=-=-=-=-=-=-=-=-=-=
## 
## Modeling id : test
## 
## Species modeled : Chuckwalla
## 
## Considered variables : BlkDensity pctCov pctRocks pctRuf slope sp30 wp30
## 
## 
## Computed Models :  Chuckwalla_AllData_RUN1_SRE 
## Chuckwalla_AllData_RUN1_GAM Chuckwalla_AllData_RUN1_GBM 
## Chuckwalla_AllData_RUN1_RF Chuckwalla_AllData_RUN2_SRE 
## Chuckwalla_AllData_RUN2_GAM Chuckwalla_AllData_RUN2_GBM 
## Chuckwalla_AllData_RUN2_RF Chuckwalla_AllData_RUN3_SRE 
## Chuckwalla_AllData_RUN3_GAM Chuckwalla_AllData_RUN3_GBM 
## Chuckwalla_AllData_RUN3_RF Chuckwalla_AllData_RUN4_SRE 
## Chuckwalla_AllData_RUN4_GAM Chuckwalla_AllData_RUN4_GBM 
## Chuckwalla_AllData_RUN4_RF Chuckwalla_AllData_RUN5_SRE 
## Chuckwalla_AllData_RUN5_GAM Chuckwalla_AllData_RUN5_GBM 
## Chuckwalla_AllData_RUN5_RF
## 
## 
## Failed Models :  none
## 
## -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=</code></pre>
</div>
<div id="pull-the-evaluation-data-and-check-it." class="section level5">
<h5>Pull the evaluation data and check it.</h5>
</div>
<div id="sre-and-gam-dont-appear-to-perform-as-well-as-the-gbm-and-rf-models.-run5-looks-good-for-both-gbm-and-rf-for-this-exercise-we-will-choose-that-run-for-those-two-models." class="section level5">
<h5>SRE and GAM don’t appear to perform as well as the GBM and RF models. Run5 looks good for both GBM and RF, for this exercise we will choose that run for those two models.</h5>
<pre class="r"><code>myBiomodModelEval &lt;- get_evaluations(myBiomodModelOut)
myBiomodModelEval</code></pre>
<pre><code>## , , SRE, RUN1, AllData
## 
##          Testing.data Evaluating.data Cutoff Sensitivity Specificity
## TSS             0.328           0.338    495      81.379      52.414
## ROC             0.664           0.669    500      81.379      52.414
## ACCURACY        0.664           0.669    495      81.379      52.414
## 
## , , GAM, RUN1, AllData
## 
##          Testing.data Evaluating.data Cutoff Sensitivity Specificity
## TSS             0.582           0.379  553.5      76.552      61.379
## ROC             0.859           0.783  651.5      67.586      74.483
## ACCURACY        0.791           0.690  558.0      76.552      61.379
## 
## , , GBM, RUN1, AllData
## 
##          Testing.data Evaluating.data Cutoff Sensitivity Specificity
## TSS             0.627           0.448  386.0      82.759      62.069
## ROC             0.900           0.813  667.5      74.483      76.552
## ACCURACY        0.813           0.724  386.0      82.759      62.069
## 
## , , RF, RUN1, AllData
## 
##          Testing.data Evaluating.data Cutoff Sensitivity Specificity
## TSS             0.716           0.524    706      76.552      75.172
## ROC             0.913           0.834    837      73.103      82.759
## ACCURACY        0.858           0.759    626      77.241      74.483
## 
## , , SRE, RUN2, AllData
## 
##          Testing.data Evaluating.data Cutoff Sensitivity Specificity
## TSS             0.358           0.331    495      81.379      51.724
## ROC             0.679           0.666    500      81.379      51.724
## ACCURACY        0.679           0.666    495      81.379      51.724
## 
## , , GAM, RUN2, AllData
## 
##          Testing.data Evaluating.data Cutoff Sensitivity Specificity
## TSS             0.597           0.448  528.0          80      64.828
## ROC             0.839           0.795  530.5          80      65.517
## ACCURACY        0.799           0.724  528.0          80      64.828
## 
## , , GBM, RUN2, AllData
## 
##          Testing.data Evaluating.data Cutoff Sensitivity Specificity
## TSS             0.597           0.476  355.5      83.448      64.138
## ROC             0.865           0.815  589.5      77.931      71.724
## ACCURACY        0.799           0.738  355.5      83.448      64.138
## 
## , , RF, RUN2, AllData
## 
##          Testing.data Evaluating.data Cutoff Sensitivity Specificity
## TSS             0.642           0.490    450      80.690      68.966
## ROC             0.877           0.832    816      71.034      82.759
## ACCURACY        0.821           0.748    434      80.690      68.966
## 
## , , SRE, RUN3, AllData
## 
##          Testing.data Evaluating.data Cutoff Sensitivity Specificity
## TSS             0.418           0.345    495       80.69      53.793
## ROC             0.709           0.672    500       80.69      53.793
## ACCURACY        0.709           0.672    495       80.69      53.793
## 
## , , GAM, RUN3, AllData
## 
##          Testing.data Evaluating.data Cutoff Sensitivity Specificity
## TSS             0.448           0.393  394.0      84.138      55.172
## ROC             0.791           0.774  580.5      74.483      66.897
## ACCURACY        0.724           0.697  394.0      84.138      55.172
## 
## , , GBM, RUN3, AllData
## 
##          Testing.data Evaluating.data Cutoff Sensitivity Specificity
## TSS             0.567           0.359    160      88.966      46.897
## ROC             0.833           0.806    408      81.379      67.586
## ACCURACY        0.784           0.679    160      88.966      46.897
## 
## , , RF, RUN3, AllData
## 
##          Testing.data Evaluating.data Cutoff Sensitivity Specificity
## TSS             0.612           0.490  379.5      81.379      67.586
## ROC             0.860           0.828  752.0      73.793      77.931
## ACCURACY        0.806           0.745  379.5      81.379      67.586
## 
## , , SRE, RUN4, AllData
## 
##          Testing.data Evaluating.data Cutoff Sensitivity Specificity
## TSS             0.254           0.366    495      76.552          60
## ROC             0.627           0.683    500      76.552          60
## ACCURACY        0.627           0.683    495      76.552          60
## 
## , , GAM, RUN4, AllData
## 
##          Testing.data Evaluating.data Cutoff Sensitivity Specificity
## TSS             0.493           0.393  380.0      81.379      57.931
## ROC             0.804           0.785  527.5      77.241      66.897
## ACCURACY        0.746           0.697  380.0      81.379      57.931
## 
## , , GBM, RUN4, AllData
## 
##          Testing.data Evaluating.data Cutoff Sensitivity Specificity
## TSS             0.522           0.483    418      82.069      66.207
## ROC             0.827           0.817    449      81.379      68.966
## ACCURACY        0.761           0.741    418      82.069      66.207
## 
## , , RF, RUN4, AllData
## 
##          Testing.data Evaluating.data Cutoff Sensitivity Specificity
## TSS             0.552           0.497  406.0      81.379      68.276
## ROC             0.856           0.832  622.5      77.931      75.862
## ACCURACY        0.776           0.748  406.0      81.379      68.276
## 
## , , SRE, RUN5, AllData
## 
##          Testing.data Evaluating.data Cutoff Sensitivity Specificity
## TSS             0.269           0.310    495       79.31      51.724
## ROC             0.634           0.655    500       79.31      51.724
## ACCURACY        0.634           0.655    495       79.31      51.724
## 
## , , GAM, RUN5, AllData
## 
##          Testing.data Evaluating.data Cutoff Sensitivity Specificity
## TSS             0.537           0.441    652      72.414      71.724
## ROC             0.866           0.803    670      71.724      75.172
## ACCURACY        0.769           0.721    652      72.414      71.724
## 
## , , GBM, RUN5, AllData
## 
##          Testing.data Evaluating.data Cutoff Sensitivity Specificity
## TSS             0.627           0.407  829.0      61.379      79.310
## ROC             0.883           0.816  509.5      80.690      71.034
## ACCURACY        0.813           0.703  829.0      61.379      79.310
## 
## , , RF, RUN5, AllData
## 
##          Testing.data Evaluating.data Cutoff Sensitivity Specificity
## TSS             0.657           0.510    796      71.724      79.310
## ROC             0.901           0.838    689      76.552      77.241
## ACCURACY        0.828           0.755    796      71.724      79.310</code></pre>
</div>
<div id="you-can-index-it-by-test-model-and-run." class="section level5">
<h5>You can index it by test, model, and run.</h5>
<pre class="r"><code>dimnames(myBiomodModelEval)   # we specify two algorithms, and run 5</code></pre>
<pre><code>## [[1]]
## [1] &quot;TSS&quot;      &quot;ROC&quot;      &quot;ACCURACY&quot;
## 
## [[2]]
## [1] &quot;Testing.data&quot;    &quot;Evaluating.data&quot; &quot;Cutoff&quot;          &quot;Sensitivity&quot;    
## [5] &quot;Specificity&quot;    
## 
## [[3]]
## [1] &quot;SRE&quot; &quot;GAM&quot; &quot;GBM&quot; &quot;RF&quot; 
## 
## [[4]]
## [1] &quot;RUN1&quot; &quot;RUN2&quot; &quot;RUN3&quot; &quot;RUN4&quot; &quot;RUN5&quot;
## 
## [[5]]
## Chuckwalla_AllData 
##          &quot;AllData&quot;</code></pre>
<pre class="r"><code> myBiomodModelEval[c(&quot;ROC&quot;, &quot;TSS&quot;,&quot;ACCURACY&quot;),c(&quot;Testing.data&quot;,&quot;Evaluating.data&quot;, &quot;Sensitivity&quot;,&quot;Specificity&quot;),c(&quot;RF&quot;,&quot;GBM&quot;),&quot;RUN5&quot;,]</code></pre>
<pre><code>## , , RF
## 
##          Testing.data Evaluating.data Sensitivity Specificity
## ROC             0.901           0.838      76.552      77.241
## TSS             0.657           0.510      71.724      79.310
## ACCURACY        0.828           0.755      71.724      79.310
## 
## , , GBM
## 
##          Testing.data Evaluating.data Sensitivity Specificity
## ROC             0.883           0.816      80.690      71.034
## TSS             0.627           0.407      61.379      79.310
## ACCURACY        0.813           0.703      61.379      79.310</code></pre>
</div>
<div id="next-look-at-variable-importance.-once-you-review-it-you-may-decide-that-some-variables-contributed-so-little-to-the-model-that-you-drop-them-and-re-run-with-a-reduced-set-of-environmental-variables.-principle-of-parsimony" class="section level5">
<h5>Next, look at variable importance. Once you review it, you may decide that some variables contributed so little to the model that you drop them and re-run with a reduced set of environmental variables. (PRINCIPLE OF PARSIMONY)</h5>
</div>
<div id="you-can-index-the-tables-by-run-and-model." class="section level5">
<h5>You can index the tables by run and model.</h5>
<pre class="r"><code>MyBiomodModelVarImp &lt;- get_variables_importance(myBiomodModelOut)
dimnames(MyBiomodModelVarImp)</code></pre>
<pre><code>## [[1]]
## [1] &quot;BlkDensity&quot; &quot;pctCov&quot;     &quot;pctRocks&quot;   &quot;pctRuf&quot;     &quot;slope&quot;     
## [6] &quot;sp30&quot;       &quot;wp30&quot;      
## 
## [[2]]
## [1] &quot;SRE&quot; &quot;GAM&quot; &quot;GBM&quot; &quot;RF&quot; 
## 
## [[3]]
## [1] &quot;RUN1&quot; &quot;RUN2&quot; &quot;RUN3&quot; &quot;RUN4&quot; &quot;RUN5&quot;
## 
## [[4]]
## Chuckwalla_AllData 
##          &quot;AllData&quot;</code></pre>
<pre class="r"><code>MyBiomodModelVarImp[,,&quot;RUN5&quot;,]</code></pre>
<pre><code>##              SRE   GAM   GBM    RF
## BlkDensity 0.062 0.014 0.033 0.093
## pctCov     0.295 0.082 0.079 0.126
## pctRocks   0.077 0.017 0.005 0.013
## pctRuf     0.063 0.042 0.021 0.090
## slope      0.142 0.195 0.164 0.161
## sp30       0.321 0.522 0.472 0.308
## wp30       0.207 0.133 0.134 0.161</code></pre>
</div>
<div id="you-can-also-visually-inspect-variable-importance-by-algorithm." class="section level5">
<h5>You can also visually inspect variable importance by algorithm.</h5>
</div>
<div id="here-its-plotted-for-the-random-forest-models." class="section level5">
<h5>Here it’s plotted for the Random Forest models.</h5>
<pre class="r"><code>str(MyBiomodModelVarImp)</code></pre>
<pre><code>##  num [1:7, 1:4, 1:5, 1] 0.061 0.308 0.054 0.067 0.12 0.374 0.157 0.009 0.09 0.049 ...
##  - attr(*, &quot;dimnames&quot;)=List of 4
##   ..$ : chr [1:7] &quot;BlkDensity&quot; &quot;pctCov&quot; &quot;pctRocks&quot; &quot;pctRuf&quot; ...
##   ..$ : chr [1:4] &quot;SRE&quot; &quot;GAM&quot; &quot;GBM&quot; &quot;RF&quot;
##   ..$ : chr [1:5] &quot;RUN1&quot; &quot;RUN2&quot; &quot;RUN3&quot; &quot;RUN4&quot; ...
##   ..$ : Named chr &quot;AllData&quot;
##   .. ..- attr(*, &quot;names&quot;)= chr &quot;Chuckwalla_AllData&quot;</code></pre>
<pre class="r"><code>rf.imp &lt;- MyBiomodModelVarImp[1:7,4,1:5,1] #pulling out the rf data

##Have a look at the average value....
rfimp.m &lt;- melt(rf.imp) #condenses data to more readable 
rfimp.av &lt;- aggregate(value~ X1, data =rfimp.m, FUN = mean) #take average value of all runs for each covariate, mean importance 
rfimp.av.o &lt;- rfimp.av[order(rfimp.av$value, decreasing = T),] #order them, highest at top 
## Plot means 
library(gplots)
levels(rfimp.m$X1)</code></pre>
<pre><code>## [1] &quot;BlkDensity&quot; &quot;pctCov&quot;     &quot;pctRocks&quot;   &quot;pctRuf&quot;     &quot;slope&quot;     
## [6] &quot;sp30&quot;       &quot;wp30&quot;</code></pre>
<pre class="r"><code>rfimp.m$X1 &lt;- factor(rfimp.m$X1, levels = rfimp.av.o$X1) #refactor to make levels equal to those we just made that are in order
plotmeans(value~ X1, data =rfimp.m, connect=F, n.label=F, xlab = &#39;&#39;, ylab = &#39;Chuck&#39;, main = &#39;Chuck RF Models&#39;, las=2)</code></pre>
<pre><code>## Warning in arrows(x, li, x, pmax(y - gap, li), col = barcol, lwd = lwd, :
## zero-length arrow is of indeterminate angle and so skipped

## Warning in arrows(x, li, x, pmax(y - gap, li), col = barcol, lwd = lwd, :
## zero-length arrow is of indeterminate angle and so skipped</code></pre>
<pre><code>## Warning in arrows(x, ui, x, pmin(y + gap, ui), col = barcol, lwd = lwd, :
## zero-length arrow is of indeterminate angle and so skipped

## Warning in arrows(x, ui, x, pmin(y + gap, ui), col = barcol, lwd = lwd, :
## zero-length arrow is of indeterminate angle and so skipped</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-47-1.png" width="672" /></p>
</div>
<div id="and-for-the-gbm-models" class="section level5">
<h5>And for the GBM models!</h5>
<pre class="r"><code>gbm.imp &lt;- MyBiomodModelVarImp[1:7,3,1:5,1] #pulling out the rf data

##Have a look at the average value....
gbmimp.m &lt;- melt(gbm.imp) #condenses data to more readable 
gbmimp.av &lt;- aggregate(value~ X1, data =gbmimp.m, FUN = mean) #take average value of all runs for each covariate, mean importance 
gbmimp.av.o &lt;- gbmimp.av[order(gbmimp.av$value, decreasing = T),] #order them, highest at top 
## Plot means 

levels(gbmimp.m$X1)</code></pre>
<pre><code>## [1] &quot;BlkDensity&quot; &quot;pctCov&quot;     &quot;pctRocks&quot;   &quot;pctRuf&quot;     &quot;slope&quot;     
## [6] &quot;sp30&quot;       &quot;wp30&quot;</code></pre>
<pre class="r"><code>gbmimp.m$X1 &lt;- factor(gbmimp.m$X1, levels = gbmimp.av.o$X1) #refactor to make levels equal to those we just made that are in order
plotmeans(value~ X1, data =gbmimp.m, connect=F, n.label=F, xlab = &#39;&#39;, ylab = &#39;Chuck&#39;, main = &#39;Chuck GBM Models&#39;, las=2)</code></pre>
<pre><code>## Warning in arrows(x, li, x, pmax(y - gap, li), col = barcol, lwd = lwd, :
## zero-length arrow is of indeterminate angle and so skipped

## Warning in arrows(x, li, x, pmax(y - gap, li), col = barcol, lwd = lwd, :
## zero-length arrow is of indeterminate angle and so skipped

## Warning in arrows(x, li, x, pmax(y - gap, li), col = barcol, lwd = lwd, :
## zero-length arrow is of indeterminate angle and so skipped

## Warning in arrows(x, li, x, pmax(y - gap, li), col = barcol, lwd = lwd, :
## zero-length arrow is of indeterminate angle and so skipped</code></pre>
<pre><code>## Warning in arrows(x, ui, x, pmin(y + gap, ui), col = barcol, lwd = lwd, :
## zero-length arrow is of indeterminate angle and so skipped

## Warning in arrows(x, ui, x, pmin(y + gap, ui), col = barcol, lwd = lwd, :
## zero-length arrow is of indeterminate angle and so skipped

## Warning in arrows(x, ui, x, pmin(y + gap, ui), col = barcol, lwd = lwd, :
## zero-length arrow is of indeterminate angle and so skipped

## Warning in arrows(x, ui, x, pmin(y + gap, ui), col = barcol, lwd = lwd, :
## zero-length arrow is of indeterminate angle and so skipped</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-48-1.png" width="672" /></p>
</div>
<div id="now-we-need-to-look-into-our-variable-importance-further-by-checking-the-response-curves.-these-trends-should-me-unimodel-and-be-able-to-be-explained-biologically.-flatlines-are-dead-to-your-model." class="section level5">
<h5>Now we need to look into our variable importance further by checking the response curves. These trends should me unimodel and be able to be explained biologically. Flatlines are “dead” to your model.</h5>
<pre class="r"><code>myMods &lt;- BIOMOD_LoadModels(myBiomodModelOut, models= c(&#39;RF&#39;,&#39;GBM&#39;), run.eval=&quot;RUN5&quot;)
response.plot2(models = myMods,
               Data = get_formal_data(myBiomodModelOut,&#39;expl.var&#39;),
               show.variables=       get_formal_data(myBiomodModelOut,&#39;expl.var.names&#39;),
               do.bivariate = FALSE,
               fixed.var.metric = &#39;median&#39;,
               col = c(&quot;blue&quot;, &quot;red&quot;),
               legend = TRUE,
               data_species = get_formal_data(myBiomodModelOut,&#39;resp.var&#39;))</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-49-1.png" width="672" /></p>
</div>
<div id="it-appears-that-pctrocks-is-consistently-the-least-important-variable." class="section level5">
<h5>It appears that pctRocks is consistently the least important variable.</h5>
<div id="considering-our-species-is-typically-found-in-rocky-areas-and-boulder-fields-this-may-set-off-some-red-flags.-perhaps-you-should-dive-deeper-into-the-environmental-variables-there-may-be-an-issue-with-this-layer" class="section level6">
<h6>…considering our species is typically found in rocky areas and boulder fields this may set off some red flags. Perhaps you should dive deeper into the environmental variables, there may be an issue with this layer!</h6>
</div>
</div>
<div id="now-that-weve-determined-which-runs-and-algorithms-look-best-we-can-create-prediction-surfaces." class="section level5">
<h5>Now that we’ve determined which runs and algorithms look best, we can create prediction surfaces.</h5>
<pre class="r"><code>myBiomodProj &lt;- BIOMOD_Projection(
  modeling.output = myBiomodModelOut,
  new.env = env,
  proj.name = &#39;Chuckwalla_proj&#39;, 
  selected.models = c(&#39;Chuckwalla_AllData_RUN5_GBM&#39;,&#39;Chuckwalla_AllData_RUN5_RF&#39;), 
  binary.meth = NULL, 
  compress = &#39;xz&#39;, 
  clamping.mask = F, 
  output.format = &#39;.img&#39;)</code></pre>
<pre><code>## 
## -=-=-=-=-=-=-=-=-=-=-=-=-= Do Models Projections -=-=-=-=-=-=-=-=-=-=-=-=-=
## 
##  &gt; Building clamping mask
## 
## *** in setMethod(&#39;BinaryTransformation&#39;, signature(data=&#39;RasterLayer&#39;)
## *** in setMethod(&#39;BinaryTransformation&#39;, signature(data=&#39;RasterLayer&#39;)
## *** in setMethod(&#39;BinaryTransformation&#39;, signature(data=&#39;RasterLayer&#39;)
## *** in setMethod(&#39;BinaryTransformation&#39;, signature(data=&#39;RasterLayer&#39;)
## *** in setMethod(&#39;BinaryTransformation&#39;, signature(data=&#39;RasterLayer&#39;)
## *** in setMethod(&#39;BinaryTransformation&#39;, signature(data=&#39;RasterLayer&#39;)
## *** in setMethod(&#39;BinaryTransformation&#39;, signature(data=&#39;RasterLayer&#39;)
## *** in setMethod(&#39;BinaryTransformation&#39;, signature(data=&#39;RasterLayer&#39;)
## *** in setMethod(&#39;BinaryTransformation&#39;, signature(data=&#39;RasterLayer&#39;)
## *** in setMethod(&#39;BinaryTransformation&#39;, signature(data=&#39;RasterLayer&#39;)
## *** in setMethod(&#39;BinaryTransformation&#39;, signature(data=&#39;RasterLayer&#39;)
## *** in setMethod(&#39;BinaryTransformation&#39;, signature(data=&#39;RasterLayer&#39;)
## *** in setMethod(&#39;BinaryTransformation&#39;, signature(data=&#39;RasterLayer&#39;)
## *** in setMethod(&#39;BinaryTransformation&#39;, signature(data=&#39;RasterLayer&#39;)
##  &gt; Projecting Chuckwalla_AllData_RUN5_GBM ...
##  &gt; Projecting Chuckwalla_AllData_RUN5_RF ...
## -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= Done -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=</code></pre>
<pre class="r"><code>myBiomodProj</code></pre>
<pre><code>## 
## -=-=-=-=-=-=-=-=-=-=-=-= &#39;BIOMOD.projection.out&#39; -=-=-=-=-=-=-=-=-=-=-=-=
## 
## Projection directory : Chuckwalla/Chuckwalla_proj
## 
## 
## sp.name : Chuckwalla
## 
## expl.var.names : BlkDensity pctCov pctRocks pctRuf slope sp30 wp30
## 
## 
## modeling id : test ( Chuckwalla/Chuckwalla.test.models.out )
## 
## models projected : 
## Chuckwalla_AllData_RUN5_GBM, Chuckwalla_AllData_RUN5_RF
## 
## -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=</code></pre>
</div>
<div id="next-get-the-rasters-out-and-plot-them." class="section level5">
<h5>Next, get the rasters out and plot them.</h5>
<pre class="r"><code>myCurrentProj &lt;- get_predictions(myBiomodProj)
class(myCurrentProj)</code></pre>
<pre><code>## [1] &quot;RasterStack&quot;
## attr(,&quot;package&quot;)
## [1] &quot;raster&quot;</code></pre>
<pre class="r"><code>plot(myCurrentProj)</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-51-1.png" width="672" /></p>
</div>
<div id="rescale-predictions-to-a-0-1-scale.-take-time-to-examine-your-model.-does-this-prediction-surface-make-sense-based-on-your-prior-knowledge-for-this-species" class="section level5">
<h5>Rescale predictions to a 0-1 scale. Take time to examine your model. Does this prediction surface make sense based on your prior knowledge for this species?</h5>
<pre class="r"><code>GBM_pred &lt;-myCurrentProj[[1]]/1000
RF_pred &lt;-myCurrentProj[[2]]/1000

plot(GBM_pred)</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-52-1.png" width="672" /></p>
<pre class="r"><code>plot(RF_pred)</code></pre>
<p><img src="SDM_v6_files/figure-html/unnamed-chunk-52-2.png" width="672" /></p>
</div>
<div id="save-your-models-to-your-working-directory" class="section level5">
<h5>Save your models to your working directory!</h5>
<pre class="r"><code>#writeRaster(GBM_pred, &quot;&quot;)  ### insert file name to save 
#writeRaster(RF_pred, &quot;&quot;)</code></pre>
</div>
<div id="and-save-your-workspace" class="section level5">
<h5>And save your workspace!</h5>
<pre class="r"><code>save.image(&quot;Chuckspace.RData&quot;)</code></pre>
</div>
<div id="see-the-minilab-code-if-you-want-to-create-an-ensemble-model-that-combines-the-results-from-the-rf-and-gbm-sdms." class="section level4">
<h4>See the MiniLab Code if you want to create an Ensemble Model that combines the results from the RF and GBM SDMs.</h4>
<div id="hey-you-just-created-a-species-distribution-model-now-go-home-and-drink-wine-and-celebrate" class="section level5">
<h5>Hey! You just created a species distribution model! Now go home and drink wine and celebrate!</h5>
<p><img src="wine.jpg" width="590" /></p>
</div>
</div>
</div>
<div id="references-and-useful-resources" class="section level2">
<h2>References and useful resources:</h2>
<p>Araújo, Miguel B., and Antoine Guisan (2006) Five (or so) Challenges for Species Distribution Modelling. Journal of Biogeography 33 (10): 1677–88.</p>
<p>Barbet-Massin, Morgane, Frédéric Jiguet, Cécile Hélène Albert, and Wilfried Thuiller (2012) Selecting Pseudo-Absences for Species Distribution Models: How, Where and How Many?: How to Use Pseudo-Absences in Niche Modelling? Methods in Ecology and Evolution 3 (2): 327–38.</p>
<p>Buckley, Lauren B., Mark C. Urban, Michael J. Angilletta, Lisa G. Crozier, Leslie J. Rissler, and Michael W. Sears (2010) Can Mechanism Inform Species’ Distribution Models?: Correlative and Mechanistic Range Models. Ecology Letters, 13:1041-1054.</p>
<p>Elith, Jane, and John R. Leathwick (2009) Species Distribution Models: Ecological Explanation and Prediction Across Space and Time. Annual Review of Ecology, Evolution, and Systematics 40 (1): 677–97.</p>
<p>Franklin, Janet (2009) Mapping Species Distributions: Spatial Inference and Prediction. Cambridge, UK: Cambridge University Press.</p>
<p>Guisan, Antoine, and Wilfried Thuiller (2005) Predicting Species Distribution: Offering More than Simple Habitat Models. Ecology Letters 8 (9): 993–1009.</p>
<p>Guisan, Antoine, and Niklaus E. Zimmermann (2000) Predictive Habitat Distribution Models in Ecology. Ecological Modelling 135 (2–3): 147–86.</p>
<p>Kearney, M. 2006. Habitat, environment and niche: what are we modeling? Oikos 115: 186-191.</p>
<p>Liu, C., M. White and G. Newell. 2018. Measuring and comparing the accuracy of species distribution models with presence–absence data. Ecography 34 (2), 232-243.</p>
<p>Lobo, J.M., A. Jiménez-Valverde, and R. Real, (2008), AUC: a misleading measure of the performance of predictive distribution models. Global Ecology and Biogeography, 17, 145-151.</p>
<p>Nussear, Kenneth E., Todd C. Esque, Richard D. Inman, Leila Gass, Kathryn A. Thomas, Cynthia S.A. Wallace, Joan B. Blainey, David M. Miller, and Robert H. Webb (2009) Modeling Habitat of the Desert Tortoise (Gopherus agassizii) in the Mojave and Parts of the Sonoran Deserts of California, Nevada, Utah, and Arizona. U.S. Geological Survey open-file report 2009-1102, 18 pp.</p>
<p>Thuiller, Wilfried &amp; Georges, D &amp; Engler, R. 2014. biomod2: Ensemble platform for species distribution modelling. 2. Version 3.3-7.1.</p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
