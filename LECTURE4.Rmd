---
title: "Likelihood!"
author: "NRES 746"
date: "September 18, 2016"
output: 
  html_document: 
    theme: cerulean
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```


In the last class, we talked about simulating data from models. This is often called *forward* modeling- that is, we take a model and use it to predict emergent patterns. The process flow goes something like this:

$Model \rightarrow Data$

In this class, we will talk about *inference* using the method of **maximum likelihood**. Inference is in some ways the opposite process (sometimes called *inverse* modeling). We are using the data to say something about the model. 

$Data \rightarrow Model$

In many ways, these two processes -- *simulation* and *inference* -- are inter-related. Simulation can help us to make better inferences, and inference can help us to construct better simulation models!

Let's see how simulation can help us to make inference. This leads directly into the core idea of maximum likelihood!

## Using data simulation to make inferences

Let's use the "mtcars" data for this example: (note: some code borrowed from [here](http://stats.stackexchange.com/questions/142443/simple-non-linear-regression-problem))

```{r echo=FALSE}
data(mtcars)

plot(mpg~disp, data = mtcars, las = 1, pch = 16, xlab = "Displacement", ylab = "Miles/Gallon")



```


Looks nonlinear, with relatively constant variance across parameter space. So let's see if we can build a model that could possibly produce these data!!

Since this looks a little like an exponential decline, let's first build a function that can generate data that follows that deterministic function:

$mpg = N\left \{  intercept\cdot e^{slope\cdot displacement} ,Variance\right \}$

Or, if we package the parameters simply as params a, b, and c:

$mpg = N\left \{  a\cdot e^{b\cdot displacement} ,c\right \}$

```{r}

Deterministic_component <- function(xvals,a,b){
  yexp <- a*exp(b*xvals)
  return(yexp)
}

DataGenerator_exp <- function(xvals,params){
  yexp <- Deterministic_component(xvals,params$a,params$b)  # get signal
  yvals <- rnorm(length(yexp),yexp,sqrt(params$c))     # add noise
  return(yvals)
}

```

Let's test this function to see if it does what we want:

```{r}

xvals=mtcars$disp    # xvals same as data (this is a "fixed effect", so there is no random component here- we can't really "sample" x values)
params <- list()  
params$a=30
params$b=-0.005
params$c=1

yvals <- DataGenerator_exp(xvals,params)

plot(yvals~xvals)


```


Okay, looks reasonable. Now, let's write a function to generate multiple replicate datasets from a particular model and plot out the barplots across measured parameter space.

```{r}

PlotRangeOfPlausibleData <- function(xvals,params,reps){ 
  samplesize <- length(xvals)
  results <- array(0,dim=c(samplesize,reps))   # storage array for results
  for(i in 1:reps){
    yvals <- DataGenerator_exp(xvals,params)
    results[,i] <- yvals
  }
      # now make a boxplot of the results
  boxplot(lapply(1:nrow(results), function(i) results[i,]),at=xvals, xaxt="n",main="Plausible data under this model",ylab="mpg",xlab="Displacement",boxwex=6)
  cleanseq <- (seq(0,max(round(xvals/100)),length=(max(round(xvals/100)))+1))*100
  axis(1,at=cleanseq,labels = cleanseq)    # label the x axis properly
  
}

```


Let's try it out!

```{r}
reps <- 1000    # number of replicate datasets to generate

PlotRangeOfPlausibleData(xvals,params,reps)

```


Now we can overlay the data and see how well we did!

```{r}
real_yvals <- mtcars$mpg
PlotRangeOfPlausibleData(xvals,params,reps)
points(xvals,real_yvals,pch=20,cex=3,col="green")
```


Okay, not very good yet. Let's see if we can improve this by changing the parameters. Let's increase the intercept and reduce the slope:

```{r}
params$a=40       # was 30
params$b=-0.001   # was 0.005

    
PlotRangeOfPlausibleData(xvals,params,reps)
points(xvals,real_yvals,pch=20,cex=3,col="green")    # overlay the real data

```


Oops- we overshot!! Let's find something in the middle!

```{r}
params$a=33       # was 40
params$b=-0.002   # was 0.001

    
PlotRangeOfPlausibleData(xvals,params,reps)
points(xvals,real_yvals,pch=20,cex=3,col="green")    # overlay the real data
```


Much better! This model could plausibly generate most of these data!

So, we have used simulation, along with trial and error, to infer parameter values for our model!


## Using data *likelihood* to make inferences

First of all, what does "data likelihood" really mean?  Formally,

$\pounds (Model|obs.data) \equiv  Prob(obs.data|Model)$

### Definition, in plain English!

The likelihood of a set of parameters $\theta $ given some observed data is equal to the *probability* of observing these data given those particular parameter values. In this way, likelihood is a quantitative measure of *goodness-of-fit*. Higher likelihoods correspond to a higher probability of the model producing the observed data.  

### Worked example

Let's go through an example! For simplicity, let's stick with the cars example for now. 

For simplicity, let's consider only the first observation:

```{r}

obs.data <- mtcars[1,c("mpg","disp")]
obs.data

```


Remember, we are considering the following data generating model:

$mpg = N\left \{  a\cdot e^{b\cdot displacement} ,c\right \}$

Let's assume for a second that the parameters we selected in our trial-and-error exercise above are the true parameters. What is the expected value of our observation under this data generating model.

```{r}
############
# "best fit" parameters from above
############

params$a=33       # was 40
params$b=-0.002   # was 0.001
params$c=1

params

expected_val <- Deterministic_component(obs.data$disp,params$a,params$b)
expected_val

```


Okay we now know our expected (mean) value for mpg for a car with displacement of 160 cubic inches. We also know the observed mpg for a car with a displacement of 160 cubic inches: it was 21 mpgs. Since the model also specifies the variance (1) we can compute the probability of observing a car with 21 mpgs under our model.

```{r}
mean = expected_val   # 23.96
stdev = sqrt(params$c)

curve(dnorm(x,mean,stdev),18,30,xlab="mpg",ylab="probability density")   # probability density
abline(v=obs.data$mpg,col="red",lwd=2)

```


Now it is straightforward to compute the likelihood. We just need to know the probability density where the red line (observed data) intersects with the normal density curve above:

```{r}
likelihood = dnorm(obs.data$mpg,mean,stdev)
likelihood
```


Now let's consider a second observation as well!

```{r}

obs.data <- mtcars[c(1,3),c("mpg","disp")]
obs.data

par(mfrow=c(1,2))  # set up graphics!

for(i in 1:nrow(obs.data)){
  curve(dnorm(x,Deterministic_component(obs.data$disp[i],params$a,params$b),sqrt(params$c)),18,30,xlab="mpg",ylab="probability density")   # probability density
  abline(v=obs.data$mpg[i],col="red",lwd=2)
}

graphics.off()

```


What is the likelihood of observing both of these data points???

```{r}

```


Let's consider four observations:

```{r}

```


What is the combined likelihood of all of these data points, assuming each observation is independent...

```{r}

```









