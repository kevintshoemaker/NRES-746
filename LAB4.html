<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="NRES 746" />


<title>Lab Exercise 4</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cerulean.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">NRES 746</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Schedule
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="schedule.html">Course Schedule</a>
    </li>
    <li>
      <a href="labschedule.html">Lab Schedule</a>
    </li>
    <li>
      <a href="Syllabus2.pdf">Syllabus</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Lectures
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="INTRO.html">Introduction to NRES 746</a>
    </li>
    <li>
      <a href="LECTURE1.html">Why focus on algorithms?</a>
    </li>
    <li>
      <a href="LECTURE2.html">Working with probabilities</a>
    </li>
    <li>
      <a href="LECTURE3.html">The Virtual Ecologist</a>
    </li>
    <li>
      <a href="LECTURE4.html">Likelihood</a>
    </li>
    <li>
      <a href="LECTURE5.html">Optimization</a>
    </li>
    <li>
      <a href="LECTURE6.html">Bayesian #1: concepts</a>
    </li>
    <li>
      <a href="LECTURE7.html">Bayesian #2: mcmc</a>
    </li>
    <li>
      <a href="LECTURE8.html">Model Selection</a>
    </li>
    <li>
      <a href="LECTURE9.html">Performance Evaluation</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Lab exercises
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="LAB1.html">Lab 1: Algorithms in R</a>
    </li>
    <li>
      <a href="FINALPROJ.html">Final project overview</a>
    </li>
    <li>
      <a href="LAB2.html">Lab 2: Virtual ecologist</a>
    </li>
    <li>
      <a href="LAB3.html">Lab 3: Likelihood</a>
    </li>
    <li>
      <a href="LAB4.html">Lab 4: Bayesian inference</a>
    </li>
    <li>
      <a href="LAB5.html">Lab 5: Model selection (optional)</a>
    </li>
    <li>
      <a href="FigureDemo.html">Demo: Figures in R</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Student-led topics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="TimeSeries.html">Time-series analysis</a>
    </li>
    <li>
      <a href="SEM.html">Structural Equation Models</a>
    </li>
    <li>
      <a href="SpatialAutocorrelation.html">Spatial Autocorrelation</a>
    </li>
    <li>
      <a href="BayesianNetworks.html">Bayesian Networks</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Data sets
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="TreeData.csv">Tree Data</a>
    </li>
    <li>
      <a href="ReedfrogPred.csv">Reed Frog Predation Data</a>
    </li>
    <li>
      <a href="ReedfrogFuncresp.csv">Reed Frog Func Resp</a>
    </li>
  </ul>
</li>
<li>
  <a href="Links.html">Links</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Lab Exercise 4</h1>
<h4 class="author"><em>NRES 746</em></h4>
<h4 class="date"><em>Fall 2018</em></h4>

</div>


<p>As with all lab reports, your answers will either take the form of R functions or short written responses (submitted together in a Word document). The R functions should be stored in an R script file (‘.R’ extension). To allow me to evaluate your work more efficiently, please name your R script using the following convention: “[your first name]_[your last name]_lab4.R“. So my submission would be”kevin_shoemaker_lab4.R“. The name of your Word docuement doesn’t matter, as long as you submit via WebCampus.</p>
<p>Please submit the R script and the Word document via WebCampus by midnight on the due date (one week after the final lab session allocated for this topic – here, <em>Nov. 21, 2018</em>). You can work in groups but please submit the materials individually.</p>
<p>First, take a little time to review the <a href="LECTURE6.html">Bayesian lecture</a> and <a href="LECTURE7.html">MCMC lecture</a>!</p>
<p><strong>Lab 4 is due before midnight on Tuesday November 21</strong></p>
<div id="bayesian-inference-with-bugs" class="section level1">
<h1>Bayesian inference (with BUGS!)</h1>
<p>NOTE: thanks to Dr. Elizabeth Hunter (formerly a postdoc in the Applied Population Ecology lab) for putting together much of this lab!</p>
<p>If you haven’t already installed JAGS on your computer, use <a href="http://mcmc-jags.sourceforge.net/">this link</a></p>
<p>In this lab we will be applying a Bayesian approach to model fitting using the same myxomatosis dataset and model that we used in the previous likelihood lab. To do this, we’ll be using the program JAGS (<strong>J</strong>ust <strong>A</strong>nother <strong>G</strong>ibbs <strong>S</strong>ampler).</p>
<p>JAGS runs seamlessly with R, if you download the “R2jags” package or the “jagsUI” package! JAGS is not the only way to do Bayesian analyses, nor is it the only implementation of the BUGS (Bayesian inference Using Gibbs Sampler) language. Others that you may have heard of include WinBUGS and OpenBUGS. STAN is another widely used software for Bayesian inference, that doesn’t use the BUGS language…</p>
<p>To familiarize ourselves with the BUGS language, let’s look at some BUGS code (for our favorite myxomatosis dataset).</p>
<pre><code>
#############
# sample BUGS code       

model {
      
      #############
      # LIKELIHOOD
      ############
      for(obs in 1:n.observations){
        titer[obs] ~ dgamma(shape,rate)
      }
      
      #############
      # PRIORS
      ############
      shape ~ dgamma(0.01,0.01)
      scale ~ dgamma(0.001,0.001)
      rate &lt;- 1/scale   # in BUGS, gamma distribution needs a &quot;rate&quot; parameter rather than a scale 
    }
    </code></pre>
<p>The syntax in BUGS/JAGS is very similar to R, but there are a few key differences. Most important, <em>assignment must always be done by the arrow (&lt;-) instead of an equals sign</em> for deterministic functions and the <em>tilde (~) is used to define stochastic processes</em>.</p>
<p>In the model code, you must also specify your priors. Here we are using relatively vague priors, meaning that the probability is spread out fairly evenly over parameter space. The Gamma distribution is always parameterized as shape and rate in BUGS (rate = 1/scale). If you wanted to see what this distribution looked like, you could plot in R (‘dgamma()’ allows you to specify a rate or a scale parameter):</p>
<pre class="r"><code>par(mfrow=c(2,1))
curve(dgamma(x, shape=0.01, rate=0.01),3,100,ylim=c(0,0.1),xlab=&quot;shape parameter&quot;,ylab=&quot;probability density&quot;, main=&quot;Prior&quot;)
curve(dgamma(x, shape=0.001, rate=0.001),0.01,0.5,ylim=c(0,1),xlab=&quot;scale parameter&quot;,ylab=&quot;probability density&quot;)</code></pre>
<p><img src="LAB4_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>In this case we want a prior distribution that has little to no information about which values of the parameter are most probable. These distributions have no peaks within the range of parameter space of interest, and the probability for any particular x-value is very low, so it does a fairly good job of representing a vague prior for the shape and rate parameters.</p>
<div id="running-jags-through-r" class="section level2">
<h2>Running JAGS through R</h2>
<div id="setting-up-the-model" class="section level3">
<h3>Setting up the model!</h3>
<p>We can use the R2JAGS package in R to run JAGS through R and have the output returned to R so that we can analyze and manipulate it further.</p>
<p>First, install and load the R2jags package. While you’re at it, install and load the coda package, which has some great utilities for visualizing and working with MCMC data.</p>
<pre class="r"><code>### load key packages for running Bayesian analysis in JAGS

library(R2jags)</code></pre>
<pre><code>## Loading required package: rjags</code></pre>
<pre><code>## Loading required package: coda</code></pre>
<pre><code>## Linked to JAGS 4.2.0</code></pre>
<pre><code>## Loaded modules: basemod,bugs</code></pre>
<pre><code>## 
## Attaching package: &#39;R2jags&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:coda&#39;:
## 
##     traceplot</code></pre>
<pre class="r"><code>library(coda)</code></pre>
</div>
<div id="writing-out-the-model" class="section level3">
<h3>Writing out the model</h3>
<p>We can use the ‘cat’ function in R to write out a text file- it can be useful to use this functionality to embed the JAGS code within our R script!</p>
<pre class="r"><code>filename &lt;- &quot;BUGSmodel.txt&quot;
cat(&quot;
    model {
      
      #############
      # LIKELIHOOD
      ############
      for(obs in 1:n.observations){
        titer[obs] ~ dgamma(shape,rate)
      }
      
      #############
      # PRIORS
      ############
      shape ~ dgamma(0.01,0.01)
      scale ~ dgamma(0.001,0.001)
      rate &lt;- 1/scale
    }
  &quot;,file=filename
)</code></pre>
</div>
<div id="packaging-the-data" class="section level3">
<h3>Packaging the data</h3>
<p>We will need to tell BUGS/JAGS what the data are. To be read into JAGS (via the R2JAGS package), the data need to be bundled together in a list. The data need to have the same names as specified in the model file:</p>
<p>First we get the data we want into R (we know the drill!):</p>
<pre class="r"><code>library(emdbook)

MyxDat &lt;- MyxoTiter_sum
Myx &lt;- subset(MyxDat,grade==1)  #Data set from grade 1 of myxo data
head(Myx)</code></pre>
<pre><code>##   grade day titer
## 1     1   2 5.207
## 2     1   2 5.734
## 3     1   2 6.613
## 4     1   3 5.997
## 5     1   3 6.612
## 6     1   3 6.810</code></pre>
<p>Then we package the data as a list, which is what JAGS wants!</p>
<pre class="r"><code>myx.data.for.bugs &lt;- list(
  titer = Myx$titer,
  n.observations = length(Myx$titer)
)

myx.data.for.bugs</code></pre>
<pre><code>## $titer
##  [1] 5.207 5.734 6.613 5.997 6.612 6.810 5.930 6.501 7.182 7.292 7.819
## [12] 7.489 6.918 6.808 6.235 6.916 4.196 7.682 8.189 7.707 7.597 7.112
## [23] 7.354 7.158 7.466 7.927 8.499
## 
## $n.observations
## [1] 27</code></pre>
</div>
<div id="setting-the-initial-values-for-our-markov-chains" class="section level3">
<h3>Setting the initial values for our Markov chain(s)</h3>
<pre class="r"><code>init.vals.for.bugs &lt;- function(){
  list(
    shape=runif(1,20,100),
    scale=runif(1,0.05,0.3)
  )
}
init.vals.for.bugs()</code></pre>
<pre><code>## $shape
## [1] 21.75969
## 
## $scale
## [1] 0.1841536</code></pre>
<pre class="r"><code>init.vals.for.bugs()</code></pre>
<pre><code>## $shape
## [1] 75.07833
## 
## $scale
## [1] 0.2878559</code></pre>
<p>Alternatively, we can specify exact initial values for our chains (in this case, we initialize three Markov chains)</p>
<pre class="r"><code>inits = list(list(shape=90,scale=0.1), list(shape=50,scale=0.2), list(shape=150,scale=0.04))  # a list of lists!</code></pre>
<p>Note that we need three different sets of starting values here because we are running three different chains. Recall that initial values are required, and you may want to use the same tricks as we have used before (e.g., method of moments) to identify reasonable starting values. JAGS will not work if you specify unreasonable initial parameters (and it won’t necessarily tell you that is the problem).</p>
<p>Now we’ll run this model through JAGS:</p>
<pre class="r"><code>params.to.store &lt;- c(&quot;shape&quot;,&quot;scale&quot;)    # specify the parameters we want to get the posteriors for

jags.fit &lt;- jags(data=myx.data.for.bugs,inits=init.vals.for.bugs,parameters.to.save=params.to.store,n.iter=50000,model.file=&quot;BUGSmodel.txt&quot;,n.chains = 3,n.burnin = 5000,n.thin = 20 )</code></pre>
<pre><code>## module glm loaded</code></pre>
<pre><code>## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 27
##    Unobserved stochastic nodes: 2
##    Total graph size: 37
## 
## Initializing model</code></pre>
<pre class="r"><code>jags.fit</code></pre>
<pre><code>## Inference for Bugs model at &quot;BUGSmodel.txt&quot;, fit using jags,
##  3 chains, each with 50000 iterations (first 5000 discarded), n.thin = 20
##  n.sims = 6750 iterations saved
##          mu.vect sd.vect   2.5%    25%    50%    75%  97.5%  Rhat n.eff
## scale      0.163   0.047  0.092  0.130  0.156  0.188  0.273 1.008   310
## shape     45.927  12.697 25.359 36.843 44.531 53.218 75.263 1.008   310
## deviance  77.433   2.033 75.381 75.953 76.822 78.251 82.729 1.006   570
## 
## For each parameter, n.eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor (at convergence, Rhat=1).
## 
## DIC info (using the rule, pD = var(deviance)/2)
## pD = 2.1 and DIC = 79.5
## DIC is an estimate of expected predictive error (lower deviance is better).</code></pre>
<p>For each parameter, n.eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor (at convergence, Rhat=1).</p>
<p>DIC info (using the rule, pD = Dbar-Dhat) pD = 3.0 and DIC = 65.3 DIC is an estimate of expected predictive error (lower deviance is better).</p>
<p>You can see the means and variance for the parameters as well as the DIC for the model. We can summarize these in plots of the posterior distributions. First, we define the MCMC output as a ‘coda’ object (for storing, visualizing and analyzing MCMC results) that R knows how to work with.</p>
<pre class="r"><code>jagsfit.mcmc &lt;- as.mcmc(jags.fit)   # convert to &quot;MCMC&quot; object (coda package)

summary(jagsfit.mcmc)</code></pre>
<pre><code>## 
## Iterations = 5001:49981
## Thinning interval = 20 
## Number of chains = 3 
## Sample size per chain = 2250 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##             Mean       SD  Naive SE Time-series SE
## deviance 77.4325  2.03261 0.0247401       0.051262
## scale     0.1629  0.04717 0.0005741       0.002051
## shape    45.9274 12.69736 0.1545474       0.585941
## 
## 2. Quantiles for each variable:
## 
##              2.5%     25%     50%     75%   97.5%
## deviance 75.38071 75.9528 76.8218 78.2511 82.7285
## scale     0.09235  0.1297  0.1559  0.1883  0.2725
## shape    25.35857 36.8431 44.5312 53.2182 75.2633</code></pre>
<pre class="r"><code>plot(jagsfit.mcmc)</code></pre>
<p><img src="LAB4_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre class="r"><code>library(lattice)
densityplot(jagsfit.mcmc)</code></pre>
<p><img src="LAB4_files/figure-html/unnamed-chunk-9-2.png" width="672" /></p>
<p>You can visually check for convergence here, using the trace plots – a converged run will look like white noise and the samples will not be hitting any ceilings or floors.</p>
<div id="parameter-uncertainty-credible-intervals" class="section level4">
<h4>Parameter uncertainty: credible intervals</h4>
<p>We can estimate the 95% credible interval by calling directly from the bugs output. The “sims.list” part of the output has all of the MCMC samples that were created during the run.</p>
<pre class="r"><code>shape95 = quantile(jags.fit$BUGSoutput$sims.list$shape,c(0.025,0.975))
scale95 = quantile(jags.fit$BUGSoutput$sims.list$scale,c(0.025,0.975))
shape95</code></pre>
<pre><code>##     2.5%    97.5% 
## 25.35857 75.26332</code></pre>
<pre class="r"><code>scale95</code></pre>
<pre><code>##       2.5%      97.5% 
## 0.09235442 0.27253294</code></pre>
<p>The probability that the <em>a</em> parameter is between these 2 numbers is actually 95%!</p>
<p>So, what’s so great about this? Using a vague prior, we get almost the exact same parameter estimates that we did when we just did a straight up likelihood model. This is usually the case with simple models like the run we ran here. However, answers can be quite different with more complicated models, and in fact the Bayesian approach allows us to simultaneously fit complex models that we could not do effectively using likelihood-based approaches.</p>
<p>That said, there are 2 main advantages to the Bayesian approach, both having to do with the fact that the answer comes in the form of a probability distribution instead of a point estimate.</p>
<p>First, the credible interval is much nicer to interpret than a confidence interval. There’s none of this “given that the null hypothesis is true, and we were to resample the data 100 times…”. You can state simply that there’s a 95% probability that the value of the parameter lies within the credible interval. Period.</p>
<p>Second, and more importantly from a pragmatic standpoint (i.e., for running simulations), you can draw from these parameter probability distributions to create simulations that include the full variability of outcomes instead of just point estimates, which will demonstrate the implications of your parameter estimates (e.g. under different management scenarios, climate change, etc.). We’ll explore how to do this a little later.</p>
</div>
<div id="challenge-problem-1-myxomatosis-analysis-in-jags-1-ricker-deterministic-function" class="section level4">
<h4>Challenge problem 1: Myxomatosis analysis in JAGS #1: Ricker deterministic function</h4>
<ul>
<li><p><strong>Exercise 1a</strong>. Write a function called “Myx_Ricker_JAGS()” that runs the Myxomatosis/Ricker example from the previous (likelihood) lab in JAGS. Recall that we are modeling titer levels (grade 1 only) as a function of the days since infection. Submit this function as part of your R script.</p>
<ul>
<li><strong>input</strong>:
<ul>
<li>data = a matrix of 2 columns and one row per observation. The first column should represent the days since infection, and the second column should represent the virus titer.</li>
<li>JAGScode = a text string, representing the file name for your JAGS code</li>
<li>CImethod = a text string, representing whether the CI should be computed using the quantile method (“quantile”) or the HPD method (“HPD”). See the Bayesian lecture for more information.<br />
</li>
<li>CIlevel = a number from 0 to 1 indicating what confidence level you want for the CI: set the default value to 0.95.</li>
</ul></li>
<li><strong>suggested algorithm</strong>:
<ul>
<li>Package the data for JAGS (store as a list object)<br />
</li>
<li>Write a function that returns a list for initializing the MCMC chains<br />
</li>
<li>Run the ‘jags’ function with 3 chains, specifying the parameters for which you want the posterior distribution, and store the results as an object.<br />
</li>
<li>use the ‘as.mcmc()’ function to convert the results to a ‘coda’ object, and store the results as a separate object.</li>
<li>Display the trace plots and density plots for the three parameters.</li>
<li>Plot the data (days on x axis and titer on y axis), and overlay the Ricker curve, with Bayesian point estimates, on the data to evaluate fit.<br />
</li>
<li>compute the posterior mean for the a, b and shape params and store as a vector.</li>
<li>compute the credible interval (CI) for the three parameters using either the quantile method or the HPD method (as requested by the user), and store as a 2x3 matrix (see below). HINT: use the ‘HDInterval’ package to help compute the HPD.<br />
</li>
<li>compute the Gelman-Rubin diagnostic (‘gelman.diag’ function) using the ‘coda’ version of the JAGS results.</li>
</ul></li>
<li><strong>return</strong>:
<ul>
<li>a list of length 3 containing (1) a vector of point estimates (posterior mean) for parameters a, b, and shape, (2) a matrix with 2 rows and 3 columns, containing the 95% credible interval (row 1 is the lower bound, row 2 is the upper bound, columns represent parameters a, b, and shape), and (3) a scalar (floating-point number) representing the Gelman-Rubin diagnostic- a tool for assessing MCMC convergence.</li>
</ul></li>
</ul></li>
</ul>
<p>Here is an example of the results you should expect to see when running your new function:</p>
<pre class="r"><code>Ricker_results &lt;- Myx_Ricker_JAGS(data=Myx[,-1],JAGScode=&quot;BUGSmodel_ricker.txt&quot;,CImethod=&quot;HPD&quot;,CIlevel=0.88)</code></pre>
<pre><code>## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 27
##    Unobserved stochastic nodes: 3
##    Total graph size: 124
## 
## Initializing model</code></pre>
<p><img src="LAB4_files/figure-html/test1a-1.png" width="672" /><img src="LAB4_files/figure-html/test1a-2.png" width="672" /><img src="LAB4_files/figure-html/test1a-3.png" width="672" /></p>
<pre class="r"><code>Ricker_results</code></pre>
<pre><code>## [[1]]
## [1]  3.5580664  0.1706747 78.5045677
## 
## [[2]]
##             a         b     shape
## [1,] 3.228456 0.1525693  44.14921
## [2,] 3.892765 0.1869516 110.22154
## 
## [[3]]
## [1] 1.001319</code></pre>
<pre class="r"><code>Ricker_results &lt;- Myx_Ricker_JAGS(data=Myx[,-1],JAGScode=&quot;BUGSmodel_ricker.txt&quot;,CImethod=&quot;quantile&quot;,CIlevel=0.88)</code></pre>
<pre><code>## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 27
##    Unobserved stochastic nodes: 3
##    Total graph size: 124
## 
## Initializing model</code></pre>
<p><img src="LAB4_files/figure-html/test1a-4.png" width="672" /><img src="LAB4_files/figure-html/test1a-5.png" width="672" /><img src="LAB4_files/figure-html/test1a-6.png" width="672" /></p>
<pre class="r"><code>Ricker_results</code></pre>
<pre><code>## [[1]]
## [1]  3.5495460  0.1702083 78.2604368
## 
## [[2]]
##             a         b     shape
## [1,] 3.225543 0.1530670  46.92557
## [2,] 3.897321 0.1877525 115.82354
## 
## [[3]]
## [1] 1.000541</code></pre>
<ul>
<li><p><strong>Exercise 1b</strong>. Can you identify any differences between the parameter estimates from the analysis in a likelihood vs Bayesian perspective? Compare your results from Lab 3, and briefly describe your findings in your Word document.</p></li>
<li><p><strong>Exercise 1c</strong>. Did your MCMC chains converge on the joint posterior distribution? Briefly explain your reasoning in your Word document! Use several lines of reasoning!</p></li>
</ul>
</div>
<div id="challenge-problem-2-myxomatosis-in-jags-with-michaelis-menten-function" class="section level4">
<h4>Challenge problem 2: Myxomatosis in JAGS with Michaelis-Menten function</h4>
<p>Recalling our plot (from the last lab) of the Ricker function with the maximum-likelihood parameter estimates drawn over the scatterplot of titers by day, there really isn’t much evidence in the data for that downward turn in the function after day 6. We chose a model that indicated decline in titer levels following a peak based on the behavior of other myxomytosis grades, but given the virulence of this particular grade most animals die once the titer levels reach their maximum. Might it be more appropriate to fit a model that levels off at some asymptote instead of declining following the peak? Let’s find out, using a little Bayesian model selection!</p>
<ul>
<li><strong>Exercise 2a</strong>. Repeat the myxomatosis example in BUGS/JAGS, but this time use the <strong>Michaelis-Menten function</strong>, which has the same number of parameters as the Ricker function, but increases to an asymptote (see below). Continue to use a Gamma distribution to describe the error! Please name your new function “Myx_MM_JAGS()”. The inputs and outputs should be the same as for “Myx_Ricker_JAGS()”. Please save this new function in your R script.</li>
</ul>
<p>And here is some test commands with output:</p>
<pre class="r"><code>MM_results &lt;- Myx_MM_JAGS(data=Myx[,-1],JAGScode=&quot;BUGSmodel_mm.txt&quot;,CImethod=&quot;HPD&quot;,CIlevel=0.88)</code></pre>
<pre><code>## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 27
##    Unobserved stochastic nodes: 3
##    Total graph size: 96
## 
## Initializing model</code></pre>
<p><img src="LAB4_files/figure-html/test2a-1.png" width="672" /><img src="LAB4_files/figure-html/test2a-2.png" width="672" /><img src="LAB4_files/figure-html/test2a-3.png" width="672" /></p>
<pre class="r"><code>MM_results</code></pre>
<pre><code>## [[1]]
## [1]  8.849332  1.202337 99.082658
## 
## [[2]]
##             a         b     shape
## [1,] 8.055208 0.7281408  54.09782
## [2,] 9.635765 1.6660165 137.65600
## 
## [[3]]
## [1] 1.001333</code></pre>
<pre class="r"><code>MM_results &lt;- Myx_MM_JAGS(data=Myx[,-1],JAGScode=&quot;BUGSmodel_mm.txt&quot;,CImethod=&quot;quantile&quot;,CIlevel=0.88)</code></pre>
<pre><code>## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 27
##    Unobserved stochastic nodes: 3
##    Total graph size: 96
## 
## Initializing model</code></pre>
<p><img src="LAB4_files/figure-html/test2a-4.png" width="672" /><img src="LAB4_files/figure-html/test2a-5.png" width="672" /><img src="LAB4_files/figure-html/test2a-6.png" width="672" /></p>
<pre class="r"><code>MM_results</code></pre>
<pre><code>## [[1]]
## [1]  8.842838  1.196076 98.771297
## 
## [[2]]
##             a         b     shape
## [1,] 8.066653 0.7399619  59.12982
## [2,] 9.683495 1.6991870 145.05708
## 
## [[3]]
## [1] 1.002458</code></pre>
<ul>
<li><strong>Exercise 2b</strong>. In your Word document, please answer the following question: overlay both the best-fit M-M and the best-fit Ricker curves on a plot of the data. On the basis of simple visual cues, does the M-M function seem to fit better than the Ricker function to describe this relationship? Explain your reasoning.</li>
</ul>
<p>The M-M function looks like this:</p>
<p><span class="math inline">\(\frac{a\cdot x}{b+x}\)</span></p>
<pre class="r"><code>mm = function(x,a,b) { a*x / (b+x) }</code></pre>
<p>You can plot an M-M function over the points to get some initial parameter estimates.</p>
<pre class="r"><code>plot(Myx$titer~Myx$day,xlim=c(0,10),ylim=c(0,10))
curve(mm(x,a=5,b=0.8),from=0,to=10,add=T,col=&quot;red&quot;,lwd=2)</code></pre>
<p><img src="LAB4_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>And here is an example of what your figure should look like with the best-fit M-M and Ricker functions overlaid on the same plot:</p>
<p><img src="LAB4_files/figure-html/answer2b-1.png" width="672" /></p>
</div>
<div id="challenge-problem-3.-goodness-of-fit-and-model-comparison" class="section level4">
<h4>Challenge problem 3. Goodness-of-fit and model comparison</h4>
<p>Let’s try a different approach for visualizing the goodness-of-fit of these two models. For each of these models, use the pseudocode provided below to evaluate goodness-of-fit. On the basis of a <em>posterior predictive check</em> (see below), how well would you say each model fits the observed data? Do you see any red flags that would indicate poor goodness of fit? Explain your reasoning.</p>
<ul>
<li><p><strong>Exercise 3a</strong>. Write a function called “Myx_PostPredCheck()” that compares the goodness-of-fit for the two models (ricker vs M-M) using a posterior predictive check.</p>
<ul>
<li><strong>input</strong>:
<ul>
<li>MCMC1 = the object generated from running the ‘jags()’ function with the Ricker function.<br />
</li>
<li>MCMC2 = the object generated from running the ‘jags()’ function with the Michaelis-Menten function.</li>
</ul></li>
<li><strong>suggested algorithm</strong>:
<ul>
<li>For each model (Ricker, M-M), generate new data under the fitted model. For each of an arbitrarily large number (e.g., 1000) of replicates:
<ul>
<li>sample from the joint posterior distribution:
<ul>
<li>pick a random integer between 1 and the number of MCMC samples (e.g., call that number “random_index”)<br />
</li>
<li>Then, use that random index to select a single random sample from the joint posterior distribution.
<ul>
<li>This will look something like this: <code>new.draw &lt;- jags.fit$BUGSoutput$sims.list$a[random_index]</code><br />
</li>
</ul></li>
</ul></li>
<li>Use those parameters (drawn from the joint posterior distribution) to simulate a data set:
<ul>
<li>For each titer observation, and using the params sampled from the posterior, generate a single random number under the gamma distribution defined by the Ricker or M-M model</li>
</ul></li>
<li>Use a standard discrepancy metric–sum of squared error– to compute the degree to which the simulated data deviate from the expected value.
<ul>
<li>For each simulated data point, compute the squared residual error- that is, the squared difference between the simulated data point and the expected value from the Ricker or M-M model.</li>
<li>For each observed data point, compute the squared residual error- that is, the squared difference between the observed data point and the expected value from the Ricker or M-M model.</li>
</ul></li>
<li>Compute the sum of squared errors (across all observations) for both the observed data and the simulated data corresponding to each sample from the joint posterior distribution.<br />
</li>
</ul></li>
<li>For each model (Ricker, M-M), use the ‘boxplot()’ function to display the range of plausible data that could be generated under the fitted model (using the simulated data). Overlay the observed data. This provides a visual goodness-of-fit evaluation. Based on a visual inspection, how well does the model fit the data?</li>
<li>Plot the sum of squared error for the simulated data sets (Y axis) against the sum of squared error for the actual data set. Overlay a 1:1 line (that is, the line corresponding to y=x). This is called a <em>Posterior Predictive Check</em>.</li>
<li>Compute the percent of the time that the discrepancy metric (SSE) for the simulated data exceeds the discrepancy metric for the observed data. This quantity is often called a <em>Bayesian p-value</em>.</li>
</ul></li>
<li><strong>return</strong>:
<ul>
<li>a list of length 3 containing (1) a vector of length 2 storing the Bayesian p-values for the two models (Ricker first, then M-M), computed above, (2) a data frame with number of rows equal to the number of simulation replicates and columns indicating, respectively, the samples from the joint posterior, SSE for the simulated data, and SSE for the real observations (the data used to compute the Bayesian p-value) for the Ricker model, and (3) a data frame with number of rows equal to the number of simulation replicates and columns indicating, respectively, the samples from the joint posterior, SSE for the simulated data, and SSE for the real observations (the data used to compute the Bayesian p-value) for the M-M model.</li>
</ul></li>
</ul></li>
</ul>
<pre><code>## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 27
##    Unobserved stochastic nodes: 3
##    Total graph size: 124
## 
## Initializing model</code></pre>
<pre><code>## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 27
##    Unobserved stochastic nodes: 3
##    Total graph size: 96
## 
## Initializing model</code></pre>
<p>And here is what the results of your function should look like!</p>
<pre class="r"><code>####
# Test the function

test &lt;- Myx_PostPredCheck(MCMC1=jags.fit_ricker,MCMC2=jags.fit_mm)</code></pre>
<p><img src="LAB4_files/figure-html/test3a-1.png" width="672" /><img src="LAB4_files/figure-html/test3a-2.png" width="672" /><img src="LAB4_files/figure-html/test3a-3.png" width="672" /><img src="LAB4_files/figure-html/test3a-4.png" width="672" /></p>
<pre class="r"><code>test[[1]]   # p-vals</code></pre>
<pre><code>## [1] 0.705 0.710</code></pre>
<pre class="r"><code>head(test[[2]])    # ppc for ricker</code></pre>
<pre><code>##          a         b     shape   SSEsim   SSEobs
## 1 3.311911 0.1590790  51.76648 31.18700 12.28114
## 2 3.478372 0.1616519  79.73983 16.12649 14.01299
## 3 3.576797 0.1757514 101.09944 13.10784 12.73049
## 4 3.853098 0.1855804  55.19437 22.32965 14.01064
## 5 3.313795 0.1653687  76.79057 12.44802 13.39743
## 6 3.143208 0.1518573  59.65199 18.92697 13.00441</code></pre>
<pre class="r"><code>head(test[[3]])    # ppc for M-M</code></pre>
<pre><code>##          a         b     shape    SSEsim    SSEobs
## 1 9.022282 1.2210385  85.42037 25.634696  9.758478
## 2 8.694518 1.1180557  82.83445 15.750999  9.425513
## 3 8.558200 1.1301919  89.51961  8.126173  9.961551
## 4 8.285284 0.9114658  75.59386 13.406036 10.106081
## 5 8.320498 0.8453829 114.09760 12.620531 10.082585
## 6 8.087020 0.8994628  98.43096 12.884267 11.573921</code></pre>
<ul>
<li><strong>Exercise 3b</strong>. In your Word document, please explain how do you interpret the Bayesian p-value. What Bayesian p-value would you expect if the model fit was perfect? What would you expect if the model fit was poor? What does the Bayesian p-value tell us about how well the Ricker and M-M models fit the data? Does one model fit better than the other?</li>
</ul>
</div>
</div>
<div id="challenge-problem-4-extra-credit" class="section level3">
<h3>Challenge Problem 4 (extra credit)</h3>
<p>DIC (analogous to AIC) is a model selection criterion for Baysian models fitted with MCMC. Just like for AIC, models with smaller values of DIC are favored. Which model (M-M or Ricker) is the better model based on DIC? What does the difference in DIC mean in terms of the strength of evidence in support of one of these models as the “best model”? [You should be aware that DIC is not a perfect solution for Bayesian model selection. For one, it is only valid if the posterior is approximately multivariate normal. Also, DIC tends to select overfitted models!]</p>
<p>WAIC (also analogous to AIC) is a newer (and better) model selection criterion for Baysian models fitted with MCMC. Just like for AIC, models with smaller values of WAIC are favored. Which model (M-M or Ricker) is the better model based on WAIC? What does the difference in WAIC mean in terms of the strength of evidence in support of one of these models as the “best model”?</p>
<pre><code>## This is loo version 2.0.0.
## **NOTE: As of version 2.0.0 loo defaults to 1 core but we recommend using as many as possible. Use the &#39;cores&#39; argument or set options(mc.cores = NUM_CORES) for an entire session. Visit mc-stan.org/loo/news for details on other changes.</code></pre>
<pre><code>## Warning: 1 (3.7%) p_waic estimates greater than 0.4. We recommend trying
## loo instead.</code></pre>
<pre><code>## Warning: 2 (7.4%) p_waic estimates greater than 0.4. We recommend trying
## loo instead.</code></pre>
<p>Here are the results I got:</p>
<pre class="r"><code>DIC_ricker</code></pre>
<pre><code>## [1] 66.2235</code></pre>
<pre class="r"><code>DIC_MM</code></pre>
<pre><code>## [1] 59.70527</code></pre>
<pre class="r"><code>WAIC_ricker$estimates[&quot;waic&quot;,]</code></pre>
<pre><code>##  Estimate        SE 
## 66.159879  8.548989</code></pre>
<pre class="r"><code>WAIC_mm$estimates[&quot;waic&quot;,]</code></pre>
<pre><code>##  Estimate        SE 
## 59.865573  9.141202</code></pre>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
