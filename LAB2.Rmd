---
title: "Lab Exercise 2"
author: "NRES 746"
date: "Fall 2016"
output: 
  html_document: 
    theme: cerulean
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

## Final Projects

Take some time to start forming groups (2-3 people) for final projects.

### General expectations

I will provide a more formal list of expectations for final projects soon, but in a nutshell (and in no particular order), you are expected to perform and write up the results for a sophisticated data analysis using *state-of-the-art analytical methods*. The write-up will loosely take the format of a scientific paper to be submitted to a professional journal. However, because of the nature of this course, the most important pieces of the write-up are the methods and results sections. Nonetheless, I expect at least a few paragraphs introducing the topic and why it's important, and a few paragraphs discussing the implications of the results. The methods and results section can (and in many cases should) be much longer than you typically see in a scientific paper- don't feel constrained by space for these sections! Not that you need to be wordy, I just want to make sure you have the space to clearly explain the analyses you performed and why you made the choices you did.  

### Picking a topic

Your final project should not be part of your thesis. That said, there is no requirement that your final project is not *relevant* to your graduate thesis project. You will end up spending quite a bit of time on your final projects, so think about what types of analyses you want/need to get to know better- ideally something that may strengthen your thesis project. 

### Picking a dataset

You are not required to use a public dataset, but there are lots of great datasets out there... see [links page](https://kevintshoemaker.github.io/NRES-746/Links.html#Data_links)

#### QUESTION 1
Develop a 1-page "proposal" that briefly describes your research question, your study system, the data set you will use, and what methods you plan to use to test your research question. Proposals are due to me by **Monday 26 September**. All groups should meet with me briefly to go over project ideas in lab on September 29!

## The Virtual Ecologist

Here is the "real" lab exercise for this week! For the assignment, please keep your work as short and sweet as possible! **LAB 2 is due by midnight on Friday 9/30.** Comment each line of your code. Use functions wherever possible. Don't be afraid of for loops. And of course be dangerous!

### Simulating Data in R

First, review the basic approach to simulating data in the ["Virtual Ecologist" lecture](https://kevintshoemaker.github.io/NRES-746/LECTURE3.html).

#### QUESTION 2 part a (model verification and goodness of fit)
Simulate data that meets all the standard assumptions of univariate linear regression. Then run the "lm" function on these data and examine how closely the parameter estimates match the "true" parameter value. Other choices (sample size, parameter values etc) are up to you!

* Plot the estimated regression line with a 95% confidence interval around the estimated regression line (e.g., computed using the "predict.lm" function). Overlay the "true" regression line (from the known data generating model). Does the "true" regression line fall within the estimated confidence interval?

* Plot the estimated regression line with a 95% prediction interval (e.g., computed using the "predict.lm" function). Overlay the "true" 95% prediction interval (e.g., the interval encompassing 95% of the data generated under the true model). Does the estimated 95% prediction interval encompass all or most of the true prediction interval? 

Note that you can use the 'predict' function to compute confidence intervals and prediction intervals:

```{r, eval=FALSE}
predict.lm(yourmodel, interval = c("confidence"), level = 0.95)   # for confidence interval
predict.lm(yourmodel, interval = c("prediction"), level = 0.95)   # for prediction interval

```

Note that the prediction interval code above might give warnings- which you may ignore!

* Extra credit: Does the 95% confidence interval around the parameter estimate (estimated from the data) contain the "true"" parameter value 95% of the time (a frequentist question!). Show this with simulations!

#### aside: conditional statements in R

NOTE: the extra credit question requires the use of "conditional" statements. That is, if a condition is true, do something. If the condition is false, do something else. The syntax for doing this in R is:

```{r eval=FALSE}
if(TRUE){
  do something
} else{
  do something else
}

```

Let's say I want to determine the number of vector elements that are cleanly divisible by 3. I could write the following code:

```{r}
inputvector <- c(1:100) # vector of interest
div_by_three <- 0

for(i in 1:length(inputvector)){
  if(i%%3==0){  # if there is zero remainder after dividing by three
    div_by_three <- div_by_three+1   # then increment the storage variable
  }
}

div_by_three

```

An alternative way to do this would be to do use the "which()" function. This tells you which indices in a vector correspond to "TRUE" conditions. 

For example,

```{r}

which(c(FALSE,TRUE,TRUE,FALSE))

```

Using "which", we could re-write the above code to take up just one line!

```{r}

div_by_three <- length(which(inputvector%%3==0))

```


#### QUESTION 2 part b (model verification #2)
Write an R function to generate data that violates *one or more* of the basic assumptions regarding the error distribution of standard linear regression. Make sure your dataset is realistic! Justify in writing how biological or sampling processes could have produced the data, including (especially) the assumptions violation(s). NOTE: for this exercise, you still need to specify a linear relationship (y=mx+b) between your response and predictor (otherwise some of the questions below wouldn't make sense!). 

Some options: 

* use a non-normal error distribution (simplest option!)
* introduce temporal autocorrelation
* introduce other types of correlation structure among the observations
* use a mixture of two error distributions
* others?? (feel free to be creative!)

Use classical linear regression to analyze these data. 

Answer the following questions (keep verbiage to a minimum, and provide all code- with comments!)

1. Is the estimate of the regression parameter (obtained using the 'lm' function) *biased*? [note: statistical bias of an estimator is the difference between the estimator's expected value and the true value of the parameter being estimated]. Use simulated data to obtain the estimator's expected value.
2. Is the estimate of the error variance biased? 
3. Evaluate *goodness-of-fit* by visualizing (fake) the "cloud" of data produced by the true model against the prediction interval from the estimated model.
4. Extra credit!: How well does the estimated confidence interval for the regression parameter (estimated with 'lm') match the true confidence interval for the regression parameter? (hint: you can use a brute-force method, i.e., a parametric bootstrap, to estimate the true confidence interval!)

#### QUESTION 3 (power analysis)
Review the "power analysis" section of the Virtual Ecologist lecture, and complete the following:

1. Develop a function that evaluates the statistical power to detect a decline under user-specified types of monitoring designs (e.g., varying numbers of observers, intervals between successive surveys). 
2. For each variable element of the survey design (survey interval, number of observers, days per survey bout), evaluate how statistical power changes across a range of plausible values. Plot out these relationships.
3. Imagine the current survey protocol is 1 surveyor for 1 day, with a 5-year interval. Identify whether this survey methodology is sufficient, and if not, which of these variables would you recommend changing to increase the power of the analysis.
4. Let's factor in dollar amounts. Let's assume each observer is paid \$200 per day. In addition, let's assume that the site is fairly remote and it costs \$2000 to mount a field expedition (regardless of the number of field technicians). Can you identify a survey design to minimize cost while meeting the objective??? 




















