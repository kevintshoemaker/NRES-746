<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="NRES 746" />


<title>Likelihood!</title>

<script src="site_libs/header-attrs-2.24/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cerulean.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">NRES 746</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Schedule
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="schedule.html">Course Schedule</a>
    </li>
    <li>
      <a href="Syllabus.pdf">Syllabus</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Lectures
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="INTRO.html">Introduction to NRES 746</a>
    </li>
    <li>
      <a href="LECTURE1.html">Why focus on algorithms?</a>
    </li>
    <li>
      <a href="LECTURE2.html">Working with probabilities</a>
    </li>
    <li>
      <a href="LECTURE3.html">The Virtual Ecologist</a>
    </li>
    <li>
      <a href="LECTURE4.html">Likelihood</a>
    </li>
    <li>
      <a href="LECTURE5.html">Optimization</a>
    </li>
    <li>
      <a href="LECTURE6.html">Bayesian #1: concepts</a>
    </li>
    <li>
      <a href="LECTURE7.html">Bayesian #2: mcmc</a>
    </li>
    <li>
      <a href="LECTURE8.html">Model Selection</a>
    </li>
    <li>
      <a href="LECTURE9.html">Performance Evaluation</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Lab exercises
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="LAB_Instructions.html">Instructions for Labs</a>
    </li>
    <li>
      <a href="LAB3demo.html">Lab 3: Likelihood (intro)</a>
    </li>
    <li>
      <a href="LAB5.html">Lab 5: Model selection (optional)</a>
    </li>
    <li>
      <a href="FigureDemo.html">Demo: Figures in R</a>
    </li>
    <li>
      <a href="GIT-tutorial.html">Demo: version control in Git</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Data sets
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="TreeData.csv">Tree Data</a>
    </li>
    <li>
      <a href="ReedfrogPred.csv">Reed Frog Predation Data</a>
    </li>
    <li>
      <a href="ReedfrogFuncresp.csv">Reed Frog Func Resp</a>
    </li>
  </ul>
</li>
<li>
  <a href="Links.html">Links</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Likelihood!</h1>
<h4 class="author">NRES 746</h4>
<h4 class="date">Fall 2023</h4>

</div>


<p>For those wishing to follow along with the R-based demo in class, <a
href="LECTURE4.R">click here</a> for the companion R-script for this
lecture.</p>
<p>In the last class (and lab), we talked about simulating data from
models. This is often called <em>forward simulation</em> modeling (or
prediction)- that is, we take a model and use it to predict emergent
patterns. The process flow goes something like this:</p>
<p><span class="math inline">\(Model \rightarrow Predicted \space
Data\)</span></p>
<p>In this lecture, we will talk about <em>inference</em> using
<strong>maximum likelihood</strong>. Inference is in some ways the
opposite process; we are using the data to say something about the
model.</p>
<p><span class="math inline">\(Real \space Data \rightarrow
Model\)</span></p>
<p>In many ways, these two processes – <em>forward simulation</em> and
<em>inference</em> – are interrelated. Simulation can help us to make
better inferences from real data (e.g., goodness of fit tests,
approximate likelihood), and inference from real data can help us to
make better predictions!</p>
<p>First let’s see how simulation from models can help us to make
inferences from observed data. This leads directly into the concept of
maximum likelihood.</p>
<div id="using-data-simulation-to-make-inferences"
class="section level2">
<h2>Using data simulation to make inferences</h2>
<p>Let’s use the built-in “mtcars” data for this example: (note: some
code borrowed from <a
href="http://stats.stackexchange.com/questions/142443/simple-non-linear-regression-problem">here</a>)</p>
<pre class="r"><code># Demo: using data simulation to make inferences ----------------

data(mtcars)    # use the &#39;mtcars&#39; data set as an example 

# ?mtcars

plot(mpg~disp, data = mtcars, las = 1, pch = 16, xlab = &quot;Displacement (cu. in.)&quot;, ylab = &quot;Miles/Gallon&quot;)   # visualize the relationship</code></pre>
<p><img src="LECTURE4_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>Looks nonlinear, with relatively constant variance across parameter
space. So let’s see if we can build a model that could possibly produce
these data!!</p>
<p>Since this looks a little like an exponential decline, let’s first
build a function that can generate data that follows that deterministic
function:</p>
<p><span class="math inline">\(mpg = N\left \{ intercept\cdot
e^{slope\cdot displacement} ,Variance\right \}\)</span></p>
<p>Or, if we package the parameters simply as params a, b, and c:</p>
<p><span class="math inline">\(mpg = N\left \{ a\cdot e^{b\cdot
displacement} ,c\right \}\)</span></p>
<p>What’s the <em>deterministic component</em> here?</p>
<p>Take a minute to visualize the negative exponential functional
relationship - e.g., using the “curve()” function in R.</p>
<pre class="r"><code># try an exponential model

Deterministic_component &lt;- function(xvals,a,b){
  yexp &lt;- a*exp(b*xvals)        # deterministic exponential decline (assuming b is negative)
  return(yexp)
}

DataGenerator_exp &lt;- function(xvals,params){
  yexp &lt;- Deterministic_component(xvals,params$a,params$b)  # get signal
  yvals &lt;- rnorm(length(yexp),yexp,sqrt(params$c))     # add noise (normally distributed)
  return(yvals)
}</code></pre>
<p>Let’s test this function to see if it does what we want:</p>
<pre class="r"><code>## generate data under an assumed process model -----------------

xvals=mtcars$disp    # xvals same as data (there is no random component here- we can&#39;t really &quot;sample&quot; x values)
params &lt;- list()  
params$a=30             # set model parameters arbitrarily (eyeballing to the data) (see Bolker book)
params$b=-0.005   # = 1/200
params$c=5

yvals &lt;- DataGenerator_exp(xvals,params)

plot(yvals~xvals)      # plot the simulated data</code></pre>
<p><img src="LECTURE4_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Okay, looks reasonable. Now, let’s write a function to generate
multiple replicate datasets from a known model and make boxplots
describing the plausible data produced by the model across measured
parameter space.</p>
<pre class="r"><code>## assess goodness-of-fit of a known data-generating model --------------------

PlotRangeOfPlausibleData &lt;- function(xvals,params,reps=100){ 
  samplesize &lt;- length(xvals)
  results &lt;- array(0,dim=c(samplesize,reps))   # storage array for results
  for(i in 1:reps){
    yvals &lt;- DataGenerator_exp(xvals,params)
    results[,i] &lt;- yvals
  }
      # now make a boxplot of the results
  boxplot(lapply(1:nrow(results), function(i) results[i,]),at=xvals, xaxt=&quot;n&quot;,main=&quot;Plausible data under this model&quot;,ylab=&quot;mpg&quot;,xlab=&quot;Displacement&quot;,boxwex=6)
  cleanseq &lt;- (seq(0,max(round(xvals/100)),length=(max(round(xvals/100)))+1))*100
  axis(1,at=cleanseq,labels = cleanseq)    # label the x axis properly
  
}</code></pre>
<p>Let’s try it out!</p>
<pre class="r"><code>reps &lt;- 1000    # number of replicate datasets to generate

PlotRangeOfPlausibleData(xvals,params,reps)    # run the function to visualize the range of data that could be produced under this model</code></pre>
<p><img src="LECTURE4_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Now we can overlay the data and see how well we did!</p>
<pre class="r"><code>## finally, overlay the real data to evaluate goodness of fit! ---------------

real_yvals &lt;- mtcars$mpg
PlotRangeOfPlausibleData(xvals,params,reps)
points(xvals,real_yvals,pch=20,cex=3,col=&quot;green&quot;)</code></pre>
<p><img src="LECTURE4_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Okay, not very good yet. Let’s see if we can improve the fit by
<em>changing the parameters</em>. Let’s increase the intercept and
reduce the slope:</p>
<pre class="r"><code># now change the parameters and see if the data fit to the model

params$a=40       # was 30
params$b=-0.001   # was 0.005

    
PlotRangeOfPlausibleData(xvals,params,reps)
points(xvals,real_yvals,pch=20,cex=3,col=&quot;green&quot;)    # overlay the real data</code></pre>
<p><img src="LECTURE4_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>Oops- we overshot!! Let’s find something in the middle!</p>
<pre class="r"><code># try again- select a new set of parameters

params$a=35       # was 40
params$b=-0.0029   # was 0.001
params$c=0.95
    
PlotRangeOfPlausibleData(xvals,params,reps)
points(xvals,real_yvals,pch=20,cex=3,col=&quot;green&quot;)    # overlay the real data</code></pre>
<p><img src="LECTURE4_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>Keep trying. See if you can find a model that could plausibly
generate most of these data!</p>
<p>Q: Why did you NOT just increase the “noise” parameter until the data
were consistent with the model?</p>
<p>So, we have used simulation, along with trial and error, to infer the
most <strong>likely</strong> parameter values for our model!</p>
<p>A <em>likelihood function</em>, very generally, is a
<em>function</em> that has 2 input arguments: + the
<strong>data</strong> + a <strong>hypothesized data-generating
model</strong> The likelihood function takes these inputs and produces a
single output: + the <em>data likelihood</em></p>
<p>The data likelihood is a single number representing the relative
plausibility that <em>this</em> model could have produced <em>these</em>
data.</p>
<p>The higher the relative plausibility of generating the data, the
higher the value the likelihood function returns.</p>
<p><strong>Q:</strong> What is the likelihood function we have used in
this example?</p>
</div>
<div id="computing-data-likelihood-more-rigorously"
class="section level2">
<h2>Computing data <em>likelihood</em> more rigorously</h2>
<p>First of all, what does “data likelihood” really mean, in a formal
sense?</p>
<p><span class="math inline">\(\mathcal{L_{model}} (obs.data) \equiv
Prob(obs.data|Model)\)</span></p>
<div id="definition-in-plain-english" class="section level3">
<h3>Definition, in plain English!</h3>
<p>The likelihood of a fully-specified model with a set of parameters
<span class="math inline">\(\theta\)</span>, given some observed data,
is equal to the <em>probability</em> of observing these data, given the
defined model with those specific parameter values. In this way,
likelihood is a quantitative measure of <em>model fit</em>. Higher
likelihoods correspond to a higher probability of the model producing
the observed data (the data “fit” the model well).</p>
<p>But remember, we use likelihood as a <em>relative</em> rather than an
<em>absolute</em> metric. Therefore, the model with the highest
likelihood (out of a set of candidate models) doesn’t necessarily mean
the model would pass a basic goodness-of-fit test!</p>
</div>
<div id="worked-example" class="section level3">
<h3>Worked example</h3>
<p>Let’s go through an example (let’s stick with the cars example for
now).</p>
<p>For simplicity, let’s consider <em>only the first
observation</em>:</p>
<pre class="r"><code># Work with likelihood! ---------------------

obs.data &lt;- mtcars[1,c(&quot;mpg&quot;,&quot;disp&quot;)]    # for simplicity, consider only the first observation
obs.data</code></pre>
<pre><code>##           mpg disp
## Mazda RX4  21  160</code></pre>
<p>Remember, we are considering the following data generating model:</p>
<p><span class="math inline">\(mpg = N\left \{ a\cdot e^{b\cdot
displacement} ,c\right \}\)</span></p>
<p>To compute likelihood we also need to specify all parameter values.
That is, we need a <em>fully specified (parameterized) data generating
model</em>.</p>
<p>Let’s use the parameters we selected in our trial-and-error exercise
above. What is the expected value of our single observation under this
data generating model.</p>
<pre class="r"><code>## &quot;best fit&quot; parameters from above   ----------------


params &lt;- list()    # set up empty list to store parameters
params$a=35            # fill the list with the &quot;best fit&quot; parameter set from above (this is still just an educated guess)   
params$b= -0.0029   
params$c=0.95

params</code></pre>
<pre><code>## $a
## [1] 35
## 
## $b
## [1] -0.0029
## 
## $c
## [1] 0.95</code></pre>
<pre class="r"><code>expected_val &lt;- Deterministic_component(obs.data$disp,params$a,params$b)   
expected_val      # expected mpg for the first observation in the &quot;mtcars&quot; dataset</code></pre>
<pre><code>## [1] 22.00672</code></pre>
<p>Okay we now know our expected (mean) value for mpg for a car with
displacement of 160 cubic inches. We also know the observed mpg for a
car with a displacement of 160 cubic inches: it was 21 mpgs. Since we
also know the variance of the residual error, we have a fully specified
data generating model (deterministic component and stochastic component
with all parameters fully specified!) we can compute the probability of
sampling a car with 21 mpgs under our model, given it has a cubic
displacement of 160 cubic inches.</p>
<p>Recall that when we are trying to compute the probability of getting
any particular number out of a random number generator with known
distribution, we can use the “d<em>x</em>” version of the probability
distribution function in R (e.g., “dnorm()”, “dunif()”, “dpois()”):</p>
<pre class="r"><code>## Visualize the likelihood of this single observation.  ------------------------

mean = expected_val   # expected (mean) value for this observation, given the &quot;known&quot; data generating model
stdev = sqrt(params$c)    # standard deviation

curve(dnorm(x,mean,stdev),10,30,xlab=&quot;possible vals for mpg under the specified model&quot;,ylab=&quot;probability density&quot;)   # probability of all plausible mpg values under the data generating model.  
abline(v=obs.data$mpg,col=&quot;red&quot;,lwd=2)    # overlay the observed data</code></pre>
<p><img src="LECTURE4_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>Now it is straightforward to compute the likelihood. We just need to
know the probability density where the red line (observed data)
intersects with the normal density curve (above). For this we can use
the “dnorm()” function (probability density, normal distribution):</p>
<pre class="r"><code>## compute the likelihood of the first observation  ---------------------

likelihood = dnorm(obs.data$mpg,mean,stdev)
likelihood</code></pre>
<pre><code>## [1] 0.2400976</code></pre>
<p><strong>Q</strong>: how could you increase the likelihood of
obtaining the observed observation??</p>
<p>Now let’s consider a second observation as well!</p>
<pre class="r"><code>## Visualize the likelihood of two observations. ---------------

obs.data &lt;- mtcars[c(1,3),c(&quot;mpg&quot;,&quot;disp&quot;)]
obs.data</code></pre>
<pre><code>##             mpg disp
## Mazda RX4  21.0  160
## Datsun 710 22.8  108</code></pre>
<pre class="r"><code>par(mfrow=c(1,2))  # set up graphics!

for(i in 1:nrow(obs.data)){
  curve(dnorm(x,Deterministic_component(obs.data$disp[i],params$a,params$b),sqrt(params$c)),10,30,xlab=&quot;mpg&quot;,ylab=&quot;probability density&quot;)   # probability density
  abline(v=obs.data$mpg[i],col=&quot;red&quot;,lwd=2)
}</code></pre>
<p><img src="LECTURE4_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>What is the likelihood of observing both of these data points???</p>
<p><span class="math inline">\(Prob(obs.data_{1}|Model])\cdot
Prob(obs.data_{2}|Model])\)</span></p>
<pre class="r"><code>## compute the likelihood of observing BOTH data points  ----------------

Likelihood &lt;- dnorm(obs.data$mpg[1],Deterministic_component(obs.data$disp[1],params$a,params$b),sqrt(params$c)) *
              dnorm(obs.data$mpg[2],Deterministic_component(obs.data$disp[2],params$a,params$b),sqrt(params$c))  
Likelihood</code></pre>
<pre><code>## [1] 0.00164031</code></pre>
<p>Let’s consider four observations:</p>
<pre class="r"><code># and now... four observations!

obs.data &lt;- mtcars[c(1,3,4,5),c(&quot;mpg&quot;,&quot;disp&quot;)]
obs.data</code></pre>
<pre><code>##                    mpg disp
## Mazda RX4         21.0  160
## Datsun 710        22.8  108
## Hornet 4 Drive    21.4  258
## Hornet Sportabout 18.7  360</code></pre>
<pre class="r"><code>par(mfrow=c(2,2))  # set up graphics!

for(i in 1:nrow(obs.data)){
  curve(dnorm(x,Deterministic_component(obs.data$disp[i],params$a,params$b),sqrt(params$c)),10,30,xlab=&quot;mpg&quot;,ylab=&quot;probability density&quot;)   # probability density
  abline(v=obs.data$mpg[i],col=&quot;red&quot;,lwd=2)
}</code></pre>
<p><img src="LECTURE4_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>What is the combined likelihood of all of these four data points,
assuming each observation is independent…</p>
<pre class="r"><code># compute the likelihood of observing all four data points

Likelihood &lt;- 1     # initialize the likelihood
for(i in 1:nrow(obs.data)){
  Likelihood &lt;- Likelihood * dnorm(obs.data$mpg[i],Deterministic_component(obs.data$disp[i],params$a,params$b),sqrt(params$c))
}
Likelihood</code></pre>
<pre><code>## [1] 6.175681e-19</code></pre>
<p>Alternatively, we can use the “prod” function in R:</p>
<pre class="r"><code>## Alternatively, we can use the &quot;prod&quot; function in R  -----------------

Likelihood &lt;- prod(dnorm(obs.data$mpg,Deterministic_component(obs.data$disp,params$a,params$b),sqrt(params$c)))
Likelihood</code></pre>
<pre><code>## [1] 6.175681e-19</code></pre>
<p>Okay, so it should be fairly obvious how we might get the likelihood
of the entire dataset. Assuming independence of observations of
course!</p>
<pre class="r"><code># Finally, compute the likelihood of ALL data points in the entire data set, using the &quot;prod()&quot; function

full.data &lt;- mtcars[,c(&quot;mpg&quot;,&quot;disp&quot;)]
Likelihood &lt;- prod(dnorm(full.data$mpg,Deterministic_component(full.data$disp,params$a,params$b),sqrt(params$c)))
Likelihood</code></pre>
<pre><code>## [1] 2.848366e-85</code></pre>
<p>You may notice that that’s a pretty small number. When you multiply
lots of really small numbers together, we get much smaller numbers. This
can be very undesirable, especially when you run into overflow/underflow
errors (meaning the number is beyond the range that can be represented
in computer memory). For this reason, and because we generally like sums
rather than products, we generally <em>log-transform</em> likelihoods.
As you recall,</p>
<p><span class="math inline">\(log(a\cdot b\cdot
c)=log(a)+log(b)+log(c)\)</span></p>
<p>Log transformations just make it easier to work with likelihoods!</p>
<p>In fact, the probability density functions in R make it extra easy
for us to work with log likelihoods, using the ‘log=TRUE’ option!</p>
<pre class="r"><code>## Compute the log-likelihood (much easier to work with!)  -----------------------

Log.Likelihood &lt;- sum(dnorm(full.data$mpg,Deterministic_component(full.data$disp,params$a,params$b),sqrt(params$c),log=TRUE)) 
Log.Likelihood  </code></pre>
<pre><code>## [1] -194.673</code></pre>
<pre class="r"><code>exp(Log.Likelihood)   # we can convert back to likelihood if we want...</code></pre>
<pre><code>## [1] 2.848366e-85</code></pre>
</div>
</div>
<div id="maximum-likelihood-estimation-mle" class="section level2">
<h2>Maximum Likelihood Estimation (MLE)</h2>
<p>Maximum likelihood estimation is a general, flexible method for
drawing <em>inference</em> about models from data.</p>
<p>The basic idea is simple: given a data generating model and a set of
‘free parameters’, search for the set of parameter values (specific
values for each of the free parameters) that maximizes the likelihood of
the observed data (the value returned by the likelihood function)!</p>
<p>Like any function, a <em>likelihood function</em> has inputs and
outputs.</p>
<p>The <strong>inputs</strong> are: + A vector of <strong>free
parameters</strong>, which are the parameters we are trying to
estimate!<br />
+ An observed data set (response and predictors) for which we want to
compute the likelihood!<br />
+ [optional] Any additional fixed parameters you want!</p>
<p>The <strong>algorithm</strong> is: + A data generating model, often
constructed by combining one or more deterministic and stochastic
components. Log-likelihood is computed by adding together the
log-likelihoods of all independent observations.</p>
<p>The <strong>output</strong> is:<br />
+ The log-likelihood of the dataset, given the model (in practice,
typically the negative log likelihood)</p>
<p>NOTE: instead of log-likelihood, we often use the <em>negative
log-likelihood</em> (it is more common to identify the minimum rather
than the maximum of an <em>objective function</em>- this is the default
for the native optimization function in R, “optim()”)</p>
<p><strong>Q</strong>: What are the free parameters in the mtcars
example?</p>
<p>It is important to note that the likelihood function, when evaluated
for every point in <em>parameter space</em> (likelihood
<em>surface</em>) essentially contains all the information in the data
that can be used to make inference about the model. The problem then
becomes, how can we search for the maximum-likelihood estimate (MLE) and
characterize the likelihood surface around the MLE? We will discuss the
mechanics of this in the <a href="LECTURE5.html">next lecture
(optimization)</a>.</p>
<p>The steps of a typical MLE analysis are as follows:</p>
<ol style="list-style-type: decimal">
<li>Build a <em>likelihood function</em> for the specified model,
bundling all free parameters together into one vector argument</li>
<li>Use <em>numerical optimization algorithms</em> to find the set of
parameters that maximize the likelihood function</li>
<li>Use the shape of the likelihood function to make inference about
parameter uncertainty (e.g., confidence intervals)</li>
</ol>
<p>Okay, let’s build our first <em>likelihood function</em>? We
basically already have this for the cars example:</p>
<pre class="r"><code># Example likelihood function!  --------------------------------

# Arguments:
#   params: bundled vector of free parameters for the known data-generating model
#   df: a data frame that holds the observed data
#   yvar: the name of the response variable (ancillary)
#   xvar: the name of the predictor variable (ancillary)

LogLikFunction &lt;- function(params,df,yvar,xvar){
  LogLik &lt;- sum(dnorm(df[,yvar],Deterministic_component(df[,xvar],params[&#39;a&#39;],params[&#39;b&#39;]),sqrt(params[&#39;c&#39;]),log=TRUE))
  return(LogLik)
}
LogLikFunction(unlist(params),df=mtcars,yvar=&quot;mpg&quot;,xvar=&quot;disp&quot;)</code></pre>
<pre><code>## [1] -194.673</code></pre>
<p>Now that we have a likelihood function, we need to search parameter
space for the parameter set that maximizes the log-likelihood of the
observed data. Luckily, there are plenty of <em>computational
algorithms</em> that can do this. We will look at this in detail in the
optimization lecture. For now, we just need to know that these fancy
algorithms exist, and that they can be harnessed using the ‘optim()’
function in R.</p>
<p>The “optim()” function in R wants (1) a likelihood function, (2) a
set of free parameters, along with <em>starting values</em> for these
parameters, bundled into a named vector object (3) any other ancillary
variables that the likelihood function requires, and (4) parameters
specifying aspects of the optimization algorithm (e.g., which numerical
algorithm to use, whether to maximize rather than minimize).</p>
<p>Let’s find the MLE for the three parameters in the cars example!!</p>
<pre class="r"><code># Use numerical optimization methods to identify the maximum likelihood estimate (and the likelihood at the MLE)

MLE &lt;- optim(fn=LogLikFunction,par=unlist(params),df=mtcars,yvar=&quot;mpg&quot;,xvar=&quot;disp&quot;,control=list(fnscale=-1))  # note, the control param is set so that &quot;optim&quot; maximizes rather than minimizes the Log-likelihood. </code></pre>
<p>Now, we can get the MLEs for the three parameters (the parameter
values that maximize the likelihood function):</p>
<pre class="r"><code>MLE$par   # maximum likelihood parameter estimates</code></pre>
<pre><code>##            a            b            c 
## 33.077304416 -0.002338545  8.168003592</code></pre>
<p>We can also get the log likelihood for the best model (the maximum
log-likelihood value, achieved by using the above parameter values as
inputs to the likelihood function)</p>
<pre class="r"><code>MLE$value   # log likelihood for the best model</code></pre>
<pre><code>## [1] -79.0089</code></pre>
<p>Let’s look at goodness-of-fit for the best model!</p>
<pre class="r"><code># visualize goodness-of-fit for the best model  ----------------------

bestParams &lt;- as.list(MLE$par)   # extract the MLE parameter vals

xvals &lt;- mtcars$disp
yvals &lt;- mtcars$mpg
PlotRangeOfPlausibleData(xvals,bestParams,1000)
points(xvals,yvals,pch=20,cex=3,col=&quot;green&quot;)</code></pre>
<p><img src="LECTURE4_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p>Now this isn’t such a bad looking model (not perfect though)!</p>
<p>Using this same strategy, we can fit countless models to data. We
just performed a non-linear regression. But we could just as well have
fit any number of alternative model formulations (different
deterministic functions and “noise” distributions). Maximum Likelihood
is a powerful and flexible framework. We will have plenty of more
opportunities to work with likelihood functions, both in a frequentist
and a Bayesian context.</p>
<div id="aside-generating-initial-values" class="section level3">
<h3>Aside: generating initial values</h3>
<p>Note that the ‘optim’ function requires specification of initial
values for every free parameter in your model. In general, it is not
critical that the initial values fit the data very well. However, we
need to put serious thought into our initial values. Using values that
are too far away from the best-fit parameter estimates can cause our
optimization algorithms to fail! The strategy I recommend for setting
initial values is:</p>
<ul>
<li>If possible, use general understanding of the meaning of the
parameters to “eyeball” an approximate value for each parameter<br />
</li>
<li>Write a data-generation function and compare the data generated by
this function against the observed data. If the fit is “close-ish” then
you should be able to use these values for your initial values (really
it doesn’t need to be that close! If not, continue to tweak the
parameters until you find something that is “close-ish”.</li>
</ul>
</div>
</div>
<div id="estimating-parameter-uncertainty" class="section level2">
<h2>Estimating parameter uncertainty</h2>
<p>We have now identified the parameter values that maximize the
likelihood function. These are now our “best” estimates of the parameter
values (MLE). But we usually want to know something about how certain we
are about our estimate, often in the form of confidence intervals.</p>
<p>Fortunately, likelihood theory offers us a strategy for estimating
confidence intervals around our parameter estimates. The idea is that
the <em>shape</em> of the likelihood function around the MLE tells us
something about the plausibility of these parameter values.</p>
<p>For instance, let’s plot out the shape of the likelihood function
across a <strong>slice</strong> of parameter space (vary one parameter
and hold all others constant). In this case, let’s look at the “decay
rate” term (the ‘b’ parameter). We can vary that parameter over a range
of possible values and see how the likelihood changes over that
parameter space. Let’s hold the other parameters at their maximum
likelihood values:</p>
<pre class="r"><code># Estimating parameter uncertainty -------------------------

# Visualize a &quot;slice&quot; of the likelihood function

upperval &lt;- -1/1000
lowerval &lt;- -1/200
allvals &lt;- seq(lowerval,upperval,length=1000)
likelihood_slice &lt;- numeric(1000)   # set up storage vector! 
newParams &lt;- bestParams 
for(i in c(1:length(allvals))){
  newParams$b &lt;- allvals[i]
  likelihood_slice[i] &lt;- exp(LogLikFunction(unlist(newParams),mtcars,&quot;mpg&quot;,&quot;disp&quot;))    # get the data likelihood across slice of parameter space
}

plot(allvals,likelihood_slice,type=&quot;l&quot;,main=&quot;Likelihood Slice&quot;,xlab=&quot;Parameter Slice for \&#39;b\&#39;&quot;,ylab=&quot;Likelihood&quot;)</code></pre>
<p><img src="LECTURE4_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<p>Again, we generally want to work with log-likelihoods. And here we
have an even better reason to use log-likelihoods. This reason: the
“rule of 2”, and (more formally) the <strong>likelihood ratio
test</strong>.</p>
<p>For now, suffice it to say that all parameter values within ~2
log-likelihood units of the best-fit parameter value are
<em>plausible</em>. Therefore, a <em>reasonable</em> confidence interval
(approximate 95% conf int) can be obtained by identifying the set of
possible parameter values for which the log-likelihood of the data is
within two of the maximum log-likelihood value…</p>
<p>Let’s plot out the log-likelihood slice:</p>
<pre class="r"><code># Work with log-likelihood instead...

upperval &lt;- -1/1000
lowerval &lt;- -1/200
allvals &lt;- seq(lowerval,upperval,length=1000)
loglikelihood_slice &lt;- numeric(1000)   # set up storage vector! 
newParams &lt;- bestParams 
for(i in c(1:length(allvals))){
  newParams$b &lt;- allvals[i]
  loglikelihood_slice[i] &lt;- LogLikFunction(unlist(newParams),mtcars,&quot;mpg&quot;,&quot;disp&quot;)    # get the data likelihood across slice of parameter space
}

plot(allvals,loglikelihood_slice,type=&quot;l&quot;,main=&quot;Log Likelihood Slice&quot;,xlab=&quot;Parameter Slice for \&#39;b\&#39;&quot;,ylab=&quot;Log-Likelihood&quot;)</code></pre>
<p><img src="LECTURE4_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p>Let’s “zoom in” to a smaller slice of parameter space so we can more
clearly see the “plausible” values:</p>
<pre class="r"><code># zoom in closer to the MLE

upperval &lt;- -1/550
lowerval &lt;- -1/350
allvals &lt;- seq(lowerval,upperval,length=1000)
loglikelihood_slice &lt;- numeric(1000)   # set up storage vector! 
newParams &lt;- bestParams 
for(i in c(1:length(allvals))){
  newParams$b &lt;- allvals[i]
  loglikelihood_slice[i] &lt;- LogLikFunction(unlist(newParams),mtcars,&quot;mpg&quot;,&quot;disp&quot;)    # get the data likelihood across slice of parameter space
}

plot(allvals,loglikelihood_slice,type=&quot;l&quot;,main=&quot;Log Likelihood Slice&quot;,xlab=&quot;Parameter Slice for \&#39;b\&#39;&quot;,ylab=&quot;Log-Likelihood&quot;)</code></pre>
<p><img src="LECTURE4_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<p>What region of this space falls within 2 log-likelihood units of the
best value?</p>
<pre class="r"><code># what parameter values are within 2 log likelihood units of the best value?  -------------

bestVal &lt;- bestParams$b
bestVal</code></pre>
<pre><code>## [1] -0.002338545</code></pre>
<pre class="r"><code>plot(allvals,loglikelihood_slice,type=&quot;l&quot;,main=&quot;Log Likelihood Slice&quot;,xlab=&quot;Parameter Slice for \&#39;b\&#39;&quot;,ylab=&quot;Log-Likelihood&quot;)
abline(v=bestVal,lwd=3,col=&quot;blue&quot;)
abline(h=(MLE$value-2))</code></pre>
<p><img src="LECTURE4_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<p>So what is our 95% confidence interval in this case?? (remember this
is <em>approximate</em>!)</p>
<pre class="r"><code># Generate an approximate 95% confidence interval for the &quot;b&quot; parameter -----------------

reasonable_parameter_values &lt;- allvals[loglikelihood_slice&gt;=(MLE$value-2)]
min(reasonable_parameter_values)</code></pre>
<pre><code>## [1] -0.002595063</code></pre>
<pre class="r"><code>max(reasonable_parameter_values)</code></pre>
<pre><code>## [1] -0.002100022</code></pre>
<pre class="r"><code>plot(allvals,loglikelihood_slice,type=&quot;l&quot;,main=&quot;Log Likelihood slice&quot;,xlab=&quot;Parameter Slice for \&#39;b\&#39;&quot;,ylab=&quot;Log-Likelihood&quot;)
abline(v=bestVal,lwd=3,col=&quot;blue&quot;)
abline(h=(MLE$value-2),lty=2)
abline(v=min(reasonable_parameter_values),lwd=1,col=&quot;blue&quot;)
abline(v=max(reasonable_parameter_values),lwd=1,col=&quot;blue&quot;)</code></pre>
<p><img src="LECTURE4_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
<div id="key-point" class="section level4">
<h4>Key point!</h4>
<p>From the Bolker book:</p>
<ul>
<li>The geometry of the likelihood surface – where it peaks and how the
distribution falls off around the peak – contains essentially all the
information you need to estimate parameters and confidence
intervals.</li>
</ul>
</div>
<div id="estimating-parameter-uncertainty-in-multiple-dimensions"
class="section level3">
<h3>Estimating parameter uncertainty in multiple dimensions</h3>
<p>If we have more than one <em>free parameter</em> in our model, it
seems strange to fix any parameter at a particular value, as we did in
computing the “likelihood slice” above. It makes more sense to allow all
the parameters to vary. For the purpose of visualization, let’s assume
for now that we only have two free parameters in our model: ‘a’ and ‘b’.
We will assume for now that the variance parameter is known for
certain.</p>
<p>Let’s try to visualize the likelihood surface in two dimensions!</p>
<pre class="r"><code># A better confidence interval, using the likelihood &quot;profile&quot; -----------------

# first, visualize the likelihood surface in 2 dimensions

upperval_b &lt;- -1/800
lowerval_b &lt;- -1/300

upperval_a &lt;- 50
lowerval_a &lt;- 5

allvals_a &lt;- seq(lowerval_a,upperval_a,length=500)
allvals_b &lt;- seq(lowerval_b,upperval_b,length=500)

loglikelihood_surface &lt;- matrix(0,nrow=500,ncol=500)   # set up storage matrix! 

newParams &lt;- bestParams 
for(i in 1:length(allvals_a)){  # loop through possible a params
  newParams$a &lt;- allvals_a[i]
  for(j in 1:length(allvals_b)){    # loop through possible b params
    newParams$b &lt;- allvals_b[j]
    loglikelihood_surface[i,j] &lt;- LogLikFunction(unlist(newParams),mtcars,&quot;mpg&quot;,&quot;disp&quot;)    # get the data likelihood across slice of parameter space
  }
}

image(x=allvals_a,y=allvals_b,z=loglikelihood_surface,zlim=c(-100,-75),col=topo.colors(12))</code></pre>
<p><img src="LECTURE4_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<p>Now let’s add a contour line to indicate the <em>95% bivariate
confidence region</em></p>
<pre class="r"><code># add a contour line, assuming deviances follow a chi-squared distribution

conf95 &lt;- qchisq(0.95,2)/2  # this evaluates to around 3. Since we are varying freely across 2 dimensions, we use chisq with 2 degrees of freedom
image(x=allvals_a,y=allvals_b,z=loglikelihood_surface,zlim=c(-100,-75),col=topo.colors(12))
contour(x=allvals_a,y=allvals_b,z=loglikelihood_surface,levels=(MLE$value-conf95),add=TRUE,lwd=3,col=gray(0.3))</code></pre>
<p><img src="LECTURE4_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<div id="likelihood-profiles" class="section level4">
<h4>Likelihood profiles</h4>
<p>So, what is the “<strong>profile likelihood</strong>” confidence
interval for the a parameter?</p>
<p>By “profile likelihood” confidence interval, we mean this: we have a
parameter of interest, and one or more free parameters that we also have
some uncertainty about. For every value of the parameter of interest, we
find the highest likelihood value across all possible values of all the
other uncertain parameters (parameter of interest is a sequence of fixed
points across its range, other parameter(s) are free to vary). This way
we can define a likelihood surface that accounts for our uncertainty
about the other parameters, and therefore we get a more honest
description of the uncertainty we have about the parameter of
interest.</p>
<pre class="r"><code># visualize likelihood profile!

              ### A parameter
profile_A &lt;- apply(loglikelihood_surface,1,max)
reasonable_parameter_values_A &lt;- allvals_a[profile_A &gt;=(MLE$value-qchisq(0.95,1)/2)]
min(reasonable_parameter_values_A)</code></pre>
<pre><code>## [1] 29.97996</code></pre>
<pre class="r"><code>max(reasonable_parameter_values_A)</code></pre>
<pre><code>## [1] 36.38277</code></pre>
<pre class="r"><code>plot(allvals_a,profile_A,type=&quot;l&quot;,main=&quot;Log Likelihood profile&quot;,xlab=&quot;Parameter \&#39;a\&#39;&quot;,ylab=&quot;Log-Likelihood&quot;)
abline(v=MLE$par[&quot;a&quot;],lwd=3,col=&quot;blue&quot;)
abline(v=min(reasonable_parameter_values_A),lwd=1,col=&quot;blue&quot;)
abline(v=max(reasonable_parameter_values_A),lwd=1,col=&quot;blue&quot;)</code></pre>
<p><img src="LECTURE4_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
<p>And the b parameter?</p>
<pre class="r"><code># profile for the b parameter... 

profile_B &lt;- apply(loglikelihood_surface,2,max)
reasonable_parameter_values_B &lt;- allvals_b[profile_B &gt;=(MLE$value-qchisq(0.95,1)/2)]
min(reasonable_parameter_values_B)</code></pre>
<pre><code>## [1] -0.002849031</code></pre>
<pre class="r"><code>max(reasonable_parameter_values_B)</code></pre>
<pre><code>## [1] -0.001859552</code></pre>
<pre class="r"><code>plot(allvals_b,profile_B,type=&quot;l&quot;,main=&quot;Log Likelihood profile&quot;,xlab=&quot;Parameter \&#39;b\&#39;&quot;,ylab=&quot;Log-Likelihood&quot;)
abline(v=MLE$par[&quot;b&quot;],lwd=3,col=&quot;blue&quot;)
abline(v=min(reasonable_parameter_values_B),lwd=1,col=&quot;blue&quot;)
abline(v=max(reasonable_parameter_values_B),lwd=1,col=&quot;blue&quot;)</code></pre>
<p><img src="LECTURE4_files/figure-html/unnamed-chunk-34-1.png" width="672" /></p>
<p>So,what happens if we compare the profile likelihood confidence
interval with the “slice” method we used earlier??</p>
<pre class="r"><code># Compare profile and slice intervals

par(mfrow=c(1,2))
reasonable_parameter_values &lt;- allvals[loglikelihood_slice&gt;=(MLE$value-2)]
plot(allvals,loglikelihood_slice,type=&quot;l&quot;,main=&quot;Log Likelihood slice&quot;,xlab=&quot;Parameter \&#39;b\&#39;&quot;,ylab=&quot;Log-Likelihood&quot;,xlim=c(-0.0035,-0.0013))
abline(v=bestVal,lwd=3,col=&quot;blue&quot;)
abline(h=(MLE$value-2),lty=2)
abline(v=min(reasonable_parameter_values),lwd=1,col=&quot;blue&quot;)
abline(v=max(reasonable_parameter_values),lwd=1,col=&quot;blue&quot;)


profile_B &lt;- apply(loglikelihood_surface,2,max)
reasonable_parameter_values_B &lt;- allvals_b[profile_B &gt;=(MLE$value-2)]
plot(allvals_b,profile_B,type=&quot;l&quot;,main=&quot;Log Likelihood profile&quot;,xlab=&quot;Parameter \&#39;b\&#39;&quot;,ylab=&quot;Log-Likelihood&quot;,xlim=c(-0.0035,-0.0013))
abline(v=MLE$par[&quot;b&quot;],lwd=3,col=&quot;blue&quot;)
abline(h=(MLE$value-2),lty=2)
abline(v=min(reasonable_parameter_values_B),lwd=1,col=&quot;blue&quot;)
abline(v=max(reasonable_parameter_values_B),lwd=1,col=&quot;blue&quot;)</code></pre>
<p><img src="LECTURE4_files/figure-html/unnamed-chunk-35-1.png" width="672" /></p>
<p><strong>Does it make sense why there is a difference (i.e., why the
profile-likelihood CI is wider than the slice CI)??</strong></p>
<p>In R and other software packages you may have worked with, you will
have the option to estimate the confidence interval using the ‘profile
likelihood’ method. Now you know what that means!</p>
<p>**Are there any other ways of getting a confidence interval from a
likelihood surface?<br />
+ Evaluate the shape of the likelihood surface at the MLE using
mathematical approximation: use the second derivatives of -LogLik
evaluated at the MLE to estimate the standard errors of all parameters
(formally, use the “Hessian” matrix!).</p>
<p>NOTE: the profile method can easily detect asymmetries in the
likelihood surface. Commonly used approximations are often not able to
detect these asymmetries.</p>
</div>
<div id="exercise-3.1" class="section level4">
<h4>Exercise 3.1</h4>
<p>Develop a <em>likelihood function</em> for the following scenario:
you visit three known-occupied wetland sites ten times and for each site
you record the number of times a particular frog species is detected
within a 5-minute period. Assuming that all sites are occupied
continuously, compute the likelihood of these data: [3, 2 and 6
detections for sites 1, 2, and 3 respectively] for a given detection
probability <span class="math inline">\(p\)</span>. Assume that all
sites have the same (unknown) detection probability. Using this
likelihood function, answer the following questions:</p>
<ol style="list-style-type: decimal">
<li>What is the maximum likelihood estimate (MLE) for the p
parameter?</li>
<li>Using the “rule of 2”, determine the approximate 95% confidence
interval for the p parameter.</li>
</ol>
<pre class="r"><code>###### Practice exercise: develop a likelihood function for estimating the probability of detection of a rare frog species

ncaps &lt;- c(3,2,6)   # number of times out of 10 that a frog is detected at 3 known-occupided wetland sites

#### construct a likelihood function


#### find the MLE using &#39;optim()&#39; in R


#### find the approximate 95% confidence interval using the &quot;rule of 2&quot;</code></pre>
</div>
</div>
<div id="the-likelihood-ratio-test-lrt" class="section level3">
<h3>The likelihood ratio test (LRT)</h3>
<p>Steeper gradients (slopes) in the likelihood surface near the maximum
likelihood estimate correspond to narrower confidence intervals. But how
can we determine the cutoff for where the edge of the confidence
interval is?</p>
<p>The likelihood ratio test (LRT) gives us an answer!</p>
<div id="definition-likelihood-ratio" class="section level4">
<h4>Definition: Likelihood Ratio</h4>
<p>The <em>likelihood Ratio</em> is defined as:</p>
<p><span
class="math inline">\(\frac{\mathcal{L}_{r}}{\widehat{\mathcal{L}}}\)</span></p>
<p>Where <span class="math inline">\(\widehat{\mathcal{L}}\)</span> is
the maximum likelihood of the full fitted model and <span
class="math inline">\(\mathcal{L} _{r}\)</span> is the Likelihood of a
model for which one or more parameters have been ‘fixed’ at their true
value(s).</p>
</div>
<div id="likelihood-ratio-test" class="section level4">
<h4>Likelihood Ratio Test</h4>
<p>Twice the negative log likelihood ratio, <span
class="math inline">\(-2*ln(\frac{\mathcal{L}
_{r}}{\widehat{\mathcal{L}}})\)</span>, known as the <em>deviance</em>
(this is an important statistic in both Bayesian and frequentist
inference), is an important test statistic with a known theoretical
sampling distribution!</p>
<div id="sampling-distribution-of-the-deviance-statistic-frequentist"
class="section level5">
<h5>Sampling distribution of the deviance statistic (frequentist!)</h5>
<p>For some reason (which we will not dwell on) the sampling
distribution of the deviance (test statistic) under the null hypothesis
(H0: the reduced model is in fact the true model) is
<em>approximately</em> <span class="math inline">\(\chi^2\)</span>
(“chi-squared”) distributed with <em>r</em> degrees of freedom, where
<em>r</em> is the number of dimensions by which the full model has been
reduced (number of parameters “fixed”).</p>
<p><em>r</em> is equal to the number of free parameters that have been
fixed at their true values. That is, if our full model has three free
parameters and we fix the value of two of these parameters at their true
values to build a reduced model, <em>r</em> is equal to 2.</p>
<p>We can use this property to estimate the statistical significance of
any difference in log-likelihood (or more precisely, the deviance)
between a fitted model and a null model with one or more parameters
fixed at their true values.</p>
<p>Here is a visualization of the chi-squared distribution with 2
degrees of freedom:</p>
<pre class="r"><code># demo: likelihood ratio test  -------------------------------

curve(dchisq(x,2),0,10,ylab=&quot;probability density&quot;,xlab=&quot;x&quot;, main=&quot;Chi-Squared distribution, df=2&quot;)</code></pre>
<p><img src="LECTURE4_files/figure-html/unnamed-chunk-37-1.png" width="672" /></p>
<p>What is the 95% quantile of this distribution?</p>
<pre class="r"><code>curve(dchisq(x,2),0,10,ylab=&quot;probability density&quot;,xlab=&quot;x&quot;, main=&quot;Chi-Squared distribution, df=2&quot;)
abline(v=qchisq(0.95,2),col=&quot;red&quot;,lwd=2)</code></pre>
<p><img src="LECTURE4_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
<p>What about 1 df?</p>
<pre class="r"><code>curve(dchisq(x,1),0,5,ylab=&quot;probability density&quot;,xlab=&quot;x&quot;, main=&quot;Chi-Squared distribution, df=1&quot;)
abline(v=qchisq(0.95,1),col=&quot;red&quot;,lwd=2)</code></pre>
<p><img src="LECTURE4_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
<p>Okay, so now we know that the quantity defined as <span
class="math inline">\(-2*ln(\frac{\mathcal{L}
_{r}}{\widehat{\mathcal{L}}})\)</span>, should be distributed according
to the above probability distribution under the null hypothesis of the
reduced model being true (the deviance between the full and reduced
model is simply a result of random chance). How does this relate to
confidence intervals?</p>
<ol style="list-style-type: decimal">
<li>The deviance between the true model (one or more parameters fixed at
their true value) and the fitted model (with these same parameters
estimated from the data) is a measure of <em>sampling error</em> (the
degree to which the result may be an artifact of a random sample rather
than a reflection of the truth)</li>
<li>The theoretical distribution of the deviance (sampling error)
follows a Chi-squared distribution (df=number of parameters fixed at
their true value)</li>
<li>To define a confidence interval, we typically ask “How different
than the fitted value could the true parameter be and still allow us to
obtain our fitted parameter value as a result of sampling error?”</li>
<li>It follows that we can define the 95% univariate confidence interval
for a parameter as the region around the MLE such that the deviance
<span class="math inline">\(-2*ln(\frac{\mathcal{L}
_{r}}{\widehat{\mathcal{L}}})\)</span> is within <span
class="math inline">\(\chi^2_{crit, df=1}\)</span> of the MLE.</li>
</ol>
<p>So, if we want to determine a range in parameter space that can
plausibly contain the true parameter value, we can select the range of
parameter space for which <span
class="math inline">\(-2*ln(\frac{\mathcal{L}
_{r}}{\widehat{\mathcal{L}}})\)</span> is less than or equal to
3.84.</p>
<p><span class="math inline">\(-2*ln(\frac{\mathcal{L}
_{r}}{\widehat{\mathcal{L}}}) \leq - 3.84\)</span><br />
<span class="math inline">\(-2*[ln(\mathcal{L} _{r}) -
ln{\widehat{\mathcal{L}}})] \leq - 3.84\)</span><br />
<span class="math inline">\([ln(\mathcal{L} _{r}) -
ln{\widehat{\mathcal{L}}})] \leq 1.92\)</span></p>
<p>So, now what do you think about the ‘rule of 2’? Is it close
enough??</p>
<p><strong>Q</strong>: is the likelihood surface a <em>probability
distribution</em>?</p>
<p><img src="curve_fitting.png" /></p>
<p><a href="LECTURE5.html">–go to next lecture–</a></p>
</div>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
